{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc66f688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\Downloads\\ML\\RAG\\venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9676d2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2c3eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = Document(\n",
    "    page_content = \"This is the main text\",\n",
    "    metadata = {\n",
    "        \"Source\": \"example.txt\",\n",
    "        \"Author\": \"Kelvin Johnson\",\n",
    "        \"Date_created\": \"2025-10-24\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c37c0cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'Source': 'example.txt', 'Author': 'Kelvin Johnson', 'Date_created': '2025-10-24'}, page_content='This is the main text')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2efa75a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##createing a simple txt file\n",
    "import os\n",
    "os.makedirs(\"/data/text_files\",exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "258c53fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\Downloads\\ML\\RAG\\data\\text_files\n"
     ]
    }
   ],
   "source": [
    "path = \"data/text_files\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "print(os.path.abspath(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "941789af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text file created\n"
     ]
    }
   ],
   "source": [
    "sample_texts = {\n",
    "    \"data/text_files/python.txt\": \"\"\"Python is a high-level, interpreted programming language known for its simplicity, readability, and versatility. Created by Guido van Rossum and released in 1991, it emphasizes clear syntax and code reusability, making it ideal for beginners and professionals alike. Python supports multiple programming paradigms, including object-oriented, procedural, and functional programming. It has an extensive standard library and a vast ecosystem of external packages that enable applications in various domains such as web development (Django, Flask), data science (Pandas, NumPy, Scikit-learn), artificial intelligence (TensorFlow, PyTorch), and automation. Python’s dynamic typing and interpreted nature allow rapid development and prototyping. It is widely used by organizations like Google, Netflix, and NASA due to its flexibility and strong community support. Overall, Python’s combination of ease of use, power, and scalability has made it one of the most popular programming languages in the world.\"\"\"\n",
    "}\n",
    "\n",
    "\n",
    "for filepath, content in sample_texts.items():\n",
    "    with open(filepath, 'w', encoding=  \"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"Sample text file created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41f82174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\Downloads\\ML\\RAG\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'data/text_files/python.txt'}, page_content='Python is a high-level, interpreted programming language known for its simplicity, readability, and versatility. Created by Guido van Rossum and released in 1991, it emphasizes clear syntax and code reusability, making it ideal for beginners and professionals alike. Python supports multiple programming paradigms, including object-oriented, procedural, and functional programming. It has an extensive standard library and a vast ecosystem of external packages that enable applications in various domains such as web development (Django, Flask), data science (Pandas, NumPy, Scikit-learn), artificial intelligence (TensorFlow, PyTorch), and automation. Python’s dynamic typing and interpreted nature allow rapid development and prototyping. It is widely used by organizations like Google, Netflix, and NASA due to its flexibility and strong community support. Overall, Python’s combination of ease of use, power, and scalability has made it one of the most popular programming languages in the world.')]\n"
     ]
    }
   ],
   "source": [
    "# text loader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader(\"data/text_files/python.txt\", encoding = 'utf-8')\n",
    "document = loader.load()\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55df451b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\text_files\\\\python.txt'}, page_content='Python is a high-level, interpreted programming language known for its simplicity, readability, and versatility. Created by Guido van Rossum and released in 1991, it emphasizes clear syntax and code reusability, making it ideal for beginners and professionals alike. Python supports multiple programming paradigms, including object-oriented, procedural, and functional programming. It has an extensive standard library and a vast ecosystem of external packages that enable applications in various domains such as web development (Django, Flask), data science (Pandas, NumPy, Scikit-learn), artificial intelligence (TensorFlow, PyTorch), and automation. Python’s dynamic typing and interpreted nature allow rapid development and prototyping. It is widely used by organizations like Google, Netflix, and NASA due to its flexibility and strong community support. Overall, Python’s combination of ease of use, power, and scalability has made it one of the most popular programming languages in the world.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#directory loader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "##loading text file from the directory\n",
    "dir_loader = DirectoryLoader(\n",
    "    \"data/text_files\",\n",
    "    glob = \"**/*.txt\",\n",
    "    loader_cls = TextLoader,\n",
    "    loader_kwargs={'encoding': 'utf-8'},\n",
    ")\n",
    "\n",
    "document = dir_loader.load()\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b5de2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 0}, page_content='Unit 5 \\nUnit-5 : Multivariate Time Series Analysis — VAR Estimation: \\n \\n• Introduction to multivariate time series analysis, \\n• Concepts of Vector Auto Regression, \\n• multivariate least square estimation, asymptotic properties of Lease \\nsquare estimation, \\n• Introduction to Vector Error Correction Models, \\n• Cointegrated Processes (Johensen Co-integration technique), \\nCommon Stochastic Trends Deterministic Terms in Cointegrated \\nProcesses, Forecasting Integrated and Cointegrated Variables \\n• Introduction to Univariate GARCH models, multivariate GARCH, \\nestimation of GARCH models. \\n \\n1. Statistics: Multivariate time series analysis — fundamental concepts, VMA, VAR and VARMA  \\n \\n2. Vector Autoregression (VAR) for Multivariate Time Series  \\nhttps://www.geeksforgeeks.org/vector-autoregression-var-for-multivariate-time-series/ \\n \\n3. Vector Autoregressive Model (VAR) Using R  \\nhttps://www.geeksforgeeks.org/vector-autoregressive-model-var-using-r/ \\n \\n4. Introduction to the Fundamentals of Vector Autoregressive Models \\nhttps://www.aptech.com/blog/introduction-to-the-fundamentals-of-vector-\\nautoregressivemodels/#:~:text=We%20lay%20the%20foundation%20for%20getting%20start\\ned%20with,VAR%20model.%20Estimation%20and%20forecasting%20with%20VAR%20mo\\ndels. \\n \\n5. An Introduction to Vector Error Correction Models (VECMs) · r-econometrics \\nhttps://www.r-econometrics.com/timeseries/vecintro/ \\n \\n6. VECM Estimation and Interpretation - SPUR ECONOMICS \\nhttps://spureconomics.com/vecm-estimation-and-interpretation/ \\n \\n \\n7. Johansen Cointegration Test: Learn How to Implement it in Python \\nhttps://blog.quantinsti.com/johansen-test-cointegration-building-stationary-portfolio/'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 1}, page_content='Univariate and Multivariate Time Series Analysis  \\n \\nTraditional statistical approaches for time series are univariate, meaning they focus on a single \\nsequence of values. \\nHowever, in the real world, time series data often consists of multiple variables that interact with one \\nanother. This interaction introduces an opportunity to move beyond univariate analysis and leverage \\nmultivariate time series, where relationships between features play a central role. \\n \\nWhat is Univariate Time Series? \\nUnivariate time series analysis deals with a single variable measured over time. For example: \\n• \\nStock prices: The daily closing price of a single stock. \\n• \\nTemperature: The hourly temperature recorded in a city. \\n• \\nMachine sensor data: A single sensor recording vibration levels over time. \\nIn a univariate time series, we focus exclusively on the historical behavior of one sequence to predict \\nits future values. Traditional statistical techniques like autoregressive models (AR), moving averages \\n(MA), and their combination (ARIMA) are all built around this univariate framework. \\nFor example, if we are analyzing a machine’s temperature sensor, we might forecast tomorrow’s \\ntemperature based solely on its historical trend without considering any other variables. This \\nsimplicity is efficient and computationally simple. Analyzing a single variable makes it easier to \\nunderstand the underlying patterns. \\nHowever, univariate models have limitations. They fail to account for external influences or \\ncorrelations between variables. In a world where systems are often interconnected, ignoring these \\nrelationships can lead to suboptimal forecasts. \\n \\nMultivariate Time Series \\nIn a multivariate time series, we analyze multiple time-dependent variables simultaneously. This \\napproach allows us to incorporate relationships and correlations between different features, providing \\na richer context for predictions. \\nConsider a machine in an industrial setting. A single temperature sensor might not tell us much about \\npotential failures, but combining data from multiple sensors — such as temperature, pressure, \\nvibration, and energy consumption — gives us a more comprehensive view. These variables often \\ninteract in predictable ways, especially when bounded by physical laws. \\nMultivariate analysis Capturing Relationships between variables. For example, an increase in \\nmachine temperature might correlate with a rise in vibration levels, both of which may signal an \\nimpending failure. \\nThat means we have more info to drive our multivariate models. If one variable strongly influences \\nanother, the additional information can help anticipate future changes more effectively. \\nMany systems — especially physical systems like machinery, climate, or energy grids — operate \\nunder physics-bounded constraints. For instance: In a machine, temperature cannot rise indefinitely \\nwithout causing other measurable effects (like pressure changes). Another example: In an electric \\ngrid, load and power generation must remain in balance. \\nSo it makes sense to use multiple variables (and multivariate models) to incorporate these constraints.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 2}, page_content='Univariate vs. Multivariate: Which one should I use? \\nLet’s compare univariate and multivariate approaches by predicting machine failure. \\n• \\nUnivariate Approach: Suppose we have a time series of temperature readings from a single \\nsensor. Using a univariate model, we can identify trends, seasonality, or anomalies in the \\ntemperature data over time. this is simple to implement and computationally efficient. But it \\nfailsto account for other factors (e.g., pressure, vibration) that could provide additional \\ncontext. \\n• \\nMultivariate Approach: Imagine we have data from three sensors: temperature, vibration, and \\npressure. These variables are interrelated: an increase in vibration may lead to higher \\ntemperature and pressure changes. We can etect complex patterns that wouldn’t be apparent \\nin a single variable and we can identify leading indicators (e.g., vibration might increase \\nbefore temperature rises). overall this helps us build better forecasts and failure detection \\nmodels. \\nFor example, if a multivariate model recognizes that a spike in vibration tends to precede an increase \\nin temperature by 10 minutes, it can issue early warnings for preventive maintenance. \\n \\nTechniques for Multivariate Time Series Analysis \\nTransitioning from univariate to multivariate analysis requires models that can handle multiple \\nvariables simultaneously. Here are some key techniques: \\n1. Vector Autoregressive (VAR) Models: The VAR model is an extension of autoregression for \\nmultivariate time series. It captures linear relationships between multiple variables over time. \\n2. Vector Error Correction Models (VECM): VECM is a variant of VAR used when variables \\nexhibit long-term equilibrium relationships. It’s particularly useful when features are \\ncointegrated — meaning they move together over time. \\n3. Machine Learning Approaches: Recurrent Neural Networks (RNNs) and Long Short-Term \\nMemory (LSTM) networks: These models excel at learning complex, non-linear patterns in \\nmultivariate time series. They are widely used for predictive maintenance, financial \\nforecasting, and weather prediction. \\n4. Transformer Models: Recent advances like transformers can efficiently handle multivariate \\ntime series with long-term dependencies. \\n5. Multivariate State-Space Models: These models explicitly consider the underlying system \\ndynamics and constraints, making them well-suited for physical systems governed by laws \\nlike thermodynamics or mechanics. \\nNext Steps \\nUnivariate time series models are simple and effective for single-variable analysis but fail to account \\nfor relationships between features. \\nMultivariate time series models leverage correlations between variables to improve forecast accuracy \\nand account for system constraints. \\nPhysical systems often exhibit interdependencies that can only be captured through multivariate \\nanalysis, making it essential for fields like predictive maintenance, energy forecasting, and climate \\nmodeling. \\nTechniques like VAR, LSTMs, and transformers allow us to analyze and predict multivariate time \\nseries data at scale. \\nBy embracing multivariate approaches, we unlock deeper insights, better forecasts, and more reliable \\ndecisions — especially in complex, interconnected systems.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 3}, page_content=\"Bee Example \\nYou notice a correlation between bee traffic and temperature. If temperature increases, bee traffic \\nincreases. If bee traffic decreases suddenly, the hive may be under stress. \\nHere, analyzing only bee traffic (univariate) would miss the relationship with temperature and weight. \\nMultivariate analysis can combine all three to improve predictions. \\n \\nApplications of Multivariate Time Series \\n \\n• \\nFinance: To track indicators like stock prices, interest rates, and trading volumes, \\nhelping forecast market trends. \\n• \\nHealthcare: To monitor health metrics such as blood pressure and heart rate, detecting \\npatterns or predicting health events. \\n• \\nClimate Science: To analyze variables like temperature and precipitation, aiding in \\nweather prediction and climate study. \\n• \\nEconomics: To assess indicators like GDP and inflation rates, providing insights into \\neconomic conditions. \\n• \\nManufacturing: To monitor production metrics like machine performance and product \\nquality, optimizing processes and preventing failures. \\nConclusion \\nMultivariate time series modeling involves preparing the data by handling missing values, selecting \\nan appropriate model like VAR, fitting the model to the data, and then evaluating its performance \\nthrough diagnostics and metrics. This process helps to understand the relationships between variables \\nand supports decision-making and forecasting. To enhance the analysis, you can add relevant \\nvariables, explore advanced modeling techniques, regularly update the model with new data, and \\nconduct sensitivity analyses. \\n \\nVector Autoregression (VAR) for Multivariate Time Series \\n \\nVector Autoregression (VAR) is a statistical tool used to investigate the dynamic relationships between \\nmultiple time series variables. Unlike univariate autoregressive models, which only forecast a single \\nvariable based on its previous values, VAR models investigate the interconnectivity of many variables. \\nThey accomplish this by modeling each variable as a function of not only its previous values but also \\nof the past values of other variables in the system. In this article, we are going to explore the \\nfundamentals of Vector Autoregression. \\nTable of Content \\n• \\nWhat is Vector Autoregression? \\n• \\nMathematical Intuition of VAR Equations \\n• \\nAssumptions underlying the VAR model \\n• \\nApplications of VAR Models \\n \\nWhat is Vector Autoregression? \\nVector Autoregression was first presented in the 1960s by economist Clive Granger. Granger's \\nsignificant discoveries laid the framework for understanding and modeling the dynamic interactions \\nthat exist among economic factors. VAR models acquired significant momentum in econometrics and \\nmacroeconomics during the 1970s and 1980s. \\n \\nVector Autoregression (VAR) is a multivariate extension of autoregression (AR) models. While \\ntraditional AR models analyze the relationship between a single variable and its lagged values, VAR \\nmodels consider multiple variables simultaneously. In a VAR model, each variable is regressed on its \\nown lagged values as well as lagged values of other variables in the system.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 4}, page_content='Mathematical Intuition of VAR Equations \\nVAR models are mathematically represented as a system of simultaneous equations, where each \\nequation describes the behavior of one variable as a function of its own lagged values and the lagged \\nvalues of all other variables in the system. \\n \\n \\nvarious assumptions and requirements must be met. \\n \\nAssumptions underlying the VAR model \\n \\nVAR analysis is subject to several assumptions and requirements to ensure the validity and reliability \\nof the results: \\n \\n1. Linearity: Relationships between variables are linear. \\n2. Stationarity: Time series data are stationary. \\n3. No Perfect Multicollinearity: No perfect linear relationships exist between variables. \\n4. No Autocorrelation in Residuals: Residuals are not serially correlated. \\n5. Homoscedasticity: Residual variance is constant. \\n6. No Endogeneity: Variables are not affected by omitted factors. \\n7. Exogeneity: Explanatory variables are not influenced by other variables. \\n8. Sufficient Observations: Adequate data for parameter estimation. \\n9. Weak Exogeneity: Some variables may be endogenous but not contemporaneously \\ncorrelated with errors. \\n \\nApplications of VAR Models \\n \\n1. Economic Forecasting: VAR models are widely used in economics to forecast the \\nbehavior of economic variables such as GDP, inflation, and interest rates. \\n2. Causal Inference: By studying the impulse responses generated by VAR models, \\nresearchers can infer the causal impact of one variable on another. This is particularly \\nvaluable in policy evaluation. \\n3. Financial Markets: VAR models can be used to predict financial indices, stocks and \\nasset prices.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 5}, page_content='What is Multivariate Least Squares Estimation? \\n• \\nIn a multivariate time series model like VAR (Vector Auto Regression), we have multiple \\nequations, each explaining a variable based on its own lags and the lags of other variables. \\n• \\nMultivariate Least Squares Estimation simply means: \\no \\nApply Ordinary Least Squares (OLS) to each equation separately. \\no \\nEach equation is treated like an independent multiple regression. \\n \\nAsymptotic Properties of Least Squares Estimation (OLS) \\nWhat Are Asymptotic Properties? \\n• \\nAsymptotic refers to the behavior of an estimator as the sample size (T) approaches infinity. \\n• \\nIn the case of OLS, these properties describe how the estimates of the model parameters behave \\nwhen you have a large number of observations. \\nThese properties are essential for understanding whether OLS estimators are reliable when working \\nwith large datasets (like in time series or panel data). \\nKey Asymptotic Properties of OLS Estimators'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 6}, page_content='3. Efficiency (BLUE: Best Linear Unbiased Estimator) \\n• \\nDefinition: OLS is the Best Linear Unbiased Estimator (BLUE) under certain conditions. \\n• \\nWhy Important: \\no \\nEfficiency means that, among all linear unbiased estimators, OLS has the smallest \\nvariance. \\no \\nIn simple terms, OLS gives the most precise estimates when assumptions hold. \\n \\n• \\nMathematical Basis (Gauss-Markov Theorem): \\no \\nUnder the assumption of no heteroskedasticity (constant variance of errors) and no \\nautocorrelation (errors are uncorrelated), OLS is the best estimator in terms of \\nhaving the lowest variance. \\n \\nAn Introduction to Vector Error Correction Models (VECMs) \\nOne of the prerequisits for the estimation of a vector autoregressive (VAR) model is that the analysed \\ntime series are stationary. However, economic theory suggests that there exist equilibrium relations \\nbetween economic variables in their levels, which can render these variables stationary without taking \\ndifferences. This is called cointegration. Since knowing the size of such relationships can improve the \\nresults of an analysis, it would be desireable to have an econometric model, which is able to capture \\nthem. So-called vector error correction models (VECMs) belong to this class of models. The following \\ntext presents the basic concept of VECMs and guides through the estimation of such a model in R. \\n \\nModel and data'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 7}, page_content='Vector error correction models are very similar to VAR models and can have the following form: \\n \\nwhere Δx is the first difference of the variables in vector x, Pi is a coefficient matrix of cointegrating \\nrelationships, T is a coefficient matrix of the lags of differenced variables of x, d is a vector of \\ndeterministic terms and C its corresponding coefficient matrix. p is the lag order of the model in its \\nVAR form and ϵ is an error term with zero mean and variance-covariance matrix Σ. \\nThe above equation shows that the only difference to a VAR model is the error correction term Πxt−1, \\nwhich captures the effect of how the growth rate of a variable in x changes, if one of the variables \\ndeparts from its equilibrium value. The coefficient matrix Π can be written as the matrix \\nproduct Π=αβ′ so that the error correction term becomes αβ′xt−1. The cointegration matrix β contains \\ninformation on the equilibrium relationships between the variables in levels. The vector described \\nby β′xt−1 can be interpreted as the distance of the variables form their equilibrium values. α is a so-\\ncalled loading matrix describing the speed at which a dependent variable converges back to its \\nequilibrium value. \\nNote that Π is assumed to be of reduced rank, which means that α is a K×r matrix and β is a Kco×r \\nmatrix, where K is the number of endogenous variables, Kco is the number of variables in the \\ncointegration term and r is the rank of Π, which describes the number of cointegrating relationships that \\nexist between the variables. Note that if r=0, there is no cointegration between the variables so that Π=0. \\nA Vector Error Correction Model (VECM) is a special form of a Vector Autoregression (VAR) \\nmodel that is designed for non-stationary but cointegrated time series. If two or more variables are \\nintegrated (i.e., I(1)) and share a long-run equilibrium relationship, VECM is used to model both \\ntheir short-run dynamics and long-run relationships. \\n Key Features: \\n• \\nIncorporates cointegration constraints into a VAR model. \\n• \\nCaptures both short-term adjustments and long-run equilibrium. \\n• \\nSuitable when at least two variables move together over time due to an economic relationship \\n(like inflation and interest rates). \\n \\nCointegrated Processes (Johensen Co-integration technique), Common Stochastic Trends \\nDeterministic Terms in Cointegrated Processes, Forecasting Integrated and Cointegrated \\nVariables'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 8}, page_content=\"2. Cointegrated Processes \\nWhat is Cointegration? \\nTwo or more non-stationary time series are said to be cointegrated if a linear combination of them is \\nstationary (I(0)). This implies a long-run equilibrium relationship between them despite being \\nindividually non-stationary. \\n   Example: \\nLet’s say GDP and consumption are both I(1). If the residual from the equation Consumption = β0 + \\nβ1*GDP + ε is I(0), then these variables are cointegrated. \\n3. Johansen Cointegration Technique \\nWhat is Johansen's Method? \\nJohansen's test is a multivariate technique for testing the number of cointegration relationships in a \\nsystem of I(1) time series. It is based on estimating a VECM and uses eigenvalues and trace \\nstatistics to determine the number of cointegration vectors. \\n Steps: \\n1. Check each variable is I(1) using ADF or PP test. \\n2. Estimate a VECM. \\n3. Use Johansen Trace Test or Max-Eigenvalue Test to find the number of cointegrating \\nequations. \\nWhat is the Johansen cointegration test? \\nThe Johansen Cointegration Test is a statistical procedure used to analyse the long-term \\nrelationships between multiple time series variables. Time Series is a sequence of observations \\nover time, which are usually spaced at regular intervals. For example, daily observed prices of \\nthe stocks, bonds etc. over a period of 10 years, 1 minute stock price data for the last 100 days \\netc. \\nKey properties of Johansen cointegration test \\nThe Johansen Cointegration Test is a valuable tool for economists, financial analysts, and \\nresearchers to assess the relationships between multiple time series variables and make informed \\ndecisions based on their long-term behaviour. \\nKey properties of the Johansen Cointegration Test include:\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 9}, page_content='Key properties of the Johansen Cointegration Test \\n• \\nMultivariate Approach: Unlike some other cointegration tests, the Johansen Test \\ncan handle multiple time series variables simultaneously. This makes it especially \\nuseful when you want to analyse the relationships between more than two variables. \\n• \\nEigenvalues and Eigenvectors: The test relies on the eigenvalues and eigenvectors \\nof a matrix derived from the time series data. These mathematical properties help \\ndetermine the number of cointegrating relationships between the variables. \\n• \\nTrace and Maximum Eigenvalue Tests: The Johansen Test consists of two different \\ntests: the Trace test and the Maximum Eigenvalue test. These tests help determine \\nthe rank of the cointegration matrix, which, in turn, indicates the number of \\ncointegrating relationships present. \\n• \\nOrder of Integration: The test takes into account the order of integration of the \\ntime series variables, allowing it to differentiate between I(0) (stationary) and I(1) \\n(integrated of order 1) series. This is crucial for understanding whether the variables \\nhave a common stochastic trend. \\n• \\nCritical Values: The interpretation of the test results involves comparing test \\nstatistics to critical values from statistical tables, which depend on the significance \\nlevel chosen for the test. These critical values help determine whether cointegration \\nexists. \\n• \\nInterpretation: The test results can reveal whether there are long-term relationships \\nbetween the variables. If cointegration is detected, it implies that the variables move \\ntogether in the long run, and deviations from this equilibrium relationship are mean-\\nreverting.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 10}, page_content='Importance of Johansen Cointegration Test \\nThe Johansen Cointegration Test holds significant importance in the fields of econometrics, \\nfinance, and time series analysis for several key reasons: \\n \\nImportance of the Johansen Cointegration Test \\n• \\nLong-Term Relationships: It identifies and quantifies the existence of long-term or \\nequilibrium relationships between multiple time series variables. This is crucial for \\nunderstanding how different economic or financial factors interact over extended \\nperiods.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 11}, page_content=\"• \\nDiverse Applications: The test can be applied in various contexts, such as finance, \\neconomics, and social sciences. It's used to analyse the relationships between \\nmacroeconomic variables, financial instruments, asset pricing models, and more. \\n• \\nMultivariate Analysis: Unlike some other cointegration tests, the Johansen Test can \\nhandle multiple variables simultaneously, making it a versatile tool for analysing \\ncomplex relationships within a dataset. \\n• \\nPortfolio Management: In finance, the test is essential for portfolio management. It \\nhelps investors and fund managers assess the cointegration of assets in a portfolio, \\nwhich can inform diversification and risk management strategies. \\n• \\nMean-Reverting Portfolios: The test can identify mean-reverting (stationary) \\nportfolios. In such cases, deviations from the long-term equilibrium are expected to \\nreturn to that equilibrium, making it valuable for traders and investors. \\n• \\nHedging Strategies: For hedging purposes, it is important to determine if there are \\ncointegrated relationships between assets or financial instruments. A cointegrated \\nrelationship can be exploited for hedging purposes. \\n• \\nReducing Spurious Regression: Cointegration analysis helps reduce the risk of \\nspurious regression, a common issue when dealing with non-stationary time series \\ndata. By identifying cointegration, researchers avoid drawing erroneous conclusions \\nfrom non-causal relationships. Exploring Stationary Time Series plays a key role in \\navoiding spurious regression. When time series are stationary, cointegration analysis \\nbecomes more effective, ensuring that you draw accurate conclusions and base your \\ndecisions on true relationships. Learn more to see how stationarity can enhance your \\nanalysis and minimize errors. \\n• \\nPolicy Analysis: In economics, the Johansen Cointegration Test is useful for policy \\nanalysis. It can help assess the long-term impact of various economic policies on \\ndifferent variables, providing insights for policymakers. \\n• \\nForecasting: Cointegrated variables can be used to improve the accuracy of \\neconomic and financial forecasts. By understanding how variables move together in \\nthe long term, forecasts can be refined. \\n• \\nFinancial Modelling: The test plays a crucial role in the development of financial \\nmodels, particularly those involving multiple interacting variables. It enhances the \\naccuracy of models by capturing the underlying cointegrated relationships. \\nIn summary, the Johansen Cointegration Test is a valuable tool for analysing the long-term \\nrelationships between time series variables, providing insights into economic and financial \\ndynamics, portfolio management, and policy analysis, among other applications. Its ability to \\nhandle multivariate data makes it a versatile and indispensable technique for researchers and \\npractitioners in these fields. \\nApplying cointegration in trading or forecasting \\nCointegration, a concept in time series analysis, is especially useful in the world of trading and \\nforecasting. It helps traders and analysts make better predictions and strategic decisions. \\nHere's how it works: \\n• \\nIdentifying Trading Pairs: Traders often look for pairs of assets or securities that \\nmove together in the long run. Cointegration can help identify these pairs. For \\ninstance, if you're trading stocks, you might notice that the prices of two companies \\ntend to follow a similar pattern over time. These pairs could be useful for a trading \\nstrategy. \\n• \\nStatistical Arbitrage: Cointegration enables traders to engage in statistical \\narbitrage. This means taking advantage of temporary price divergences within\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 12}, page_content=\"cointegrated pairs. If one stock temporarily deviates from the other in a predictable \\nway, traders can buy or sell to capture the difference when the prices realign. \\n• \\nRisk Management: Cointegration can be a tool for risk management. By \\ndiversifying your investments in cointegrated assets, you can reduce your portfolio's \\nexposure to risk. When one asset in a pair fluctuates, the other tends to balance it \\nout. \\n• \\nForecasts: Cointegration can improve forecasting accuracy. When two or more \\nvariables are cointegrated, their long-term relationship can be used to make better \\npredictions. For instance, in economics, cointegrated variables can help in predicting \\nfuture inflation or interest rates. \\n• \\nHedging: Cointegrated assets are often used for hedging purposes. If you have an \\nasset exposed to a certain risk, you can use another cointegrated asset to hedge that \\nrisk. This helps protect your investments. \\nCommon Stochastic Trends and Deterministic Terms in Cointegrated Processes \\nCommon Stochastic Trends: \\nThese are shared underlying trends that drive the long-term behavior of multiple variables. \\nCointegrated variables are driven by fewer stochastic trends than the number of series. \\n• \\nIf you have 3 I(1) series with 2 cointegrating vectors, then only one common stochastic trend \\ndrives them. \\n Deterministic Terms: \\nThese are constants, trends, or seasonal dummies included in cointegration analysis. \\n• \\nIntercept (constant): Captures mean shift. \\n• \\nTrend term: Models time-dependent growth or decline. \\n• \\nSeasonal dummies: Account for periodic patterns. \\nThe inclusion of these terms affects the interpretation and estimation of cointegrating relationships. \\n \\n Forecasting Integrated and Cointegrated Variables \\nWhat Are Integrated and Cointegrated Variables? \\n1. Integrated Variables (I(1)) \\n• \\nThese are non-stationary time series that become stationary after differencing once. \\n• \\nExample: GDP, inflation, or interest rate levels often show trends over time and are I(1). \\n2. Cointegrated Variables \\n• \\nA group of I(1) variables are cointegrated if a linear combination of them is stationary. \\n• \\nThis implies a long-run equilibrium relationship among the variables despite short-term \\nfluctuations. \\nKey Concepts:\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 13}, page_content='• \\nFor non-cointegrated I(1) variables, standard differenced VAR or ARIMA models can be \\nused. \\n• \\nFor cointegrated variables, a VECM provides better forecasts since it: \\no \\nIncorporates short-term dynamics. \\no \\nMaintains long-term equilibrium relationships. \\no \\nAvoids spurious regression results. \\nForecasting Steps with VECM: \\n1. Identify and test for unit roots. \\n2. Test for cointegration using Johansen’s method. \\n3. Estimate the VECM. \\n4. Generate forecasts and interpret both short-run and long-run implications. \\n \\nIntroduction to Univariate GARCH models...elaborate in detail \\ndetailed explanation of Univariate GARCH (Generalized Autoregressive Conditional \\nHeteroskedasticity) models, which are widely used in financial econometrics to model and forecast \\ntime-varying volatility in time series data such as stock returns or exchange rates. \\nWhat Is a Univariate GARCH Model? \\nUnivariate GARCH models focus on a single time series (like the daily return of a stock) and aim to \\ncapture the phenomenon where volatility changes over time — specifically where periods of high \\nand low volatility cluster together. \\nThese models address the non-constant variance (heteroskedasticity) in the error terms of time \\nseries data. \\nWhy Use GARCH Models? \\n• \\nFinancial return data often exhibit volatility clustering. \\n• \\nClassical time series models assume homoskedasticity (constant variance), which is \\nunrealistic in financial markets. \\n• \\nGARCH models capture and forecast this changing variance. \\nARCH Model: The Starting Point \\nBefore GARCH, the ARCH (Autoregressive Conditional Heteroskedasticity) model, introduced by \\nRobert Engle in 1982, was the first to model conditional variance. \\nARCH(q) Model:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 14}, page_content='GARCH Model: A Generalization (Bollerslev, 1986) \\nGARCH(p, q) Model: \\n \\nInterpretation of Parameters in GARCH(1,1) \\n• \\nα0: Long-run average variance. \\n• \\nα1: Impact of recent shocks (news). \\n• \\nβ1: Persistence of past variance. \\nThe sum α1+β1 indicates the persistence of volatility: \\n• \\nIf close to 1 → high persistence \\n• \\nIf < 1 → volatility eventually dies out (stationary)'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 15}, page_content='Properties of GARCH Models \\nProperty \\nExplanation \\nVolatility clustering \\nCaptures the fact that volatility tends to persist. \\nLeptokurtosis \\nCan account for fat tails in returns. \\nForecasting power \\nExcellent for short-term volatility forecasts. \\nConditional heteroskedasticity Variance depends on past information. \\n \\nApplications of Univariate GARCH Models \\n• \\nRisk management (Value at Risk) \\n• \\nOption pricing (volatility modeling) \\n• \\nPortfolio optimization \\n• \\nMarket analysis (detecting crisis periods) \\n• \\nMacroeconomic volatility studies \\nExample in Real Life: S&P 500 Returns \\nIf daily returns of the S&P 500 show high volatility after major economic news and calm periods \\notherwise, a GARCH(1,1) model can help: \\n• \\nModel how the news affects short-term volatility. \\n• \\nPredict future volatility for risk control or derivative pricing. \\n \\nIntroduction: Why Multivariate GARCH? \\nWhile Univariate GARCH models capture the time-varying volatility of a single time series (e.g., \\nreturns of one stock), Multivariate GARCH (MGARCH) models extend this framework to handle \\nmultiple time series simultaneously — for example: \\nModeling volatility and correlation across different assets, sectors, or markets. \\nThis is crucial for: \\n• \\nPortfolio optimization \\n• \\nRisk management \\n• \\nAsset allocation \\n• \\nSpillover and contagion analysis in financial markets \\n Key Objectives of Multivariate GARCH Models \\n1. Model time-varying variances of multiple assets. \\n2. Capture time-varying covariances or correlations. \\n3. Ensure the covariance matrix is positive semi-definite. \\n4. Allow for parsimonious parameter estimation, especially when the number of series is large.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 16}, page_content='Estimation of GARCH Models \\n• \\nMethod: Maximum Likelihood Estimation (MLE) or Quasi-MLE (QMLE) \\n• \\nSteps (for DCC-GARCH): \\n1. Estimate univariate GARCH models. \\n2. Use standardized residuals to estimate correlation dynamics. \\n• \\nSoftware: \\no \\nR: rmgarch, ccgarch \\no \\nPython: arch, statsmodels \\no \\nEViews, MATLAB, Stata \\nApplication Areas of Multivariate GARCH \\n1. Portfolio Risk Modeling: Estimating time-varying covariance matrix for optimal weights. \\n2. VaR (Value at Risk): Computing portfolio risk under changing volatility and correlation. \\n3. Market Spillovers: Identifying how volatility in one market (e.g., US) affects others (e.g., \\nIndia, EU). \\n4. Financial Contagion: Studying co-movement during crisis periods. \\nExample \\nSuppose you’re analyzing daily returns of Apple, Google, and Tesla: \\n• \\nStep 1: Fit individual GARCH(1,1) to each stock. \\n• \\nStep 2: Use residuals to estimate dynamic correlation matrix using DCC. \\n• \\nStep 3: Forecast covariance matrix for tomorrow’s portfolio risk.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 0}, page_content='Unit 3 \\nUnit 3: Univariate time series analysis — II: \\n• ARMA (p,q) process,  \\n• ACF (Auto Correlation Function) and PACF (Partial Auto Correlation Function) of an \\nARMA (p,q) process, forecasting ARMA process,  \\n• integration of non-stationary data, first-order integration and second order integration,  \\n• ARIMA (p,i,q), estimation of parameters of ARIMA model,  \\n• Wald Test Statistic for significance of coefficients. \\n \\n1. Chap 5: ARIMA Model \\nhttp://ocw.utm.my/pluginfile.php/3782/mod_resource/content/0/Chap5-\\nARIMAModel.pdf  \\n \\n2. Auto correlation Function (ACF) and Partial Auto correlation Function (PACF) \\nhttps://medium.com/@ritusantra/auto-correlation-function-acf-and-partial-auto-\\ncorrelation-function-pacf-e29ec2db2b1b \\n \\n \\n3. Order of Integration: Time Series and Integration \\nhttps://www.statisticshowto.com/order-of-integration/ \\n \\n4. What are ARIMA models? \\nhttps://www.ibm.com/think/topics/arima-model \\n \\n5. Time Series Analysis using ARIMA model in R Programming \\nhttps://www.geeksforgeeks.org/time-series-analysis-using-arima-model-in-r-\\nprogramming/ \\n \\n6. ARIMA Models in R \\nhttps://medium.com/biased-algorithms/arima-models-in-r-8ccd2328bb32 \\n \\n7. Model Selection for ARIMA \\nhttps://www.geeksforgeeks.org/model-selection-for-arima/ \\n \\n8. Quick way to find p, d and q values for ARIMA (With time series data sample) \\nhttps://analyticsindiamag.com/ai-trends/quick-way-to-find-p-d-and-q-values-for-\\narima/ \\n \\n9. How to Perform a Wald Test in R \\nhttps://www.geeksforgeeks.org/how-to-perform-a-wald-test-in-r/ \\n \\n10. Wald test hypothesis testing regression analysis \\nhttps://diogoribeiro7.github.io/statistics/wald_test_hypothesis_testing_regression_anal\\nysis/ \\n \\n11. Understanding — ‘Wald Test’'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 1}, page_content='https://medium.com/@analyttica/understanding-wald-test-2e3fa7723516 \\n \\n12. ARMA TIME SERIES MODEL  \\nhttps://www.geeksforgeeks.org/arma-time-series-model/ \\n \\n13. Time Series Forecasting \\nhttps://medium.com/@immadisettysukeshkumar999/time-series-forecasting-part-3-\\na4bcdec1b44e \\n \\nARMA TIME SERIES MODEL \\nTime series analysis is a crucial aspect of data science, particularly when dealing with data \\nthat is collected over time. One of the fundamental models used in time series analysis is the \\nARMA (Autoregressive Moving Average) model. This article will delve into the ARMA \\nmodel, its components, how it works, and its applications. \\nTable of Content \\n• \\nUnderstanding ARMA Model \\no 1. ARMA Components: Autoregressive (AR) \\no 2. ARMA Components: Moving Average (MA) \\no Mathematical Representation of ARMA Model \\n• \\nHow to Determine the Orders p and q in ARMA Model? \\n• \\nApplication and Use Cases of ARMA Model \\n• \\nAdvantages and Disadvantages of ARMA Model \\nUnderstanding ARMA Model \\nThe ARMA model is a combination of two simpler models: the Autoregressive (AR) \\nmodel and the Moving Average (MA) model. The ARMA model is used to describe time series \\ndata that is stationary, meaning its statistical properties do not change over time. \\n• \\nAutoregressive (AR) Model: This model uses the dependency between an \\nobservation and a number of lagged observations (previous time points). It is denoted \\nas AR(p), where p is the number of lagged observations included. \\n• \\nMoving Average (MA) Model: This model uses the dependency between an \\nobservation and a residual error from a moving average model applied to lagged \\nobservations. It is denoted as MA(q), where ?q is the number of lagged forecast \\nerrors included. \\nThe ARMA model combines these two approaches and is denoted as ARMA(p, q), where p is \\nthe order of the autoregressive part and q is the order of the moving average part. \\n1. ARMA Components: Autoregressive (AR)'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 2}, page_content=\"The Autoregressive (AR) part of the ARMA model uses the relationship between an \\nobservation and a number of lagged (previous) observations to predict future values. Imagine, \\nthat you are attempting to forecast the temperature for tomorrow by using the data from the last \\nseveral days. The AR portion makes the assumption that the current temperature and the \\ntemperatures from earlier days are connected. For instance suppose we write the temperature \\nof today as Tt and the temperatures of the last two days as Tt−1 \\n \\n2. ARMA Components: Moving Average (MA) \\nThe Moving Average (MA) part of the ARMA model uses the dependency between an \\nobservation and a residual error from a moving average model applied to lagged observations. \\nContinuing with our temperature example, the MA part assumes that today's temperature is \\nalso influenced by the errors made in predicting previous days' temperatures. If we denote \\ntoday's error as et and the errors of the last two days as et−1 and et−2 an MA(2) model can be \\nwritten as: \\n \\nMathematical Representation of ARMA Model \\nThe ARMA model is a combination of both AR and MA components. An ARMA(p, q) model, \\nwhere p is the number of lagged observations (AR part) and q is the number of lagged forecast \\nerrors (MA part), is represented as: \\n \\nHow to Determine the Orders p and q in ARMA Model?\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 3}, page_content='Determining the appropriate values for p and q is crucial for building an effective ARMA \\nmodel. This can be done using the following methods: \\n1. Partial Autocorrelation Function (PACF): \\n• \\nPACF is used to determine the order p of the AR model. It measures the \\ncorrelation between observations at different lags, excluding the influence of \\nintermediate lags. \\n• \\nThe order p is determined by the lag at which the PACF plot cuts off. \\n2. Autocorrelation Function (ACF): \\n• \\nACF is used to determine the order q of the MA model. It measures the \\ncorrelation between observations at different lags. \\n• \\nThe order q is determined by the lag at which the ACF plot cuts off. \\nApplication and Use Cases of ARMA Model \\nFor predicting and evaluating time series data the ARMA model is extensively utilized in many \\ndifferent domains. A few typical uses are as follows: \\n• \\nEconomics: Predicting stock prices, exchange rates, and economic indicators. \\n• \\nWeather Forecasting: Analyzing temperature, rainfall, and other meteorological data. \\n• \\nSales Forecasting: Predicting future sales based on past sales data. \\n• \\nEngineering: Monitoring and controlling industrial processes. \\n• \\nInventory management: Forecasting future demand for products. \\n• \\nEpidemiology: Predicting the spread of diseases. \\n \\nAdvantages and Disadvantages of ARMA Model \\nAdvantages \\nLimitations \\nSimplicity: The ARMA model is \\nrelatively simple to understand and \\nimplement. \\nStationarity Requirement: The ARMA model \\nassumes that the time series data is stationary, \\nmeaning its statistical properties do not change \\nover time. Non-stationary data needs to be \\ntransformed before applying the ARMA model. \\nEffectiveness: It works well for \\nmany types of time series data, \\nespecially when there are clear \\npatterns or trends. \\nComplexity with High Parameters: For large \\nvalues of ? and ?, the model can become complex \\nand difficult to interpret.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 4}, page_content='Advantages \\nLimitations \\nCombination of AR and MA: By \\ncombining both autoregressive and \\nmoving average components, the \\nARMA model can capture more \\ncomplex patterns in the data. \\nChoosing the right order for the AR and MA \\ncomponents can be challenging. \\n \\nAuto correlation Function (ACF) and Partial Auto correlation Function (PACF) \\n \\nAuto correlation Function (ACF) \\nAuto-correlation is the correlation between a time series and a delayed version of itself (lag). \\nIt represents a correlation coefficient between the time series and its lag values. \\nAuto correlation Function (ACF) plots the correlation coefficient against the lag, and it’s a \\nvisual representation of autocorrelation. \\nFor example, ACF at lag 3 is calculated as the correlation between the time series (Yt) and the \\nsame time series lagged by 3 time periods (Yt-3). In this way, the correlation is estimated at \\nevery lag and plotted on a graph showing the correlation coefficient at each lag.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 5}, page_content='The correlation coefficient is measured either by Pearson’s correlation coefficient or \\nby Spearman’s rank correlation coefficient. \\nThe correlation coefficient can range from -1 (a perfect negative relationship) to +1 (a perfect \\npositive relationship). A coefficient of 0 means that there is no relationship between the \\nvariables. \\nThe autocorrelation function starts a lag 0, which is the correlation of the time series with itself \\nand therefore results in a correlation of 1. \\nNote: ACF includes both direct and indirect effects through the intermediary time periods. \\n \\n \\nPartial Auto correlation Function (PACF) \\nA partial autocorrelation function captures a direct correlation between time series and a \\nlagged version of itself. \\nFor example, if we’re regressing a signal S at lag t (St) with the same signal at lags t-1, t-2 and \\nt-3 (St-1, St-2, St-3), the partial correlation between St and St-2 is the amount of correlation \\nbetween St and St-3 that isn’t explained by their mutual correlations with St-1 and St-2. \\nTo find PACF between St and St-3 we use regression model, \\n \\nHere, ϕ3 is the PACF at lag 3; \\nϕ1, ϕ2 and ϕ3 are coefficients and Є is error. \\nFrom the regression formula above, the PACF value between St and St-3 is the coefficient ϕ3. \\nThis coefficient will give us direct effect of time-series St-3 to the time-series St because the \\neffects of St-2 and St-1 are already captured by ϕ1 and ϕ2. \\nThe PACF graph is constructed by plotting all the values of PACF obtained from regressions \\nat different lags. \\nNote: PACF includes only direct effect and it does not consider the indirect effects.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 6}, page_content='Importance of ACF and PACF \\nACF and PACF graphs are used to find out the order of AR and MA component of an ARIMA \\nmodel. \\nIf the ACF graph is declining and there are a few significant lags in the PACF, then this \\nindicates the process is AR (Auto-regressive). We can select the order p for AR(p) model \\nbased on significant spikes from the PACF plot. Spikes those are outside the blue boundary of \\nthe PACF plot tell us the order of the AR model. \\nIf the PACF graph is declining and there are a few significant lags in the ACF, then this \\nindicates the process is MA (Moving average). We can select the order q for MA(q) model \\nbased on significant spikes from the ACF plot. Spikes those are outside the blue boundary of \\nthe ACF plot tell us the order of the MA model. \\nThe blue area in the ACF and PACF graphs indicated 95% confidence interval and it is an \\nindictor of significance threshold. Anything within the are is statistically close to zero and \\nanything outside is statistically non-zero. \\nTo determine the order of the model, we have to consider the spikes which are outside the \\nsignificance threshold (blue area). \\n \\nForecasting with ARMA Process \\n Steps for Forecasting: \\n1. Check Stationarity: \\no Use ADF/KPSS tests. \\no If non-stationary, difference the series. \\n2. Plot ACF and PACF: \\no Identify appropriate p and q values. \\n3. Estimate Parameters:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 7}, page_content='o Use Maximum Likelihood Estimation or Least Squares to estimate ϕ\\\\phiϕ and \\nθ\\\\thetaθ. \\n4. Model Validation: \\no Check residuals (should resemble white noise). \\no Use AIC/BIC for model selection. \\n5. Make Forecasts: \\no Once model fits well, use it to predict future values. \\n \\nIntegration of Non-Stationary Data \\nNon-Stationary Data \\nIn time series analysis, a stationary series has a constant mean, variance, and autocovariance \\nover time. A non-stationary series, on the other hand, exhibits trends, seasonality, or changing \\nvariance. \\n• \\nNon-stationary data often lead to spurious regression results, which means misleading \\nstatistical inferences. \\n \\nIntegration \\n\"Integration\" is the process of transforming a non-stationary time series into a stationary one \\nby differencing. \\n• \\nA time series is said to be integrated of order d (denoted I(d)) if it becomes stationary \\nafter differencing d times. \\nDifferencing \\n \\nFirst-Order Integration (I(1)) and Second-Order Integration (I(2)) \\n I(1) Process (First-order Integrated) \\n• \\nA time series Yt is I(1) if it becomes stationary after taking the first difference. \\n• \\nMany economic and financial time series are I(1), such as GDP, exchange rates, or stock \\nprices.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 8}, page_content='I(2) Process (Second-order Integrated) \\n• \\nA time series is I(2) if it becomes stationary only after taking the second difference. \\n• \\nRare in practice but may occur in some long-term macroeconomic variables. \\nARIMA (p, d, q) Model \\nThe ARIMA model combines three components: \\n• \\nAR (Auto Regressive) – p: Regression on its own lagged (past) values. \\n• \\nI (Integrated) – d: Number of times the data are differenced to become stationary. \\n• \\nMA (Moving Average) – q: Regression on past forecast errors. \\nMathematical Representation: \\n \\nEstimation of Parameters of ARIMA Model \\nParameters are typically estimated using Maximum Likelihood Estimation (MLE) or Least \\nSquares. \\nSteps: \\n1. Identify the model order (p, d, q) using: \\no ACF (AutoCorrelation Function) \\no PACF (Partial AutoCorrelation Function) \\no Information criteria like AIC, BIC \\n2. Estimate parameters: \\no Estimate AR (ϕ) and MA (θ) coefficients. \\no Software like R, Python (statsmodels), and EViews can automate this. \\n3. Diagnostic checking: \\no Check residuals for autocorrelation (Ljung-Box test). \\no Ensure residuals are white noise. \\nWald Test Statistic for Significance of Coefficients \\nPurpose:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 9}, page_content='The Wald test checks the statistical significance of individual or a group of \\nparameters in the model. \\nFormula: \\n \\nHypotheses: \\n• \\nNull Hypothesis (H₀): Parameter = 0 (not significant) \\n• \\nAlternative Hypothesis (H₁): Parameter ≠ 0 (significant) \\nIf the Wald statistic exceeds the critical value from a Chi-square distribution, or the p-value < \\n0.05, we reject H₀. \\nUse in ARIMA: \\nUsed to test whether AR or MA coefficients significantly improve the model. \\nSummary Table \\nConcept \\nMeaning \\nNon-stationary Data \\nMean/variance changes over time \\nIntegration \\nMaking data stationary via differencing \\nFirst-order \\nIntegration \\n(I(1)) \\nOne difference needed for stationarity \\nSecond-order \\nIntegration \\n(I(2)) \\nTwo differences needed \\nARIMA(p, d, q) \\nCombines autoregression, integration (differencing), and \\nmoving average \\nParameter Estimation \\nTypically via MLE or least squares \\nWald Test \\nTests if AR/MA parameters are statistically significant'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 10}, page_content=''),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 0}, page_content='Unit-2: Univariate time series analysis — I: \\n \\nModels related to stationary data, Auto Regressive model, Moving Average model, Stationarity \\nof data, concepts on unit root, impacts of a unit root in estimating the model parameters, tests \\nrelated to unit root Dickey Fuller test, Augmented Dickey Fuller test, KPSS Test, The Phillips \\nPeron Test, seasonal unit roots periodic integration and unit root testing. \\n \\nhttps://www.wallstreetmojo.com/unit-root-tests/ \\nhttps://ebrary.net/577/economics/stationarity_tests \\nhttps://www.analyticsvidhya.com/blog/2015/12/complete-tutorial-time-series-modeling/ \\n \\nAutoregressive (AR) Model for Time Series Forecasting \\nAutoregressive models, often abbreviated as AR models, are a fundamental concept in time \\nseries analysis and forecasting. They have widespread applications in various fields, including \\nfinance, economics, climate science, and more. In this comprehensive guide, we will explore \\nautoregressive models, how they work, their types, and practical examples. \\nAutoregressive Models \\nAutoregressive models belong to the family of time series models. These models capture the \\nrelationship between an observation and several lagged observations (previous time steps). The \\ncore idea is that the current value of a time series can be expressed as a linear combination of \\nits past values, with some random noise.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 1}, page_content='Autocorrelation (ACF) in Autoregressive Models \\nAutocorrelation, often denoted as \"ACF\" (Autocorrelation Function), is a fundamental concept \\nin time series analysis and autoregressive models. It refers to the correlation between a time \\nseries and a lagged version of itself. In the context of autoregressive models, autocorrelation \\nmeasures how closely the current value of a time series is related to its past values, specifically \\nthose at different time lags. \\nHere\\'s a breakdown of the concept of autocorrelation in autoregressive models: \\n• \\nAutocorrelation involves calculating the correlation between a time series and a lagged \\nversion of itself. The \"lag\" represents the number of time units by which the series is \\nshifted. For example, a lag of 1 corresponds to comparing the series with its previous \\ntime step, while a lag of 2 compares it with the time step before that, and so on. Lag \\nvalues help you calculate autocorrelation, which measures how each observation in a \\ntime series is related to previous observations. \\n• \\nThe autocorrelation at a particular lag provides insights into the temporal dependence \\nof the data. If the autocorrelation is high at a certain lag, it indicates a strong relationship \\nbetween the current value and the value at that lag. Conversely, if the autocorrelation is \\nlow or close to zero, it suggests a weak or no relationship. \\n• \\nTo visualize autocorrelation, a common approach is to create an ACF plot. This plot \\ndisplays the autocorrelation coefficients at different lags. The horizontal axis represents \\nthe lag, and the vertical axis represents the autocorrelation values. Significant peaks or \\npatterns in the ACF plot can reveal the underlying temporal structure of the data. \\nAutocorrelation plays a pivotal role in autoregressive models. \\n• \\nIn an Autoregressive model of order p, the current value of the time series is expressed \\nas a linear combination of its past p values, with coefficients determined through'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 2}, page_content='methods like least squares or maximum likelihood estimation. The selection of the lag \\norder (p) in the AR model often relies on the analysis of the ACF plot. \\n• \\nAutocorrelation can also be used to assess whether a time series is stationary. In a \\nstationary time series, autocorrelation should gradually decrease as the lag increases. \\nDeviations from this behavior might indicate non-stationarity. \\nTypes of Autoregressive Models \\n \\nAR(p) Model: \\n• \\nThe general autoregressive model of order p includes p lagged values. \\n• \\nIt is expressed as shown in the introduction. \\n \\nBenefits and Drawbacks of Autoregressive Models \\nAutoregressive models (AR models) are a class of time series models that have their own set \\nof benefits and drawbacks. Understanding these can help in choosing when to use them and \\nwhen to consider alternative modeling approaches. \\nBenefits of Autoregressive Models: \\n• \\nSimplicity: AR models are relatively simple to understand and implement. They rely \\non past values of the time series to predict future values, making them conceptually \\nstraightforward. \\n• \\nInterpretability: The coefficients in an AR model have clear interpretations. They \\nrepresent the strength and direction of the relationship between past and future values, \\nmaking it easier to derive insights from the model. \\n• \\nUseful for Stationary Data: AR models work well with stationary time series data. \\nStationary data have stable statistical properties over time, which is an assumption that \\nAR models are built upon. \\n• \\nEfficiency: AR models can be computationally efficient, especially for short time \\nseries or when you have a reasonable amount of data. \\n• \\nModeling Temporal Patterns: AR models are good at capturing short-term temporal \\ndependencies and patterns in the data, which makes them valuable for short-term \\nforecasting. \\nDrawbacks of Autoregressive Models:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 3}, page_content=\"• \\nStationarity Assumption: AR models assume that the time series is stationary, \\nmeaning that its statistical properties do not change over time. In practice, many real-\\nworld time series are non-stationary, requiring preprocessing steps like differencing. \\n• \\nLimited to Short-Term Dependencies: AR models are not well-suited for capturing \\nlong-term dependencies in data. They are primarily designed for modeling short-term \\ntemporal patterns. \\n• \\nLag Selection: Choosing the appropriate lag order (p) in an AR model can be \\nchallenging. Selecting too few lags may lead to underfitting, while selecting too many \\nmay lead to overfitting. Techniques like ACF and PACF plots are used to determine the \\nlag order. \\n• \\nSensitivity to Noise: AR models can be sensitive to random noise in the data. This \\nsensitivity can lead to overfitting, especially when dealing with noisy or irregular time \\nseries. \\n• \\nLimited Forecast Horizon: AR models are generally not suitable for long-term \\nforecasting as they are designed for capturing short-term dependencies. For long-term \\nforecasting, other models like ARIMA, SARIMA, or machine learning models may be \\nmore appropriate. \\n• \\nData Quality Dependence: The effectiveness of AR models is highly dependent on \\ndata quality. Outliers, missing values, or data irregularities can significantly affect the \\nmodel's performance. \\nConclusion \\nAutoregressive (AR) models provide a powerful framework for analyzing and forecasting time \\nseries data. We explored the fundamental concepts of AR models, from understanding \\nautocorrelation to fitting models and making future predictions. By generating a simulated \\ntemperature dataset, we were able to apply AR modeling. AR models are particularly useful \\nwhen dealing with stationary time series data, where past values influence future observations. \\nThe choice of lag order is a crucial step, and it can be determined by examining the \\nAutocorrelation Function (ACF) plot. \\nAs we demonstrated, AR models offer a practical approach to forecasting. However, they have \\ntheir limitations and are most effective when the underlying data exhibits some degree of \\nautocorrelation. \\nFor \\nmore \\ncomplex \\ntime \\nseries \\ndata, \\nother \\nmodels \\nlike ARIMA or SARIMA may be more appropriate. \\nThe ability to make accurate forecasts is a valuable asset in various domains, from finance to \\neconomics and beyond. By mastering Autoregressive models and understanding their \\napplications, analysts and data scientists can make informed decisions based on historical data, \\nhelping to anticipate future trends and make better choices. \\n \\nUnderstanding the Moving average (MA) in Time Series Data \\nData is often collected with respect to time, whether for scientific or financial purposes. When \\ndata is collected in a chronological order, it is referred to as time series data. Analyzing time\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 4}, page_content='series data provides insights into how the data behaves over time, including underlying patterns \\nthat can help solve problems in various domains. Time series analysis can also aid in \\nforecasting future values based on historical data, leading to better production, profits, policy \\nplanning, risk management, and other fields. Therefore, analysis of time series data becomes \\nan important aspect of data science. \\nWhat is the Moving Average Model? \\nMoving Average Models are a type of time series analysis model usually used in econometrics \\nto forecast trends and understand patterns in time series data. In moving average models the \\npresent value of the time series depends on the linear combination of the past white noise error \\nterms of the time series. In time series analysis moving average is denoted by the letter \"q\" \\nwhich represents the order of the moving average model, or in simple words we can say the \\ncurrent value of the time series will depend on the past q error terms. Therefore, the moving \\naverage model of order q could be represented as: \\nXt=c+ϵt+θ1.ϵt−1+θ2.ϵt−2+...+θq.ϵt−q \\nHere, \\n• \\nXt is the value of time series at time t \\n• \\nc is a constant or the mean of the time series \\n• \\nϵt,ϵt−1,ϵt−2,...,ϵt−q are the white noise terms associated with the time series at time t, \\nt-1, t-2, ... , t-q. \\n• \\nθ1,θ2,...,θq are the moving average constants. \\nFor example, if we consider MA(1) model, in this model the present value of the time series \\nwill only depend on a single past error term and the time series becomes: \\nXt=c+ϵt+θ1.ϵt−1 \\nFrom this observation we can also conclude one of the most important aspects of moving \\naverage models that the higher the value of the order of moving average model (q), the model \\nwill have longer memory and dependence on the past values. \\nInterpretation of MA model: \\nThere is a difference in the shock wave that is seen in the MA model and AR model that we \\ncan mention which might help us get a better understanding how MA and AR model differ. For \\na better understanding let\\'s look at the AR model\\'s general form as well: \\nXt=c+ϕ1.Xt−1+ϕ2.Xt−2+...+ϕp.Xt−p+ϵt \\n• \\nFirst that the past noise term ϵt−1 affects the MA model\\'s present value Xt directly as \\nwe can see in the above equation of the MA model but in AR model the past noise \\nterm(ϵt−1) have an indirect influence on the present AR model value(Xt) since the AR \\nmodel equation depends on the previous value of the model(Xt−1) and the previous \\nmodel value depends on it\\'s noise term(ϵt−1). \\n• \\nThe MA model works a a finite impulse model, which means that the current noise \\nvalue affects the present value of the model as well as \"q\" further values, as the moving'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 5}, page_content=\"average models only depend on q terms in the past. Whereas AR models acts as infinite \\nimpulse model since the current noise affects infinite values of the model in the future. \\nIn AutoRegressive model ϵt value affects the Xt term which affects the Xt+1 term and \\nso on. \\nConcept Related to Moving Average: \\nNow let's discuss about some of the concepts that can help us in understanding the moving \\naverage model in a better way: \\n• \\nStationarity: Stationarity is the principle of time series data that conveys that the \\nstatistical properties of the data doesn't change with time, the mean of the data remains \\nthe same or we can also say that the data fluctuates around a certain value, the standard \\ndeviation of the time series data nearly remains constant, and there must not be any \\nseasonality in the time series data or there is no periodic behavior in the data. We can \\ncheck for the stationarity of the dataset visually as well as through Augmented Dickey-\\nFuller(ADF) Test. We consider stationarity to be one of the most important aspect that \\nthe time series data must possess in order to be accepted by the models that are applied \\nto time series data for accurate modelling. \\n• \\nDifferencing: Differencing is one of the most important steps to consider during time \\nseries analysis, after taking a peek at the original time series data, if the data is not \\nstationary and contains a lot of trends then differencing must be considered since for \\naccurate time series data analysis the data must be stationary. In regular differencing \\nthe current time series data is subtracted by the previous data point. Δyt=yt−yt−1Δyt=yt\\n−yt−1, this method removes trends from the data, making it suitable for modelling. \\n• \\nWhite Noise: White noise is the error term which has the mean of zero and a constant \\nstandard deviation with no correlation of the data points with each other. White noise \\nacts as a benchmark in the forecasting process through time series modelling, if the \\nforecast error is nor white noise further modifications could be performed on the model, \\nbut if it reaches a state such that the forecast errors are white noise then the model would \\nneed no further improvements. The value of white noise series are random and \\nunpredictable therefore if any time series data is a white noise then there is no method \\nto model or forecast it.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 6}, page_content=\"White noise time series with mean = 0 and standard deviation = 1 \\n• \\nACF Plot: Autocorrelation Function plot or the ACF plot is the plot of correlation \\nbetween the time series and its lagged version. It shows how similar the time series is \\nwith it's different lagged values. Here the lag term is a fixed time displacement, in the \\nACF plot the x-axis is the lagged time series and the y-axis is the correlation which \\nranges from -1 to 1. \\nAdvantages and Disadvantages of Using MA Model \\nThere are certain advantages and disadvantages of using a moving average model that \\nwe must pay attention to in order to achieve better results in modelling and forecasting \\nthe time series data. \\n \\n \\nAdvantages \\n• \\nNoise Reduction: Moving average models are effective in smoothing out the noise \\nwhich is present in the time series data, thus, it helps in reducing the short term \\nfluctuations in the time series data. \\n• \\nStationarity: Moving average models within itself assumes that the time series data is \\nstationary which is a primary requirement in the time series analysis. \\n• \\nEase of Understanding: It is not that tough to understand how the moving average \\nmodels work in comparison to some of the other time series forecasting models. The \\norder of the moving average model is the number of previous error terms on which the \\ncurrent value of the time series depends. \\n• \\nCombination of models: The moving average models could be easily combined with \\nautoregressive and integrated models and the whole of ARIMA modelling could be \\napplied on the time series data.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 7}, page_content=\"Disadvantages \\n• \\nAssumption of Stationarity: In moving average models it is already assumed that the \\ntime series data is stationary, but in reality, most of the real world data are not stationary. \\nTherefore, in order to convert the time series data into stationary data information loss \\nmight happen. \\n• \\nLimited Forecasting Range: Moving average models are suitable for short term \\nforecasting, as the time increases model's forecasting capabilities decreases. \\n• \\nSensitivity to Outliers \\n• \\nIdentification of Model Order: If the model order is not chosen correctly the model \\nmight not be able to predict the time series data effectively. \\nConclusion \\nHence, we can conclude that analysis of the time series data with moving average model \\nis possible but is only suitable for short period of time and the predictions are not good \\nas the time span increases. \\n \\nWhat Are Unit Root Tests? \\nA Unit Root Test is a statistical method employed in econometrics to determine whether a time \\nseries dataset is non-stationary and contains a unit root. A unit root indicates that a variable is \\naffected by random shocks and tends to return to its mean over time, suggesting a lack of long-\\nterm trend or stability. These tests are used in econometrics to analyze economic data. \\n \\nYou are free to use this image on your website, templates, etc..   \\nStationary time series data is crucial for accurate modeling and forecasting in statistical \\nanalysis. Hence, researchers, economists, and analysts employ the unit root test to confirm if \\nstatistical properties like mean and variance have remained constant over time. If a series is\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 8}, page_content='non-stationary (contains a unit root), it can lead to misleading regression results and unreliable \\nforecasts. It happens because the statistical properties of non-stationary data change over time. \\nKey Takeaways \\n• \\nA unit root test refers to an econometric measure that aids researchers in identifying \\nwhether a time series is stationary or non-stationary. \\n• \\nSome of the standard methods are the Augmented Dickey-Fuller (ADF), Dickey-Fuller \\n(DF), and Phillips-Perron (PP) tests. \\n• \\nRejecting the null hypothesis of a unit root test indicates stationarity, making the data \\nsuitable for various time series models and analyses. \\n• \\nSuch tests are critical as they ensure the validity of statistical analysis, improve \\nforecasting accuracy, and provide a solid foundation for economic research and \\npolicymaking. \\nUnit Root Tests Explained \\nUnit root tests are essential tools in time series analysis. They are used to determine whether a \\nvariable is non-stationary (has a unit root) or stationary. A non-stationary variable (as the name \\nsuggests) is one where the mean, variance, or autocorrelation changes over time. A stationary \\nvariable is one where statistical property remains unchanged over time. \\nThere are many unit root tests in econometrics and time series analysis, as discussed below: \\n1. Augmented Dickey-Fuller (ADF) Test: In the context of the ADF test, a unit root \\nsuggests that the series follows a random walk pattern, where changes from one period \\nto the next are unorganized and unpredictable. \\n2. Dickey-Fuller Test (DF) Test: This is the simpler version of the ADF test, which does \\nnot include additional lagged differences in the regression equation. \\n3. Phillips-Perron (PP) Test: Similar to ADF, the PP test examines a unit root and \\nrectifies errors like autocorrelation and heteroskedasticity in the given series. It is \\nespecially useful for analyzing non-normal data or data that contains outliers since it is \\nbased on nonparametric regression. Nonparametric regression does not make any \\nassumptions about the underlying distribution of the data in question. \\n4. Elliott-Rothenberg-Stock (ERS) Test: This test is specifically designed to handle \\nstructural breaks in time series data, allowing for a more robust analysis in the presence \\nof such noise. Structural breaks refer to changes in underlying trends or patterns of a \\ntime series.  \\n5. Zivot-Andrews Test: It is used when there might be a single structural break in the \\ndata. It is an extension of the ADF test that allows for a structural break at an unknown \\npoint in the series. A structural break is a sudden and permanent change in the level or \\ntrend of a time series.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 9}, page_content='Examples \\nA unit root test makes the analytical process seamless and efficient. Let us understand its \\napplication in certain scenarios. \\nExample #1 \\nSuppose Laura, the sales head of ABC Co., uses the unit root test to analyze time series datasets \\nfor one of her retail stores. In this case, she wishes to analyze the monthly sales data. She \\napplies the Augmented Dickey-Fuller (ADF) test to the sales data. The purpose of this test is \\nto determine whether the data exhibits a unit root, indicating a random walk and non-stationary \\nbehavior, or if it is stationary over time. \\nThe unit root test null hypothesis of the ADF test asserts that unit roots exist in the time series \\nsample. If the calculated test statistic is significantly lower than the critical values, the null \\nhypothesis can be rejected. This rejection implies that the data is stationary, without a unit root, \\nmaking it valuable for accurate forecasting and understanding the underlying patterns in the \\nsales data. \\nNow, let us see what Laura achieves by doing this. She ensures that the sales data is stationary \\nbefore making important decisions. This is because stationary data will likely be more accurate, \\nimproving the quality and relevance of business decisions. \\nExample #2 \\nSuppose the stock price movements of a specific stock in the last ten years without a constant \\ntrend are: \\nTime \\nStock Price \\n∆ Stock Price ($) \\n1 \\n$78 \\n \\n2 \\n$77 \\n-1 \\n3 \\n$81 \\n4 \\n4 \\n$87 \\n6 \\n5 \\n$85 \\n-2'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 10}, page_content='Time \\nStock Price \\n∆ Stock Price ($) \\n6 \\n$89 \\n4 \\n7 \\n$92 \\n3 \\n8 \\n$95 \\n3 \\n9 \\n$92 \\n-3 \\n10 \\n$94 \\n2 \\nSince the series has no constant trend, one can use the formula δYt-1＋ut to find the time series. \\nUsing this test, analysts identify patterns in price movements, determining whether such data \\nis stationary or non-stationary. It enables them to make decisions and market predictions. \\nApplications \\nListed below are some ways in which the unit root tests can be used: \\n• \\nIt is used for forecasting economic variables by establishing the order of integration. \\n• \\nIt helps analyze the long-term behavior of economic variables. \\n• \\nUnit root tests enable the examination of stock prices, exchange rates, and other \\nfinancial variables to assess future trends in these areas. \\n• \\nThese tests are applied to macroeconomic variables such as GDP, inflation, \\nand unemployment rates to understand their long-term patterns and relationships. \\n• \\nThey are used with asset pricing models to determine the stationarity of the variables \\nused in these models. \\n• \\nEnvironmental studies use these tests to analyze time series data related to pollution, \\nclimate, and other environmental factors. \\n• \\nMonitoring, controlling, and improving the quality of products in manufacturing over \\ntime is possible by studying the results obtained from unit root tests. \\n• \\nA major application that helps on a macroeconomic level is the analysis of patterns in \\ndisease prevalence, patient outcomes, or healthcare costs. \\nHowever, like other statistical techniques, this measure is also prone to certain limitations. \\nPrimarily, its outcomes can be sensitive to the sample size, leading to different results even \\nwith minor variations in input variables. Also, it assumes that the underlying process is linear, \\nwhich may not always be the case. It even fails to provide information about the order of \\nintegration or the presence of structural breaks in the data. \\nFurther, its interpretation is quite challenging and requires strong econometrics knowledge. \\nMoreover, the outcomes may not always be definitive, requiring extensive analysis and testing \\nwith other methods. \\nStill, unit root tests are used extensively in situations where time series analysis is needed. \\nHence, using it in conjunction with other testing methodologies may prove wise. \\nImportance'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 11}, page_content='Unit root tests are essential tools in time series analysis and econometrics. They play a crucial \\nrole in determining whether a given time series dataset is stationary or non-stationary. Its \\nimportance can be outlined as follows: \\n1. Critical for Time Series Modeling: It facilitates employing time series models such \\nas Vector Auto-Regression (VAR) and Auto-Regressive Integrated Moving Average \\n(ARIMA), which requires the data to be stationary, showing constant mean and \\nvariance over time. \\n2. Avoids Spurious Regression: Since non-stationary time series can lead to false \\nregression outcomes, where unrelated series appear correlated simply because they both \\nhave trends, stationary testing helps identify and address this issue. \\n3. Enhances Forecasting Accuracy: The stationary series tend to exhibit more \\npredictable patterns, making them easier to forecast accurately. Hence, the unit root \\ntests assist analysts in selecting appropriate models for such analysis. \\n4. Facilitates Policy Formulation and Economic Research: In the field of economics, \\nsuch tests are indispensable for making policy decisions and economic research that \\nrely on interpreting the underlying patterns in economic variables identified through \\nthis test. \\n5. Prevents Misinterpretation: These tests provide a systematic approach to assess the \\nstationarity of a time series, saving analysts from misinterpreting results or drawing \\nfalse conclusions about data patterns. Marketing analysts, financial analysts, and \\nresearchers are some examples of professionals who use this testing method to their \\nadvantage. \\n6. Cointegration Analysis: Such tests are fundamental in cointegration analysis that \\nhelps understand the various equilibrium relationships among economic variables. \\nCointegration analysis is useful for identifying long-run relationships between the given \\ntime series, which helps reduce or eliminate spurious regression. \\nImpact of Unit Root on Estimating Model Parameters \\nThe presence of a unit root in a time series can significantly impact the estimation of model \\nparameters, particularly in econometric and statistical analyses. Here’s why it matters: \\n1. Non-Stationarity and Mis-Specification: A unit root indicates that the series is non-\\nstationary, meaning its statistical properties like mean and variance change over time. \\nModels that assume stationarity, such as ordinary least squares (OLS), may become \\nmis-specified, leading to unreliable estimates. \\n2. Biased and Inefficient Estimates: When a unit root is present but ignored, parameter \\nestimates can become biased and inefficient. For example, regression coefficients may \\nnot converge to their true values as the sample size increases. \\n3. Spurious Relationships: A non-stationary series with a unit root can exhibit spurious \\nrelationships. In such cases, high correlations may appear between unrelated variables, \\nleading to misleading conclusions.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 12}, page_content=\"4. Impact on Hypothesis Testing: Standard statistical tests, like t-tests and F-tests, may \\nlose their validity in the presence of unit roots. Critical values used to assess \\nsignificance may no longer apply, increasing the likelihood of Type I or Type II errors. \\n5. Long-Term Impact on Models: Models like ARIMA (AutoRegressive Integrated \\nMoving Average) specifically account for unit roots by differencing the series. Ignoring \\nthe unit root can hinder the model's ability to accurately capture the underlying process. \\nTo address these challenges, it’s essential to: \\n• \\nTest for unit roots using methods like the Augmented Dickey-Fuller (ADF) or Phillips-\\nPerron tests. \\n• \\nApply transformations, such as differencing or detrending, to achieve stationarity. \\n• \\nUse models explicitly designed for non-stationary data, like cointegration models or \\nerror-correction models. \\n \\nTests for Stationarity in Time Series — Dickey Fuller Test & Augmented Dickey \\nFuller(ADF) Test \\n \\nDickey Fuller Test \\nDickey Fuller test is a statistical test that is used to check for stationarity in time series. This is \\na type of unit root test, through which we find if the time series is having any unit root. \\n \\nUnit root is a feature of time series that indicates if there is any stochastic trend in the time \\nseries that drives it away from its mean value. Presence of unit root makes a time series non-\\nstationary and as a result it leads to difficulties in deriving statistical inferences from the time \\nseries and future predictions. \\n \\nDickey Fuller test assumes a AR(1) type time series model and it is represented mathematically \\nas, \\n \\n \\nAfter we substract yt-1 from both the side, we get:\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 13}, page_content='where, \\n \\nµ: Constant \\n \\nϕ: Co-efficient \\n \\nyt-1: Value in the time series at lag of 1 \\n \\nEt: Error component \\n \\nThe test statistic formula is: \\n \\n \\nAugmented Dickey Fuller(ADF) Test \\nAugmented Dickey Fuller(ADF) test is an extension of Dickey Fuller test for more complex \\nmodels than AR(1). The primary difference between the two tests is that the ADF is utilized for \\na larger sized set of time series models which can be more complicated. \\n \\nAugmented Dickey Fuller test assumes a AR(p) type time series model and it is represented \\nmathematically as, \\n \\n \\nAfter we substract yt-1 from both the side, we get:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 14}, page_content='ADF is the same equation as the DF with the only difference being the addition of differencing \\nterms representing a larger time series. \\n \\nThe test statistic formula is: \\n \\n \\nAssumptions \\nThe test is conducted under following assumptions: \\n \\nNull Hypothesis (H0): There exists a unit root in the time series and it is non-stationary. Unit \\nroot = 1 or δ = 0 \\nAlternate Hypothesis (H1): There exists no unit root in the time series and it is stationary. Unit \\nroot < 1 or δ < 0 \\nCondition to reject H0 and accept H1 \\nIf the test statistic is less than the critical value or if the p-value is less than a pre-specified \\nsignificance level (e.g., 0.05), then the null hypothesis is rejected and the time series is \\nconsidered stationary. \\n \\nIf the test statistic is greater than the critical value, the null hypothesis cannot be rejected, and \\nthe time series is considered non-stationary. \\n \\nThe critical value is found from the Dickey Fuller table (similar to t-table that we use for t-test, \\nwe have a table with critical values for Dickey Fuller test). \\n \\n \\nUnit Root Tests in Time Series Analysis: Detailed Explanation \\nIn time series analysis, determining whether a series is stationary or has a unit root is critical for \\nbuilding accurate models. The presence of a unit root indicates non-stationarity, which can lead to \\nspurious regression results. To detect unit roots, several statistical tests are commonly used, including: \\n1. Dickey-Fuller (DF) Test \\n2. Augmented Dickey-Fuller (ADF) Test'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 15}, page_content='3. Phillips-Perron (PP) Test \\n4. KPSS (Kwiatkowski-Phillips-Schmidt-Shin) Test \\nLet’s elaborate on each of these tests. \\n \\n1. Dickey-Fuller (DF) Test \\nObjective: \\n• \\nThe Dickey-Fuller Test checks for the presence of a unit root in a time series. \\nHypotheses: \\n• \\nH0: The series has a unit root (Non-stationary) \\n• \\nH1: The series does not have a unit root (Stationary) \\nDecision Rule: \\n• \\nIf the test statistic is less than the critical value, reject H0 and conclude the series is stationary. \\n• \\nIf the test statistic is greater than the critical value, fail to reject H0 (series has a unit root). \\nLimitations: \\n• \\nDF test assumes no autocorrelation in the error term. \\n• \\nIt may not perform well with autocorrelated errors. \\n \\n2. Augmented Dickey-Fuller (ADF) Test \\nObjective: \\n• \\nThe ADF Test is an improved version of the Dickey-Fuller test that accounts for higher-order \\nautocorrelation.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 16}, page_content='Hypotheses: \\n• \\nH0: The series has a unit root (Non-stationary) \\n• \\nH1: The series does not have a unit root (Stationary) \\nDecision Rule: \\n• \\nSimilar to the DF test, check the test statistic against critical values. \\nAdvantages: \\n• \\nControls for serial correlation by including lag terms. \\n• \\nMore reliable for larger datasets. \\nLimitations: \\n• \\nChoosing the right number of lags is essential. \\n• \\nOverdifferencing may remove useful information. \\n \\n3. Phillips-Perron (PP) Test \\nObjective: \\n• \\nThe Phillips-Perron Test also tests for a unit root, but it makes non-parametric adjustments to \\nthe test statistics to correct for heteroskedasticity and autocorrelation without adding lagged \\nterms. \\nHypotheses: \\n• \\nH0: The series has a unit root (Non-stationary) \\n• \\nH1: The series does not have a unit root (Stationary)'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 17}, page_content='Key Difference from ADF: \\n• \\nInstead of adding lagged differences, the PP test directly adjusts the t-statistic using non-\\nparametric techniques to correct for autocorrelation and heteroskedasticity. \\nDecision Rule: \\n• \\nReject H0 if the test statistic is lower than the critical value. \\nAdvantages: \\n• \\nSuitable for large datasets with heteroskedasticity. \\n• \\nNo need to specify the lag length. \\nLimitations: \\n• \\nCan be less effective in small samples. \\n \\n4. KPSS (Kwiatkowski-Phillips-Schmidt-Shin) Test \\nObjective: \\n• \\nUnlike the previous tests, the KPSS Test assumes the null hypothesis of stationarity and tests \\nfor the presence of a unit root as the alternative hypothesis. \\nHypotheses: \\n• \\nH0: The series is stationary \\n• \\nH1: The series has a unit root (Non-stationary) \\nDecision Rule:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 18}, page_content='• \\nIf the test statistic exceeds the critical value, reject H0 and conclude the series is non-stationary. \\n• \\nIf the test statistic is less than the critical value, accept H0 and conclude the series is stationary. \\nAdvantages: \\n• \\nComplements other tests like ADF and PP by providing a different perspective. \\n• \\nEffective for identifying mean-reverting behavior. \\nLimitations: \\n• \\nSensitive to lag selection. \\n \\nComparison of Unit Root Tests \\nCriteria \\nDF Test \\nADF Test \\nPP Test \\nKPSS Test \\nNull Hypothesis \\nUnit Root \\nUnit Root \\nUnit Root \\nStationarity \\nAlternative Hypothesis \\nStationarity \\nStationarity \\nStationarity \\nUnit Root \\nAccounts for \\nAutocorrelation \\nNo \\nYes \\nYes \\nNo \\nAdjusts for \\nHeteroskedasticity \\nNo \\nNo \\nYes \\nNo \\nLag Selection Required \\nNo \\nYes \\nNo \\nYes \\nSuitable for Small \\nSamples \\nModerate \\nGood \\nModerate \\nModerate \\nBest for \\nSimple \\nData \\nAutocorrelated \\nData \\nHeteroskedastic \\nData \\nConfirming \\nStationarity'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 0}, page_content='Unit 1 \\nIntroduction to Time Series Analysis \\n• \\nLearning Objectives \\n• \\nIntroduction \\n• \\nFunctional relationship \\n• \\nClassification of time series \\n• \\nComponents of time series \\n• \\nMathematical model of time series \\n• \\nUtility of time series \\n• \\nRequirement of time series \\n• \\nApplications of time series \\n• \\ntime series data and cross-sectional data, difference between time series and cross-\\nsectional data, time series and stochastic process, \\n• \\nMeans, variances, covariance, stationarity, importance of stationarity in time series \\nanalysis \\n• \\nwhite noise process, random walk  \\n• \\nelementary time series models with zero mean \\n• \\nmodel evaluation techniques: Bias, MAD, MSE, MAPE \\n• \\nSummary \\n• \\nSuggested Readings \\n \\nLearning Objectives \\n  \\nThe objective of this module is to give basic introduction of Time series analysis and explain its meaning \\nand concepts to understand its vast application areas. Classification of time series and components of \\ntime series will be discussed in detail. Mathematical model of time series. Utility, requirement of time \\nseries and its application will also be discussed for in depth knowledge of this topic. \\n  \\n Introduction \\n  \\nIn general, Series is a sequence of observations in a specific order. Similarly, Time series is a sequence \\nof observations in specific order but these observations are time dependent. Actual time series is \\nrealization of stochastic process. In different sectors like Economics, Commerce and Environment \\nevents happen over a period of time. For example- temperature of a day at different time interval and \\nprice of commodity in one month to other month or it may be day or year, production of crop varies \\nover year, production of an item in an industry increase or decrease depending on the demand of the'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 1}, page_content='product, sale of goods depend upon the price as well as need of the product over the time like in change \\nof technology, consumption of items increase with increase in earning over time or decrease due to lack \\nof money like visit to hotels depends upon person’s earning that varies over time. These examples show \\na series of data which are dependent on time, this measurement of variable at different time point is \\nknown as “Time interval” in literature terms. Time interval may be hours, days, quarters, months and \\nyears. In modern literature time series is also referred as both data and process. Hence time series has a \\ngreat importance in Business, Economics and other areas. This is the main reason for the development \\nof many statistics tools specially for these areas exist in literature. Even a particular subject named as \\nEconometrics originate to cater the need of this topic. Econometrics is now among the most widely \\ntaught subject in the colleges and other institutions due to importance of happening of events over a \\nperiod of time. \\n  \\nDefinition: \\n  \\n“A Time Series is a set of statistical observations arranged in chronological order” by Morris Hamburg. \\n“A time series may be defined as a collection of reading belonging to different time periods, of some \\neconomic variables or composite of variables” by Ya-lun Chou. \\n“Time series is a chronological sequence of observations of quantitative variables that are recorded \\nsuccessively at regular and specified time interval”. \\n  \\n Classification of the Time series: \\n  \\nTime series can be classified in two types, first is according to dependency on time and second is \\naccording to variable numeracy. \\n Dependency on time can be further categorized into: \\n1. Discrete time series \\n2. Continuous time series  \\nVariable numeracy has further two categories \\n1. Univariate time series \\n2. Multivariate time series \\n We will now discuss these classification in detail: \\n❖ Discrete time series: A Time series is discrete time series when variable dependency on time \\nis of discrete form. A variable is said to be discrete if it takes only integer values like days, \\nmonths etc. For example- closing price of daily stock market. \\n❖ Continuous time series: A Time series is continuous time series when variable depends on \\ntime is of continuous nature. A variable is said to be continuous if it takes values in continuous \\nform like in second, minutes etc. For example- hourly reading of temperature.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 2}, page_content='❖ Univariate time series: A time series is univariate time series when there is only one type of \\nstudy variable or one characteristics under consideration. For example: share price of one \\ncompany. \\n❖ Multivariate time series: A Time series is multivariate time series when there is more than \\none type of study variable that is of interest in time series. For example- share price of one \\ncompany, share price of other company. \\n \\n \\n \\nComponents of time series: \\nStudy variable take different values in a particular time series. This difference in value is not due to \\nonly one component like time but affected by more than one component or multiple components. These \\nmultiple components pull up and down the values of the characteristics under study. For example: the \\ncrop yield depends on weather condition, seed quality, land quality, fertilizer etc. Here crop yield is \\nstudy variable and weather condition, seed quality, land quality are other multiple components that are \\nalso responsible for the yield of the crop. \\n \\n \\n \\nThese multiple components are classified into four categories. Such as: \\n1) Secular Trend (long term movement) \\n2) Seasonal variation (short term movement) \\n3) Cyclic variation \\n4) Random or Irregular Movements \\n  \\nThese four categories are known as components of time series. Now let’s discuss components of time \\nseries one by one with examples.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 3}, page_content='• \\n1) Secular trend: \\n  \\nSecular trend or generally trend is a long term movement. In general, Trend shows tendency of the time \\nseries data in long term period. This tendency may be downward and upward. It should be kept in mind \\nthat this tendency of upward and downward movement should not remain same throughout the time \\nspan. It is also possible that it can be observed in different time section or time span. However one can \\nsay that the overall tendency of the series seem like moving upward or downward but in actual there \\nare many factor that persist for a long period. Tendency depends on the effects of the factor. If effect of \\nfactors on time series data is of increasing then it shows upward tendency, if is on decreasing then it \\nshows downward tendency. \\n Trend consists of Long term effects. Long term cannot be defined exactly because in some cases 2 year \\ntime may be enough and for some cases it is not enough. \\n For some cases 5 minutes is a very long period, for other case it may not be appropriate. The term of \\nlong or short period of time depends on the nature or objective of the data. In some cases, a period of \\nhours can be considered as very large while in other cases even the period of years is not sufficient to \\nbe named as long time. For example if data of agriculture production \\n  \\nof 24 month shows increment in the growth of the crop then it is not considered as secular trend for 2 \\nyears, the count of bacterial population of a culture in every five minutes, if this tendency of increment \\npersist for a week then it is a secular trend. One important thing is that the values for short period (may \\nbe 2-3 years in some cases) are mainly affected by cyclic variations. Hence the values are not able to \\nreveal true trend. In order to solve this problem, one should consider the multiple cycle periods to see \\nthe impact of cyclic variations on the values. For some cases, due to nature of  the data like increment \\nof bacterial population persists due to strong germicide in an hour then reading in every five minutes or \\nin seconds would lead to a general pattern that can be termed as a secular trend. \\n This tendency of the data may be linear and nonlinear trend. It depends on the nature of the data. If the \\ntime series values are plotted on the graph with more concentration around a straight line then trend \\npattern of time series values are said to be linear on the other hand if the time series values are not close \\nto straight line then it is called non-linear trend like increase in the price of gold, crude oil in the \\ninternational market is not constant and varies with different phases of time. Hence the trend of time \\nseries will help you to get a general idea about the pattern of the behavior of the data under \\nconsideration. This will help in forecasting and future planning of different sectors like business,'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 4}, page_content='weather and economy based on previous values. With the use of trend analysis one can compare two or \\nmore time series over different time periods and draw important conclusions based on them. \\n  \\n• \\n2) Seasonal variation: \\n  \\nSeasonal variation is a short term movement in a time series. Short term movement means observational \\ndata collects in less than one year of time period i.e. data collected monthly, quarterly, weekly, daily, \\nhourly etc. If collected data are annual then there is no seasonal variation. As the name suggests, \\nseasonal variation means variation that occur due to change in season and natural forces in any study \\nvariable. For example prices, production and consumption of any commodities, sales and profit in any \\ndepartmental store etc. \\n  \\nSome variations in data are due to natural forces like seasons. For example: sale of umbrella increases \\nin rainy season, consumption of ice-cream increases in summer, price of woolen increases in winter. \\nSome variation are due to man-made convention such as sale of jewellery and price of clothes go up \\ndue to marriage season and in festival like Diwali, Christmas, and Durga Pooja. \\n  \\nThe following image shows sales of clothes changing in different seasons \\n \\n \\n• \\n3) Cyclic variation: \\nCyclic variation is a repeated pattern in a time period of a time series, this time period will be more than \\none year. The data of sale of ice cream for few years shows that the sale of ice-cream is high in summer \\nand low in winter. Therefore this data shows some repeated pattern in time series data, this pattern is \\nknown as cyclic variation . \\n  \\nGenerally cyclic variation shows in business cycle. Business cycle have four phases. Hence this is \\nreferred as four phase cycle such as prosperity, recession, depression and recovery. Each phase in \\nbusiness cycle persists for a very long term variation approximately 5 to 7 years. On the other side,'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 5}, page_content='cyclic variation may be short term and long term movement that depend on time period but time period \\nmust be greater than one year. \\n \\n• \\n4) Irregular component: \\n  \\nIrregular component is also known as random or residual component. Every time series must contain \\nthis fluctuation and this fluctuation cannot be removed from the data. Irregular component can be found \\nby removing all three components, so that irregular component is not affected by other three \\ncomponents of time series.  \\nIrregular component is beyond the control of human being and considered as unpredictable. This type \\nof fluctuation may be seen due to effect of factors like earthquake, wars, floods, famines, political unrest \\nrevolution, epidemics etc. \\nIrregular variation are unpredictable due to its accidental variation. For example- rise in prices of LPG \\ngas cylinder due to strike of workers etc. \\n \\n \\nMathematical model of time series: \\n  \\nIn analysis of time series, there are types of problems like to identify the components and their effect \\non the data sets, to isolate, analyze and measure them independently. In literature, there are some \\nmathematical model to decompose the time series into its components.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 6}, page_content='Additive model: Additive model of a time series can be expressed as: \\nYt=Tt+St+Ct+Rt \\nwhere: \\n• \\nYt = observed value at time t, \\n• \\nTt= trend component (captures long-term growth or decline)/ is trend value at time t. \\n• \\nSt = seasonal component (captures periodic fluctuations)/ is seasonality value at time t. \\n• \\nRt = residual or random component (captures irregular fluctuations)/ is random or irregular \\nvalue at time t. \\n• \\nCt= is cyclic value at time t. \\nAll four component of time series in additive model operate independently to each other. Thus, in \\nadditive model , there is no effect of one component to other component. Additive model can be used \\nto measure one or more component by elimination i.e. by subtraction. \\nFor example- time series decomposition of additive model with visualization as in the following image: \\n \\nMultiplicative model: \\n  \\nIf all component of time series operate proportionally to the general level of the series, multiplicative \\nmodel is appropriate. Multiplicative model can be expressed as: \\nYt=Tt×St×Rt×Ct \\nwhere: \\n• \\nYt = observed value at time t, \\n• \\nTt = trend component (captures long-term growth or decline), \\n• \\nSt= seasonal component (captures periodic fluctuations),'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 7}, page_content='• \\nRt= residual or random component (captures irregular fluctuations). \\n• \\nCt= cyclic value at time t. \\nOr  \\nYt is the value of time series at time t. \\nTt,St,Ct,Rt, and is the value of trend, seasonal ,cyclic and irregular component respectively. \\nMultiplicative decomposition of time series is same as the additive decomposition of logarithmic values \\nof the original time series that is: \\n \\nFor example: time series transform Multiplicative to Additive decomposition by using logarithmic with \\nvisualization is given in Figure 7. \\n It means that when the observations are related with each other in proportionate manner then by taking \\nlog of the observation we can convert the multiplicative model into additive model as it is easier to \\ndetect the components in additive models than multiplicative model. By taking log of observations one \\ncan smooth the curve. In practical cases, it is most widely used concept to take log of observations to \\ndetermine the model that fits in an appropriate manner on the observations. \\n Most of time series related to business and economic confirms to multiplicative model. Multiplicative \\nmodel are used in measure of one or more components i.e. by division. For example if trend value is \\nknown then isolate them: \\n= If data is annual then seasonal components is not there i.e. \\nFor example-assume birth time series decomposition of Multiplicative model with visualization as in \\nthe following image:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 8}, page_content='Hence from Figures 6-8, one can understand the mathematical model of time series components. One \\ncan choose an appropriate model based on the relationship among components in the data values. \\n  \\nUtility of time series: \\n  \\nUtility of time series is given as: \\n  \\n1) It helps in understanding past behavior of the time series: to understand the past behavior \\nof any time series, to analyze variation between data sets over a period of time. \\n2) It helps in future prediction: by observing past behavior of time series data we may see \\nhow observation are varying. According to behavior of data one can use this information for \\nforecasting. We know that time series depend on past data. For better prediction of values one \\nrequire long period data. \\n3) It helps in understand current situation of the problem: the actual performance can be \\nanalyzed by taking difference between expected performance and cause of variation of the data. \\n4) It facilitates comparisons between different time series \\n  \\nRequirements of time series: \\n  \\nTime series have following requirements: \\n  \\n1) Data must consist of a homogenous set of values. \\n2) The data should be available for sufficiently long period. \\n3) Time gap between various values must, as far as possible be equal. \\n4) The gaps, if any, in data should be made up by interpolation.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 9}, page_content='Application of Time series: \\n  \\nTime series analysis has wide application area. Most important area of time series analysis is economic \\nand business. Some other application areas are: weather forecasting, pattern recognition, earthquake \\nprediction, mathematical science and mathematical finance. Time series analysis is mostly used in \\nforecasting or predication. \\n \\nTime Series Data vs. Cross-Sectional Data  \\nTime series data is data collected at regular intervals over time. On the other hand, cross-sectional \\ndata is a snapshot of a group of things or people at the same point in time. \\nFor example, a time series dataset of the number of cars sold each month over the course of 5 years \\nconsists of 60 data points (one for each month). Meanwhile, cross-sectional data is a dataset composed \\nof not only the number of cars sold in one month, but also information on the car model, price, color, \\nand other variables. \\nWhat is Time Series Data \\nTime series data allows you to track changes over time. It consists of observations on one or several \\nvariables over time—the most common frequencies being hourly, daily, weekly, monthly, quarterly \\n(every 3 months), and annual. \\nHere are two examples of time series data: \\n• \\nThe daily closing price of Apple’s stock over the course of a year. This data set consists of the \\nstock price recorded at the end of each trading day for 365 days. \\n• \\nThe monthly revenue of a Walmart over the course of one year. The data includes the total sales \\nfor the company recorded at the end of each month for 12 months. \\nIn both of these examples, we collect the data at regular intervals (daily or monthly) and cover a certain \\nperiod of time (a year). This allows us to see how the stock price or sales of the company change over \\ntime.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 10}, page_content='Time Series Data \\nYou can use time series data to identify patterns in financial data, and make predictions about future \\nvalues based on past behavior. \\nWhat is Cross-Sectional Data \\nCross-sectional data allows you to compare data at one point in time. It consists of observations of \\nmultiple variables at one specific point in time. \\nThe data reflects the characteristics of individuals at a single moment, rather than over a period of time. \\nHere are two examples of cross-sectional data: \\n• \\nA survey of households to learn about their saving and investment habits. The survey collects \\ndata on the types of investment products that households have, how much they save and invest, \\nand their attitudes toward risk. \\n• \\nA study of the financial performance of companies in the tech industry. The study collects data \\non the revenue, profits, debt levels, and market share of the companies. \\nBoth examples are ways to understand the financial characteristics of a group of people or companies \\nat a specific point in time.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 11}, page_content='Cross-Sectional Data \\nThis type of data does not provide information on how these characteristics change over time though. \\nDifference Between Cross-Sectional and Time Series Data \\nAttribute \\nCross-Sectional Data \\nTime Series Data \\nDefinition \\nData collected at a specific point in time, \\ncapturing information from multiple individuals, \\nentities, or observations. \\nData collected over a period of time, \\ncapturing information from a single \\nindividual, entity, or observation. \\nObservations Multiple observations at a single point in time. \\nSingle observation over multiple points in \\ntime. \\nFocus \\nComparing different individuals, entities, or \\nobservations at a specific time. \\nExamining changes in a single individual, \\nentity, or observation over time. \\nVariables \\nMultiple variables measured simultaneously for \\neach observation. \\nSingle or multiple variables measured over \\ntime for each observation. \\nAnalysis \\nTypically used for cross-sectional analysis, such \\nas comparing groups or identifying correlations. \\nCommonly used for time series analysis, \\nsuch as forecasting, trend analysis, or \\nidentifying patterns. \\nExamples \\nSurvey data collected from different households \\nat a specific point in time. \\nStock prices recorded daily over a period of \\nseveral years. \\n \\n \\nIntroduction to Time Series Analysis and key concepts'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 12}, page_content='Stationarity, Random walk, White noise, Time Series models and Evaluation of models. \\nIn this article, we are going to examine what is time series analysis?, its scope in the future? and key \\nconcepts of time series analysis. \\nTable of Contents: \\n1. Introduction: What is time series analysis and its importance? \\n2. What is stationarity in time series and its types? \\n3. White Noise & Random Walk \\n4. AutoCorrelation Function(ACF) & Partial auto correlation function(PACF) \\n5. Models: \\nAutoRegression(AR), \\nMoving \\nAverage(MA), \\nAutoRegression-Moving \\nAverage(ARMA) , Autoregressive–moving-average model with exogenous inputs (ARMAX) \\nand Auto Regressive Integrated Moving Average(ARIMA) \\n6. Model diagnostics \\n1] Introduction: \\nTime series analysis is a statistical technique that deals with time series data, or trend analysis. In Time \\nseries,data is in a series of particular time periods or intervals. \\nTime series analysis is used for various applications such as stock market analysis, pattern recognition, \\nearthquake prediction, economic forecasting, census analysis and so on. \\nA time series consists of the following components: \\n \\nImage showing Trend, Seasonality and Cyclicality (Photo by Panwar Abhash Anil )'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 13}, page_content='• \\nTrend: The trend shows the general tendency of the data to increase or decrease during a long \\nperiod of time. A trend is a smooth, general, long-term, average tendency. It is not always \\nnecessary that the increase or decrease is in the same direction throughout the given period of \\ntime. \\n• \\nSeasonality: Patterns that repeats frequently at regular intervals. For example: high sales every \\nweekend. \\n• \\nCyclicality: Cyclicality is where there is a repeating pattern but no fixed period. \\nScope of the Time Series Analysis: \\n• \\nStock Market Analysis \\n• \\nEconomic Forecasting \\n• \\nInventory studies \\n• \\nDemand Forecasting \\n• \\nSales Forecasting and more \\nTime Series and Stochastic Process'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 14}, page_content='2] Means, Variances, and Covariance in Time Series & Stationarity: \\n \\nMeans, Variances, and Covariance in Time Series'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 15}, page_content=''),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 16}, page_content='Stationary means that the distribution of the data does not change with time. \\n \\nStationary v/s Non-Stationary (Photo by Panwar Abhash Anil) \\n• \\nNo Trend: It is not growing or shrinking. \\n• \\nMean & Variance constant: The average distance of the data points from the zero line is not \\nchanging. \\n• \\nAutoCorrelation Constant: How each value in time series is related to its neighbors stays the \\nsame. \\n◦ Types of stationary: \\n• \\nStrong stationary: Entire distribution of data is time-invariant. \\n• \\nWeak stationary: mean, variance and autocorrelation are time-invariant (i.e., for \\nautocorrelation, corr[(X(t), X(t−τ )] is only a function of τ ) \\n◦ Test for stationarity: Augmented Dicky Fuller test'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 17}, page_content='• \\nNull hypothesis is that the time series is non-stationary. \\n• \\nAlternate hypothesis is that the time series is non-stationary. \\n• \\nDicky-Fuller test only used to test trend. \\n◦ Making time series stationary: \\nIdentifying whether a time series is stationary or not is very important. If it is stationary then we can \\nuse models that take assumptions that time series need to be stationary to predict the next values of the \\ntime series using historical data. If it is non-stationary then make it stationary on applying below \\ntransformations then use a model. \\n• \\nStationarity through differencing time series \\n• \\nTaking log of time series \\n• \\nTaking Square root of time series \\n• \\nTaking the proportional change (df.shift(1)/df) \\n3] White noise and random walk: \\nWhite Noise: A time series is white noise when sequence of uncorrelated random variables that are \\nidentically distributed. Stock returns are often modeled as white noise. Unfortunately, for white noise, \\nwe cannot forecast future observations based on the past — autocorrelations at all lags are zero. \\nWhite Noise is a series with: \\n• \\nConstant mean \\n• \\nConstant variance \\n• \\nZero autocorrelations at all lags \\nSpecial Case: if data has normal distribution, then white noise is termed as gaussian white noise. \\nRandom Walk: A random walk is another time series model where the current observation is equal \\nto the previous observation with a noise. \\n• \\nIn a random walk, today’s price is equal to yesterday’s price plus some noise. \\n• \\nCan’t forecast a random walk \\n• \\nIncidentally, if prices are in logs, the difference in log price is one way to measure return. \\n• \\nTo test whether the time series is random walk, you can regress current values on lagged values. \\nIf the slope coefficient (beta) is not significantly different from one then we cannot reject the \\nnull hypothesis that the series is a random walk. However if the slope is less than one we can \\nreject the null hypothesis. \\n4] AutoCorrelation Function & Partial auto correlation Function: \\nAutocorrelation: Autocorrelation is the correlation of a single time series with a lagged copy of itself. \\nIt is also called single correlation \\nACF is a complete auto-correlation function which gives us values of auto-correlation of any series \\nwith its lagged values. We plot these values along with the confidence interval. In simple terms, it \\ndescribes how well the present value of the series is related with its past values. A time series can have'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 18}, page_content='components like trend, seasonality, cyclic and residual. ACF considers all these components while \\nfinding correlations hence it’s a ‘complete auto-correlation plot’. \\nACF shows not only at one lag autocorrelation, but the entire autocorrelation function for different lags. \\nPACF is a partial auto-correlation function. PACF is a conditional correlation which gives the partial \\ncorrelation of a stationary time series with its own lagged values, regressing the values of the time series \\nat all shorter lags. It contrasts with the autocorrelation function, which does not control for other lags. \\n5] Models: \\nTime series models look at past patterns of data and attempt to predict the future based upon the \\nunderlying patterns contained within those data. \\n5.1) AR model: \\nIn an autoregressive model, we regress the values of the time series against previous values of the same \\ntime series. \\nAn autoregressive model predicts future behavior based on past behavior. It’s used for forecasting \\nwhen there is some correlation between values in a time series and the values that precede and succeed \\nthem. \\n \\nImage showing AR models (Photo by Panwar Abhash Anil) \\nThe order of the model is the number of times lags (p) used. and for stationary, -1<a1,a2,..,ap<1. If AR \\nparameter (p) is 0, then the process is white noise. \\n5.2] MA Model: \\nIn the MA model, we regress the values of the time series against the previous shocks/residual values of \\ntime series.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 19}, page_content='Image showing MA models (Photo by Panwar Abhash Anil) \\nThe order of the model is the number of times lags (q) used. and for stationary, -1<m1,m2,..,mq<1. If \\nMA parameter (p) is 0, then the process is white noise. \\n5.3] ARMA Model: \\nAn ARMA model is a combination of AR and MA models. The time series is regressed on the previous \\nvalues and the previous shock term. \\n \\nImage showing ARMA models (Photo by Panwar Abhash Anil) \\n5.4) ARMAX model: \\nAn ARMAX is a model of lagged dependent variable and lagged independent variable(s). One possible \\nextension to the ARMA model is to use exogenous. This means that we model the time series using \\nother independent variables as well as the time series itself. \\nThis is like a combination between an ARMA model and a normal linear regression model. \\n• \\nExogenous ARMA \\n• \\nUse external variables as well as time series \\n• \\nARMAX =ARMA + linear regression \\nIn principle, an ARMAX model is a linear regression model that uses an ARMA-type process [i.e. w(t)] \\nto model residuals: \\n \\nEquation of ARMAX (Photo by Panwar Abhash Anil) \\n5.5) ARIMA model: \\nARIMA model is actually a class of models that ‘explains’ a given time series based on its own past \\nvalues, that is, its own lags and the lagged forecast errors, so that equation can be used to forecast future \\nvalues. \\nWe cannot apply the ARMA model to non-stationary times series. We need to take the difference of the \\ntime series to make it stationary. Only then can we model it.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 20}, page_content='However, when we do this, we have a modal which is trained to predict the value of the difference of \\nthe time series. What we really want to predict is not the difference, but the actual value of the time \\nseries. \\nAn ARIMA model is characterized by 3 terms: p, d, q \\nwhere, \\n• \\np is the order of the AR term \\n• \\nq is the order of the MA term \\n• \\nd is the number of differencing required to make the time series stationary \\n6] Model diagnostics: \\nModel diagnostics to confirm our model is behaving well. To diagnose our model we focus on the \\nresiduals to the training data. \\nThe residuals are the difference between our model’s one-step-ahead predictions and the real values of \\nthe time series. \\n  \\n1. Mean Absolute Percentage Error (MAPE) \\nMAPE calculates the average of the absolute percentage differences between the model’s predictions \\nand the actual values. Therefore, this metric expresses the average error as a percentage of the actual \\nvalue. \\n \\nMAPE penalizes negative errors more heavily (when the predicted value exceeds the actual). This is \\nbecause the percentage error cannot exceed 100% for very low predictions, while there is no upper limit \\nfor higher predictions. Consequently, MAPE tends to favor models that underestimate rather than \\noverestimate. An example of using MAPE in a business context would be in evaluating the accuracy of \\nonline sales forecasting models, as well as in cash flow forecasting (financial projections) \\n \\n2. Mean Squared Error (MSE) \\nThis metric is widely used to evaluate regression models. It represents the average of the squared \\ndifference between the original and predicted values.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 21}, page_content='The importance of using MSE in identifying outliers and imbalances in the dataset. Furthermore, this \\nmetric is most suitable when the dataset has a normal distribution. MSE will always be non-negative \\nand in simpler terms, the lower the value, the better the fit. Implicitly understood, it indicates that the \\nsmaller the difference between the actual and predicted values, the smaller the trade-off between bias \\nand variance of the model. \\nAs previously explained, the downside of using MSE is that it is sensitive to large errors, as it squares \\nthe differences. \\nThe use of this metric in a business environment includes employing MSE in evaluating stock forecasts \\nand financial asset price predictions, to fine-tune investment strategies. \\n \\nTo optimize your forecast, whether moving average, exponential smoothing or another form of a \\nforecast, you need to calculate and evaluate MAD, MSE, RMSE, and MAPE. With Excel 2016 or later, \\nthis is easy to do. \\n3. The Mean Absolute Deviation (MAD) is the sum of absolute differences between the actual \\nvalue and the forecast divided by the number of observations. MAD is the same as MAE, Mean \\nAbsolute Error. \\n \\n4. Mean square error (MSE) is probably the most commonly used error metric. It penalizes \\nlarger errors because squaring larger numbers has a greater impact than squaring smaller \\nnumbers.  The MSE is the sum of the squared errors divided by the number of observations. \\n \\n5. The Root Mean Square Error (RMSE) is the square root of the MSE. RMSE is used to \\nconvert MSE back into the same units as the actual data. \\n \\n6. Mean Absolute Percentage Error (MAPE) is the average of absolute errors divided by actual \\nobservation values. MAPE should not be used if there are zeros or near-zeros in the actual \\ndata. SMAPE, Symmetric Mean Absolute Percent Error, can be used where there are zero \\nor near-zeros values in the actual data.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 22}, page_content='7. Symmetric Mean Absolute Percent Error (SMAPE) is an alternative to Mean Absolute \\nPercent Error (MAPE) when there are zero or near-zero values in your actual observations. \\nSMAPE self-limits to an error rate of 200%, reducing the influence of zero or near-zeros \\nobservations. SMAPE is the forecast minus actuals divided by the sum of forecasts and actuals \\nas expressed in this formula: \\n \\n \\n8. Mean Absolute Error: \\nHow large the residuals are and so how far our predictions are from the true values. Then calculate mae \\nof the residuals \\nIf the model fits well the residuals will be white gaussian centered on zero. \\n \\nEvaluating Time Series Models \\nWhen Evaluating Time Series Models, it’s super important to consider various metrics to determine \\ntheir accuracy and performance. \\nHere are some key factors to assess: \\n• \\nMean Absolute Error (MAE) provides an average of the absolute errors between predictions \\nand actual values.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 23}, page_content='• \\nMean Squared Error (MSE) measures the average of the squared errors, emphasizing larger \\nerrors more than MAE. \\n• \\nRoot Mean Squared Error (RMSE) is the square root of MSE, giving us an interpretable value \\nin the same units as the data. \\n• \\nMean Absolute Percentage Error (MAPE) calculates the percentage not the same between \\npredictions and actual values, giving ideas into the model’s performance relative to the data. \\nTo improve the evaluation process, consider using techniques like cross-validation to test the model on \\ndifferent subsets of data. \\nThis helps validate the model’s strongness and generalizability. \\nChoosing the Right Time Series Model \\nWhen it comes to time series analysis, selecting the appropriate model is critical for accurate \\nforecasting. \\nHere are some key considerations to help us choose the right time series model: \\n• \\nUnderstand the Data: Before choosing a model, it’s super important to thoroughly understand \\nthe patterns present in the data. Looking at the trends, seasonality, and cyclicality can guide us \\ntowards selecting the most suitable model. \\n• \\nIdentify Stationarity: Ensuring that the data is stationary is important for many time series \\nmodels. Stationarity implies that the statistical properties of the data remain constant over time, \\nmaking it easier to predict future values. \\n• \\nChoose the Right Technique: Based on the characteristics of the data, we can opt for techniques \\nsuch as moving averages, exponential smoothing, or more advanced models like ARIMA \\n(AutoRegressive Integrated Moving Average). \\n• \\nInvestigate Advanced Models: To investigate more into time series analysis, it’s beneficial to \\ninvestigate resources from reputable sources such as Towards Data Science and \\nthe StatsModels library for Python. \\nBy following these steps and using the appropriate time series models, we can make smart decisions for \\nforecasting future trends. \\n \\nSummary \\n  \\nThis module is an introduction to time series. Here we give a basic introduction of Time series analysis \\nand attempt to explain its meaning, concepts that help in understanding its vast application areas. \\nClassification of time series like univariate, multivariate, discrete and continuous are discussed and their \\ndifferences analyzed from one another. After that components of time series like secular trend, seasonal, \\ncyclic and irregular are discussed in detail with graphical understanding so that they are easy to learn \\nand differentiate from one another. Mathematical model of time series like additive model, \\nmultiplicative model and mixed models are shown with their mathematical formulation, to know about \\nthe importance of time series and its applications. Utility, requirement of time series and its application \\nare discussed for in depth knowledge of this topic.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 24}, page_content='Suggested Readings \\n  \\n• \\nGupta, S. P., Statistical Methods, Sultan Chand & Sons, New Delhi, 2012. \\n• \\nGupta, S. C. and Kapoor, V. K., Fundamentals of Applied Statistics, Sultan Chand & Sons, New \\nDelhi, 2009. \\n• \\nSharma, J. K., Business Statistics, Vikas Publishing House, 2014. \\n• \\nTsay, R. S., Time Series and Forecasting: Brief History and Future Research, Journal of the \\nAmerican \\n• \\nStatistical Association, Vol.95, pp. 638-643, 2000. \\n• \\n https://medium.com/analytics-vidhya/introduction-to-time-series-analysis-and-key-concepts-\\ndbf6c394984f \\n• \\nhttps://financestu.com/time-series-data-vs-cross-sectional-data/ \\n \\n \\nWhat is Stationarity? \\nA time series is said to be stationary if its statistical properties, such as the mean, variance, and \\nautocorrelation, are constant over time. In other words, the distribution of the data does not change over \\ntime. This is in contrast to a non-stationary time series, where the statistical properties of the data change \\nover time. \\nFor example, consider a time series of monthly sales data for a company. If the mean sales are constant \\nover time, and the variance of the sales is also constant over time, then the time series is stationary. \\nHowever, if the mean sales are increasing over time, or if the variance of the sales is increasing over \\ntime, then the time series is non-stationary. \\nThe reason why stationarity is important is because many statistical models and techniques used in \\neconomics and other fields require the data to be stationary. This is because these models and techniques \\nare based on the assumption that the statistical properties of the data are constant over time. If the data \\nis non-stationary, then these models and techniques may not provide accurate results. \\n \\nWhy Stationarity Matters in Time Series Analysis and How to Achieve It \\n \\nTime series data is universal in fields like finance, healthcare, climate science, and more, where the \\nanalysis of patterns over time plays a crucial role in decision-making. However, not all time series data \\nis immediately ready for modeling. One of the fundamental properties that analysts and data scientists \\nlook for in time series is stationarity. A stationary time series has statistical properties — such as its \\nmean, variance, and autocorrelation — that remain consistent over time. This stability is a critical \\nassumption for many forecasting models, such as ARIMA, that rely on predictable and consistent \\npatterns in the data. Understanding stationarity and knowing how to test and enforce it are essential \\nskills for anyone working with time series data. \\nWhat is Stationarity?'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 25}, page_content='A time series is stationary if its statistical properties (mean, variance, and autocorrelation) remain \\nconstant over time. This means that the process generating the time series does not change over time, \\nmaking it easier to model and predict. \\nOr \\nStationarity in time series refers to a condition where the statistical properties of the series remain \\nconstant over time. This means that the mean, variance, and autocorrelation structure of the data do not \\nchange as time progresses. Stationarity is often categorized into two main types: \\n1. Strong (Strict) Stationarity: A time series is strictly stationary if the joint probability \\ndistribution of any subset of the series remains the same, regardless of the time at which the \\nsubset is observed. \\nOr  \\nStrict Stationarity → The joint distribution of values remains unchanged regardless of the \\ntime shift. \\n \\n2. Weak (Second-Order) Stationarity: A time series is weakly stationary if its mean and variance \\nare constant over time, and the covariance between two time points depends only on the time \\nlag between them. \\nOr  \\nWeak (or Second-Order) Stationarity → The mean and variance are constant over time, and \\nthe autocovariance depends only on the time lag, not the actual time. \\n \\nFor practical purposes, weak stationarity is usually sufficient and is the focus of most statistical tests \\nand transformations in time series analysis. \\nMany real-world time series, like stock prices or seasonal sales data, are non-stationary due to trends, \\nseasonality, or other factors. Recognizing this non-stationarity is the first step toward making the data \\nusable for predictive models.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 26}, page_content='Why Stationarity Matters \\nStationarity is a cornerstone of time series analysis and forecasting. Many statistical and machine \\nlearning models, such as ARIMA and SARIMA, assume that the input data is stationary. When this \\nassumption is violated, these models can produce inaccurate or misleading results. Here’s why \\nstationarity is important: \\n1. Model Assumptions: Time series models often rely on the assumption that relationships in the \\ndata remain consistent over time. Non-stationary data, with changing means or variances, can \\ndisrupt this consistency and compromise model performance. \\n2. Predictability: Stationary data is easier to predict because its underlying patterns are stable. \\nThis stability allows models to identify consistent trends and relationships, which leads to more \\nreliable forecasts. \\n3. Statistical Inference: Many statistical tests and methods, like hypothesis testing or confidence \\nintervals, assume stationarity. Violations of this assumption can lead to incorrect conclusions. \\n4. Simpler Transformations: Working with stationary data simplifies the analysis by removing \\ncomplex trends and seasonality, enabling a clearer focus on relationships in the residual data. \\nUnderstanding the importance of stationarity helps analysts and data scientists make informed decisions \\nabout preprocessing and choosing appropriate models for their time series data.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 27}, page_content='Or  \\n Importance of Stationarity in Time Series Analysis \\n1. Model Simplicity and Reliability \\n• \\nMany time series models (such as ARIMA, SARIMA, and Exponential Smoothing) assume \\nstationarity. \\n• \\nIf a time series is non-stationary, the model may give misleading results or fail to capture \\npatterns effectively. \\n2. Consistency in Statistical Inference \\n• \\nIn stationary series, parameters like mean and variance remain stable over time, making \\nstatistical tests (like hypothesis testing) valid. \\n• \\nIn non-stationary series, statistical relationships may change over time, leading to incorrect \\nconclusions. \\n3. Improved Forecasting Accuracy \\n• \\nStationary time series allow models to generalize better for forecasting future values. \\n• \\nNon-stationary data often require differencing or transformation to remove trends and \\nseasonality before forecasting. \\n4. Meaningful Autocorrelation and Seasonality Detection \\n• \\nIn a stationary series, the autocorrelation function (ACF) and partial autocorrelation \\nfunction (PACF) provide meaningful insights into the relationship between past and present \\nvalues. \\n• \\nIn non-stationary series, high correlations can be due to trends, not actual dependencies, leading \\nto spurious results. \\n5. Preventing Spurious Regression \\n• \\nRegressing non-stationary time series on each other can lead to spurious (false) relationships, \\nwhere variables appear to be correlated even when they are not. \\n• \\nStationarity ensures that the regression results are valid and interpretable. \\n \\nHow to Test for Stationarity \\nIdentifying whether a time series is stationary is a critical step before building predictive models. There \\nare several methods to assess stationarity, ranging from simple visual inspections to formal statistical \\ntests. \\n1. Visual Inspection \\n• \\nPlot the Time Series: Observe the time series plot for trends or seasonality. Non-stationary \\ndata often shows upward or downward trends or repeating seasonal patterns. \\n• \\nRolling Statistics: Calculate and plot rolling mean and variance. If these values change over \\ntime, the data is likely non-stationary.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 28}, page_content='The plot above illustrates the original non-stationary time series data, along with its rolling mean and \\nrolling standard deviation. Notice how both the rolling mean and standard deviation change over time, \\nindicating that the data is non-stationary. \\n2. Statistical Tests \\nAugmented Dickey-Fuller (ADF) Test: \\n• \\nA widely used test for stationarity. \\n• \\nNull hypothesis (H₀): The series is non-stationary. \\n• \\nIf the p-value is below a chosen significance level (e.g., 0.05), you can reject the null \\nhypothesis, indicating the series is stationary. \\nFor example:  \\nThe Augmented Dickey-Fuller (ADF) test results are as follows: \\n• \\nADF Statistic: 0.096 \\n• \\np-value: 0.966 \\nSince the p-value (0.966) is much greater than 0.05, we fail to reject the null hypothesis. This indicates \\nthat the data is non-stationary.  \\n Kwiatkowski-Phillips-Schmidt-Shin (KPSS) Test: \\n• \\nTests for trend stationarity. \\n• \\nNull hypothesis (H₀): The series is stationary. \\n• \\nA p-value higher than the significance level suggests stationarity. \\nFor example: \\nThe Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test results are as follows: \\n• \\nKPSS Statistic: 1.770 \\n• \\np-value: 0.01 \\n• \\nSince the KPSS statistic exceeds the critical values at all levels and the p-value (0.01) is less \\nthan 0.05, we reject the null hypothesis. This indicates that the data is not stationary.  \\n3. Autocorrelation Analysis'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 29}, page_content='• \\nUse an autocorrelation function (ACF) plot to detect patterns or dependencies in the data. Non-\\nstationary series often exhibit slowly decaying autocorrelations. \\n \\nThe autocorrelation plot (ACF) above shows that the autocorrelations decay slowly over increasing \\nlags. This gradual decline is a strong indicator of non-stationarity in the time series data.  \\nOr \\nHow to Check for Stationarity? \\n1. Visual Inspection \\n• \\nPlot the time series and observe if there is a clear trend or seasonality. \\n• \\nIf the mean and variance seem to change over time, the series is likely non-stationary. \\n2. Summary Statistics \\n• \\nDivide the series into different time intervals and check if mean and variance remain constant. \\n3. Statistical Tests for Stationarity \\n• \\nAugmented Dickey-Fuller (ADF) Test → Null hypothesis: The series is non-stationary. \\n• \\nKwiatkowski-Phillips-Schmidt-Shin (KPSS) Test → Null hypothesis: The series is \\nstationary. \\n• \\nPhillips-Perron (PP) Test → Alternative to ADF for testing unit roots. \\n \\nStationarity is a fundamental requirement for many time series models. Ensuring that a time \\nseries is stationary improves: \\n• \\n \\nModel accuracy \\n• \\n \\nForecast reliability \\n• \\n \\nStatistical validity'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 30}, page_content='Unit 3: \\nUnivariate time series analysis — II \\n \\nARMA (p,q) process, ACF (Auto Correlation Function) and PACF (Partial Auto Correlation \\nFunction) of an ARMA (p,q) process, forecasting ARMA process, integration of non-stationary data, \\nfirst-order integration and second order integration, ARIMA (p,i,q), estimation of parameters of ARIMA \\nmodel, Wald Test Statistic for significance of coefficients. \\n \\nARMA TIME SERIES MODEL \\nTime series analysis is a crucial aspect of data science, particularly when dealing with data that is \\ncollected over time. One of the fundamental models used in time series analysis is the ARMA \\n(Autoregressive Moving Average) \\nmodel. \\nThis article \\nwill delve \\ninto \\nthe ARMA \\nmodel, \\nits components, how it works, and its applications. \\nTable of Content \\n• \\nUnderstanding ARMA Model \\no \\n1. ARMA Components: Autoregressive (AR) \\no \\n2. ARMA Components: Moving Average (MA) \\no \\nMathematical Representation of ARMA Model \\n• \\nHow to Determine the Orders p and q in ARMA Model? \\n• \\nApplication and Use Cases of ARMA Model \\n• \\nAdvantages and Disadvantages of ARMA Model \\nUnderstanding ARMA Model \\nThe ARMA model is a combination of two simpler models: the Autoregressive (AR) model and the \\nMoving Average (MA) model. The ARMA model is used to describe time series data that is stationary, \\nmeaning its statistical properties do not change over time. \\n• \\nAutoregressive (AR) Model: This model uses the dependency between an observation and a \\nnumber of lagged observations (previous time points). It is denoted as AR(p), where p is the \\nnumber of lagged observations included. \\n• \\nMoving Average (MA) Model: This model uses the dependency between an observation and \\na residual error from a moving average model applied to lagged observations. It is denoted \\nas MA(q), where q is the number of lagged forecast errors included. \\nThe ARMA model combines these two approaches and is denoted as ARMA(p, q), where p is the order \\nof the autoregressive part and q is the order of the moving average part. \\n1. ARMA Components: Autoregressive (AR) \\nThe Autoregressive (AR) part of the ARMA model uses the relationship between an observation and a \\nnumber of lagged (previous) observations to predict future values. Imagine, that you are attempting to \\nforecast the temperature for tomorrow by using the data from the last several days. The AR portion'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 31}, page_content=\"makes the assumption that the current temperature and the temperatures from earlier days are connected. \\nFor instance suppose we write the temperature of today as Tt and the temperatures of the last two days \\nas Tt−1 and Tt−2, an AR(2) model (since it uses two lagged values) can be written as: \\nTt=c+ϕ1Tt−1+ϕ2Tt−2+et \\nWhere: \\n• \\nc is a constant. \\n• \\nϕ1 and ϕ2 are coefficients that determine the influence of the past temperatures. \\n• \\net is the error term (random noise). \\n2. ARMA Components: Moving Average (MA) \\nThe Moving Average (MA) part of the ARMA model uses the dependency between an observation and \\na residual error from a moving average model applied to lagged observations. Continuing with our \\ntemperature example, the MA part assumes that today's temperature is also influenced by the errors \\nmade in predicting previous days' temperatures. If we denote today's error as etet and the errors of the \\nlast two days as et−1et−1 and et−2et−2 an MA(2) model can be written as: \\nTt=c+et+θ1et−1+θ2et−2Tt=c+et+θ1et−1+θ2et−2 \\nWhere: \\n• \\nc is a constant. \\n• \\nϕ1ϕ1and ϕ2ϕ2 are coefficients that determine the influence of the past temperatures. \\nMathematical Representation of ARMA Model \\nThe ARMA model is a combination of both AR and MA components. An ARMA(p, q) model, \\nwhere pp is the number of lagged observations (AR part) and qq is the number of lagged forecast errors \\n(MA part), is represented as: \\nTt=c+Σi=1pϕiTt−i+Σj=1qθjet−j+etTt=c+Σi=1pϕiTt−i+Σj=1qθjet−j+et \\nHow to Determine the Orders p and q in ARMA Model? \\nDetermining the appropriate values for p and q is crucial for building an effective ARMA model. This \\ncan be done using the following methods: \\n1. Partial Autocorrelation Function (PACF): \\n• \\nPACF is used to determine the order p of the AR model. It measures the correlation \\nbetween observations at different lags, excluding the influence of intermediate lags. \\n• \\nThe order p is determined by the lag at which the PACF plot cuts off. \\n2. Autocorrelation Function (ACF): \\n• \\nACF is used to determine the order q of the MA model. It measures the correlation \\nbetween observations at different lags. \\n• \\nThe order q is determined by the lag at which the ACF plot cuts off. \\nApplication and Use Cases of ARMA Model \\nFor predicting and evaluating time series data the ARMA model is extensively utilized in many different \\ndomains. A few typical uses are as follows:\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 32}, page_content=\"• \\nEconomics: Predicting stock prices, exchange rates, and economic indicators. \\n• \\nWeather Forecasting: Analyzing temperature, rainfall, and other meteorological data. \\n• \\nSales Forecasting: Predicting future sales based on past sales data. \\n• \\nEngineering: Monitoring and controlling industrial processes. \\n• \\nInventory management: Forecasting future demand for products. \\n• \\nEpidemiology: Predicting the spread of diseases. \\nAdvantages and Disadvantages of ARMA Model \\nAdvantages \\nLimitations \\nSimplicity: The ARMA model is \\nrelatively simple to understand and \\nimplement. \\nStationarity Requirement: The ARMA model assumes \\nthat the time series data is stationary, meaning its \\nstatistical properties do not change over time. Non-\\nstationary data needs to be transformed before applying \\nthe ARMA model. \\nEffectiveness: It works well for many \\ntypes of time series data, especially \\nwhen there are clear patterns or trends. \\nComplexity with High Parameters: For large values of ? \\nand ?, the model can become complex and difficult to \\ninterpret. \\nCombination of AR and MA: By \\ncombining both autoregressive and \\nmoving average components, the ARMA \\nmodel can capture more complex \\npatterns in the data. \\nChoosing the right order for the AR and MA \\ncomponents can be challenging. \\nConclusion \\nThe ARMA model is a powerful tool for time series analysis, helping us predict future values based on \\npast trends. It offers a thorough method for deciphering patterns and generating forecasts by merging \\nthe moving average and autoregressive components. Even though it has drawbacks, its ease of use and \\npotency make it a useful technique in a variety of sectors. \\nWe have deconstructed the ARMA model in this easy-to-read introduction for beginners. Always keep \\nin mind that improving forecasts requires balancing historical values and mistakes. Next time you \\nencounter time series data, think ARMA ! \\nARMA TIME SERIES MODEL- FAQs \\nWhat is the difference between AR and MA in ARMA? \\nWhile the MA (Moving Average) component leverages historical errors to enhance the prediction, the \\nAR (Autoregressive) component uses historical observations to forecast future values. \\nWhat if my data isn't stationary?\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 33}, page_content='There are techniques to make non-stationary data stationary, like differencing. \\nCan ARMA be used for non-stationary data? \\nNo, the ARMA model requires the data to be stationary. Non-stationary data needs to be transformed \\n(e.g., through differencing) to become stationary before applying ARMA. \\nHow do you choose the values of ? and ? in ARMA? \\nSelecting the values of ? , and ? frequently entails applying information criteria, such as AIC (Akaike \\nInformation Criterion), and evaluating the time series data autocorrelation function (ACF), and partial \\nautocorrelation function (PACF). \\n \\nAutocorrelation and Partial Autocorrelation \\n \\nAutocorrelation and partial autocorrelation are statistical measures that help analyze the relationship \\nbetween a time series and its lagged values. In R Programming Language, the acf() and pacf() functions \\ncan be used to compute and visualize autocorrelation and partial autocorrelation, respectively. \\nAutocorrelation \\nAutocorrelation measures the linear relationship between a time series and its lagged values. In simpler \\nterms, it assesses how much the current value of a series depends on its past values. Autocorrelation is \\nfundamental in time series analysis, helping identify patterns and dependencies within the data. \\nInterpretation \\n• \\nPositive ACF: A positive ACF at lag k indicates a positive correlation between the current \\nobservation and the observation at lag k. \\n• \\nNegative ACF: A negative ACF at lag k indicates a negative correlation between the current \\nobservation and the observation at lag k.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 34}, page_content='• \\nDecay in ACF: The decay in autocorrelation as lag increases often signifies the presence of a \\ntrend or seasonality in the time series. \\n• \\nSignificance: Significant ACF values at certain lags may suggest potential patterns or \\nrelationships in the time series. \\nExample:  \\nLet\\'s take an example with a real-world dataset to illustrate the differences between the Autocorrelation \\nFunction (ACF) and Partial Autocorrelation Function (PACF). In this example, we\\'ll use the \\n\"AirPassengers\" dataset in R, which represents monthly totals of international airline passengers. \\n# Load necessary libraries \\nlibrary(forecast) \\n \\n# Load AirPassengers dataset \\ndata(\"AirPassengers\") \\n \\n# Plot the time series \\nplot(AirPassengers, main = \"Monthly International Airline Passengers\") \\nOutput: \\nAutocorrelation \\nNow Plot ACF \\n# Plot ACF \\nacf(AirPassengers, main = \"Autocorrelation Function (ACF) for AirPassengers\") \\nOutput:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 35}, page_content='Autocorrelation \\nwe use the same \"AirPassengers\" dataset and plot the PACF. The PACF plot shows the direct correlation \\nat each lag, helping identify the order of autoregressive terms. \\n• \\nThe ACF plot reveals a decaying pattern, indicating a potential seasonality in the data. Peaks at \\nmultiples of 12 (12, 24, ...) suggest a yearly cycle, reflecting the seasonal nature of airline \\npassenger data. \\n• \\nThe ACF plot gives a comprehensive view of the correlation at all lags, showing how each \\nobservation relates to its past values. \\nPartial Autocorrelation \\nPartial autocorrelation removes the influence of intermediate lags, providing a clearer picture of the \\ndirect relationship between a variable and its past values. Unlike autocorrelation, partial autocorrelation \\nfocuses on the direct correlation at each lag. \\n \\nInterpretation \\n• \\nDirect Relationship: PACF isolates the direct correlation between the current observation and \\nthe observation at lag k, controlling for the influence of lags in between. \\n• \\nAR Process Identification: Peaks or significant values in PACF at specific lags can indicate \\npotential orders for autoregressive (AR) terms in time series models. \\n• \\nModeling Considerations: Analysts often examine PACF to guide the selection of lag orders \\nin autoregressive integrated moving average (ARIMA) models. \\n# Load necessary libraries \\nlibrary(forecast)'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 36}, page_content='# Load AirPassengers dataset \\ndata(\"AirPassengers\") \\n \\n# Plot PACF \\npacf_result <- pacf(AirPassengers,  \\n                    main = \"Partial Autocorrelation Function (PACF) for AirPassengers\") \\nOutput: \\nPartial Autocorrelation \\nwe use the same \"AirPassengers\" dataset and plot the PACF. The PACF plot shows the direct correlation \\nat each lag, helping identify the order of autoregressive terms. \\n• \\nThe PACF plot helps identify the direct correlation at each lag. Peaks at lags 1 and 12 suggest \\npotential autoregressive terms related to the monthly and yearly patterns in the data. \\n• \\nThe PACF plot, on the other hand, focuses on the direct correlation at each lag, providing \\ninsights into the order of autoregressive terms. \\n• \\nBy comparing the two plots, you can observe how they complement each other in revealing the \\ntemporal dependencies within the time series. The ACF helps identify overall patterns, while \\nthe PACF refines the analysis by highlighting direct correlations. \\nPerform both on a Time series dataset to compare \\n# Load necessary libraries \\nlibrary(fpp2) \\n \\n# Load the \"ausbeer\" dataset from fpp2 package \\ndata(\"ausbeer\") \\n \\n# Plot the time series \\nautoplot(ausbeer, main = \"Monthly Australian Beer Production\")'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 37}, page_content='Output: \\nTime Series Plot \\nPlot ACF \\n# Plot ACF \\nacf(ausbeer, main = \"Autocorrelation Function (ACF) for Australian Beer Production\") \\nOutput: \\nAutocorrelation Plot \\nPlot PACF for differenced time series \\n# Load PACF from the forecast package \\nlibrary(forecast) \\n \\n# Plot PACF for differenced time series'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 38}, page_content='diff_ausbeer <- diff(ausbeer) \\npacf_result <- pacf(diff_ausbeer,main = \"Partial Autocorrelation Function (PACF) for  \\n                                  Differenced Australian Beer Production\") \\nOutput: \\nPartial Autocorrelation Plot \\nIn this example, we use the \"ausbeer\" dataset from the fpp2 package, which represents monthly \\nAustralian beer production. The ACF plot can provide insights into the potential seasonality and trends \\nin beer production. \\n• \\nAutocorrelation (ACF): The ACF plot for Australian beer production may reveal patterns \\nrelated to seasonality, trends, or cyclic behavior. Peaks at certain lags could indicate recurring \\npatterns in beer production. \\n• \\nPartial Autocorrelation (PACF): Differencing the time series and examining the PACF helps \\nidentify potential autoregressive terms that capture the direct correlation at each lag, after \\nremoving the influence of trends. \\nAdditional Considerations \\n• \\n \\no \\nSeasonal Differencing: In some cases, it might be beneficial to apply seasonal \\ndifferencing (e.g., differencing by 12 for monthly data) to handle seasonality properly. \\no \\nSeasonal Differencing: In some cases, it might be beneficial to apply seasonal \\ndifferencing (e.g., differencing by 12 for monthly data) to handle seasonality properly. \\no \\nModel Selection: The combination of ACF and PACF analysis can guide the selection \\nof parameters in time series models, such as autoregressive integrated moving average \\n(ARIMA) models. \\no \\nInterpretation: Understanding the patterns revealed by ACF and PACF is crucial for \\ninterpreting the underlying dynamics of a time series and building accurate forecasting \\nmodels. \\nDifference between Autocorrelation and Partial Autocorrelation \\nAutocorrelation (ACF) and Partial Autocorrelation (PACF) are both measures used in time series \\nanalysis to understand the relationships between observations at different time points.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 39}, page_content='Autocorrelation \\nPartial Autocorrelation \\nUsed for identifying the order of a moving average \\n(MA) process. \\nUsed for identifying the order of an autoregressive \\n(AR) process. \\nRepresents the overall correlation structure of the \\ntime series. \\nHighlights \\nthe \\ndirect \\nrelationships \\nbetween \\nobservations at specific lags. \\nAutocorrelation measures the linear relationship \\nbetween \\nan \\nobservation \\nand \\nits \\nprevious \\nobservations at different lags. \\nPartial Autocorrelation measures the direct linear \\nrelationship between an observation and its \\nprevious observations at a specific lag, excluding \\nthe contributions from intermediate lags. \\nConclusion \\nACF and PACF are critical tools in time series analysis, providing insights into temporal dependencies \\nwithin a dataset. These functions aid in understanding the structure of the data, identifying potential \\npatterns, and guiding the construction of time series models for accurate forecasting. By examining \\nACF and PACF, analysts gain valuable information about the underlying dynamics of the time series \\nthey are studying. \\nhttps://www.geeksforgeeks.org/autocorrelation-and-partial-autocorrelation/ \\nOR \\n \\nARMA (p, q) Process: Detailed Explanation \\nARMA (p, q) stands for AutoRegressive Moving Average process, which is one of the most commonly \\nused models in time series analysis for understanding and forecasting data. It combines two \\ncomponents: \\n• \\nAR (AutoRegressive) Component: Uses past values (lags) to predict future values. \\n• \\nMA (Moving Average) Component: Uses past forecast errors (shocks) to predict future values.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 40}, page_content='Properties of ARMA Model \\n• \\nStationarity: ARMA requires the data to be stationary, meaning constant mean and variance \\nover time. \\n• \\nInvertibility: For the MA component, it ensures that the model can be represented using an \\ninfinite AR process. \\n• \\nWhite Noise Residuals: The error terms (ϵt) should be independent and identically distributed \\nwith zero mean and constant variance. \\nSteps to Build an ARMA Model \\n1. Visualize the Data: Plot the time series to check for trends or seasonality. \\n2. Check for Stationarity: Use plots like ACF (Autocorrelation Function) and PACF (Partial \\nAutocorrelation Function) or perform statistical tests (e.g., ADF Test). \\n3. Determine p and q Values: \\no \\nUse PACF to determine the AR order p \\no \\nUse ACF to determine the MA order q \\n4. Estimate Parameters: Fit the model using Maximum Likelihood Estimation (MLE). \\n5. Model Diagnostics: Check residuals to ensure they follow a white noise process. \\n6. Forecasting: Use the fitted model for short-term predictions.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 41}, page_content='Example of ARMA Model Application \\nScenario: \\nA financial analyst wants to predict the daily stock prices of a company using past data. After examining \\nthe data, they determine the following: \\n• \\np=2p = 2p=2 (using PACF) \\n• \\nq=1q = 1q=1 (using ACF) \\nARMA(2,1) Model: \\nYt=c+ϕ1Yt−1+ϕ2Yt−2+θ1ϵt−1+ϵt \\nUsing this model, the analyst predicts stock prices for the next 5 days, adjusts the portfolio accordingly, \\nand monitors the results. \\nhttp://www-stat.wharton.upenn.edu/~stine/insr260_2009/lectures/arma_forc.pdf \\nhttp://www.statslab.cam.ac.uk/%7Errw1/timeseries/t.pdf')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader,PyPDFLoader\n",
    "\n",
    "##loading text file from the directory\n",
    "dir_loader = DirectoryLoader(\n",
    "    \"data/pdf\",\n",
    "    glob = \"**/*.pdf\",\n",
    "    loader_cls = PyMuPDFLoader,\n",
    ")\n",
    "pdf_documents = dir_loader.load()\n",
    "pdf_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdc53759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='User_ID: 1000004\n",
      "Product_ID: P00128942\n",
      "Gender: M\n",
      "Age: 46-50\n",
      "Occupation: 7\n",
      "City_Category: B\n",
      "Stay_In_Current_City_Years: 2\n",
      "Marital_Status: 1\n",
      "Product_Category_1: 1\n",
      "Product_Category_2: 11\n",
      "Product_Category_3: ' metadata={'source': 'data/csv/test.csv', 'row': 0}\n",
      "page_content='User_ID: 1000009\n",
      "Product_ID: P00113442\n",
      "Gender: M\n",
      "Age: 26-35\n",
      "Occupation: 17\n",
      "City_Category: C\n",
      "Stay_In_Current_City_Years: 0\n",
      "Marital_Status: 0\n",
      "Product_Category_1: 3\n",
      "Product_Category_2: 5\n",
      "Product_Category_3: ' metadata={'source': 'data/csv/test.csv', 'row': 1}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "filepath = \"data/csv/test.csv\"\n",
    "loader = CSVLoader(filepath)\n",
    "\n",
    "csv_doc = loader.load()\n",
    "for records in csv_doc[:2]:\n",
    "    print(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14409234",
   "metadata": {},
   "source": [
    "CHUNKING (DIVIDING LARGE FILES INTO SMALLER PIECES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6ebb015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193\n",
      "Unit 5 \n",
      "Unit-5 : Multivariate Time Series Analysis — VAR Estimation: \n",
      " \n",
      "• Introduction to multivariate time series analysis, \n",
      "• Concepts of Vector Auto Regression, \n",
      "• multivariate least square estimation, asymptotic properties of Lease \n",
      "square estimation, \n",
      "• Introduction to Vector Error Correction M\n",
      "{'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 150,\n",
    "    separators = [\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(pdf_documents)\n",
    "print(len(chunks))\n",
    "print(chunks[0].page_content[:300])\n",
    "print(chunks[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56892081",
   "metadata": {},
   "source": [
    "embedding and vectorStoreDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be8cd5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import Dict, Any, Tuple, List\n",
    "import chromadb\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998189e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n",
      "Model loaded successfully: Embedding dimensions: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x25828320ec0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    \"\"\"Handels Document embedding generation using sentenceTransformers\"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = 'all-MiniLM-L6-v2'):\n",
    "        \"\"\"Initializing the embedding manager\n",
    "        Args:\n",
    "            model_name: HuggingFace Model for sentence embeddings    \n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Loading the SentenceTransformer model\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading embedding model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded successfully: Embedding dimensions: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model{self.model_name}: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    def generate_embeddings(self, texts: list[str])->np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of texts\n",
    "\n",
    "        args:\n",
    "            Texts: list of string to embed\n",
    "\n",
    "        Returns: \n",
    "                numpy array of embeddings with shape (len(texts), embedding_dim)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        else:\n",
    "            print(f\"Generating embeddings for {len(texts)} texts...\")\n",
    "            embeddings = self.model.encode(texts, show_progress_bar = True)\n",
    "            print(f\"Generated Embeddings with shape: {embeddings.shape}\")\n",
    "            return embeddings\n",
    "        \n",
    "\n",
    "\n",
    "#Initializing the embedding manager\n",
    "embedding_manager = EmbeddingManager()\n",
    "embedding_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e5d277",
   "metadata": {},
   "source": [
    "VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbd0192d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store intialized collection:  pdf_documents\n",
      "Existing document in collection: 579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x2583832f770>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    \"\"\"Manages Document embeddings in a chromaDB vector store\"\"\"\n",
    "\n",
    "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory: str  = \"data/vectorStor\"):\n",
    "        \"\"\"Initialize the vector store\n",
    "        args:\n",
    "            collection_name: Name of the chromaDB collection\n",
    "            persist_directory: Directory to persist the vector store\n",
    "        \"\"\"\n",
    "\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initialize the chromaDB client and collection\"\"\"\n",
    "        try:\n",
    "            #create persistent chromadb client\n",
    "            os.makedirs(self.persist_directory, exist_ok = True)\n",
    "            self.client = chromadb.PersistentClient(path = self.persist_directory)\n",
    "\n",
    "            #get or create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name = self.collection_name,\n",
    "                metadata = {\"description\": \"PDF document embeddings for RAG\"}\n",
    "            )\n",
    "            print(f\"Vector store intialized collection:  {self.collection_name}\")\n",
    "            print(f\"Existing document in collection: {self.collection.count()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error Initializing vector store: {e}\")\n",
    "            raise\n",
    "            \n",
    "    def add_documents(self, documents: list[Any], embeddings: np.ndarray):\n",
    "        \"\"\"Add documents and their embedding to the vector store\n",
    "        Args:\n",
    "            documents: List of Langchain documents\n",
    "            embeddings: corresponding embeddings for the documents\n",
    "        \"\"\"\n",
    "\n",
    "        if len(documents) != len(embeddings): \n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "\n",
    "        #prepare data for chromadb\n",
    "        ids =  []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "\n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            #Generate unique id\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "\n",
    "            #prepare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "            #document content\n",
    "            documents_text.append(doc.page_content)\n",
    "\n",
    "            #embedding\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "\n",
    "        #add to collection\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids = ids,\n",
    "                metadatas = metadatas,\n",
    "                embeddings = embeddings_list,\n",
    "                documents = documents_text\n",
    "            )\n",
    "\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "        except Exception as e:\n",
    "            print(\"Error adding document to vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "vector_store =VectorStore()\n",
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "248440dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 0}, page_content='Unit 5 \\nUnit-5 : Multivariate Time Series Analysis — VAR Estimation: \\n \\n• Introduction to multivariate time series analysis, \\n• Concepts of Vector Auto Regression, \\n• multivariate least square estimation, asymptotic properties of Lease \\nsquare estimation, \\n• Introduction to Vector Error Correction Models, \\n• Cointegrated Processes (Johensen Co-integration technique), \\nCommon Stochastic Trends Deterministic Terms in Cointegrated \\nProcesses, Forecasting Integrated and Cointegrated Variables \\n• Introduction to Univariate GARCH models, multivariate GARCH, \\nestimation of GARCH models. \\n \\n1. Statistics: Multivariate time series analysis — fundamental concepts, VMA, VAR and VARMA  \\n \\n2. Vector Autoregression (VAR) for Multivariate Time Series  \\nhttps://www.geeksforgeeks.org/vector-autoregression-var-for-multivariate-time-series/ \\n \\n3. Vector Autoregressive Model (VAR) Using R  \\nhttps://www.geeksforgeeks.org/vector-autoregressive-model-var-using-r/'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 0}, page_content='3. Vector Autoregressive Model (VAR) Using R  \\nhttps://www.geeksforgeeks.org/vector-autoregressive-model-var-using-r/ \\n \\n4. Introduction to the Fundamentals of Vector Autoregressive Models \\nhttps://www.aptech.com/blog/introduction-to-the-fundamentals-of-vector-\\nautoregressivemodels/#:~:text=We%20lay%20the%20foundation%20for%20getting%20start\\ned%20with,VAR%20model.%20Estimation%20and%20forecasting%20with%20VAR%20mo\\ndels. \\n \\n5. An Introduction to Vector Error Correction Models (VECMs) · r-econometrics \\nhttps://www.r-econometrics.com/timeseries/vecintro/ \\n \\n6. VECM Estimation and Interpretation - SPUR ECONOMICS \\nhttps://spureconomics.com/vecm-estimation-and-interpretation/ \\n \\n \\n7. Johansen Cointegration Test: Learn How to Implement it in Python \\nhttps://blog.quantinsti.com/johansen-test-cointegration-building-stationary-portfolio/'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 1}, page_content='Univariate and Multivariate Time Series Analysis  \\n \\nTraditional statistical approaches for time series are univariate, meaning they focus on a single \\nsequence of values. \\nHowever, in the real world, time series data often consists of multiple variables that interact with one \\nanother. This interaction introduces an opportunity to move beyond univariate analysis and leverage \\nmultivariate time series, where relationships between features play a central role. \\n \\nWhat is Univariate Time Series? \\nUnivariate time series analysis deals with a single variable measured over time. For example: \\n• \\nStock prices: The daily closing price of a single stock. \\n• \\nTemperature: The hourly temperature recorded in a city. \\n• \\nMachine sensor data: A single sensor recording vibration levels over time. \\nIn a univariate time series, we focus exclusively on the historical behavior of one sequence to predict'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 1}, page_content='In a univariate time series, we focus exclusively on the historical behavior of one sequence to predict \\nits future values. Traditional statistical techniques like autoregressive models (AR), moving averages \\n(MA), and their combination (ARIMA) are all built around this univariate framework. \\nFor example, if we are analyzing a machine’s temperature sensor, we might forecast tomorrow’s \\ntemperature based solely on its historical trend without considering any other variables. This \\nsimplicity is efficient and computationally simple. Analyzing a single variable makes it easier to \\nunderstand the underlying patterns. \\nHowever, univariate models have limitations. They fail to account for external influences or \\ncorrelations between variables. In a world where systems are often interconnected, ignoring these \\nrelationships can lead to suboptimal forecasts. \\n \\nMultivariate Time Series \\nIn a multivariate time series, we analyze multiple time-dependent variables simultaneously. This'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 1}, page_content='Multivariate Time Series \\nIn a multivariate time series, we analyze multiple time-dependent variables simultaneously. This \\napproach allows us to incorporate relationships and correlations between different features, providing \\na richer context for predictions. \\nConsider a machine in an industrial setting. A single temperature sensor might not tell us much about \\npotential failures, but combining data from multiple sensors — such as temperature, pressure, \\nvibration, and energy consumption — gives us a more comprehensive view. These variables often \\ninteract in predictable ways, especially when bounded by physical laws. \\nMultivariate analysis Capturing Relationships between variables. For example, an increase in \\nmachine temperature might correlate with a rise in vibration levels, both of which may signal an \\nimpending failure. \\nThat means we have more info to drive our multivariate models. If one variable strongly influences'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 1}, page_content='impending failure. \\nThat means we have more info to drive our multivariate models. If one variable strongly influences \\nanother, the additional information can help anticipate future changes more effectively. \\nMany systems — especially physical systems like machinery, climate, or energy grids — operate \\nunder physics-bounded constraints. For instance: In a machine, temperature cannot rise indefinitely \\nwithout causing other measurable effects (like pressure changes). Another example: In an electric \\ngrid, load and power generation must remain in balance. \\nSo it makes sense to use multiple variables (and multivariate models) to incorporate these constraints.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 2}, page_content='Univariate vs. Multivariate: Which one should I use? \\nLet’s compare univariate and multivariate approaches by predicting machine failure. \\n• \\nUnivariate Approach: Suppose we have a time series of temperature readings from a single \\nsensor. Using a univariate model, we can identify trends, seasonality, or anomalies in the \\ntemperature data over time. this is simple to implement and computationally efficient. But it \\nfailsto account for other factors (e.g., pressure, vibration) that could provide additional \\ncontext. \\n• \\nMultivariate Approach: Imagine we have data from three sensors: temperature, vibration, and \\npressure. These variables are interrelated: an increase in vibration may lead to higher \\ntemperature and pressure changes. We can etect complex patterns that wouldn’t be apparent \\nin a single variable and we can identify leading indicators (e.g., vibration might increase \\nbefore temperature rises). overall this helps us build better forecasts and failure detection \\nmodels.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 2}, page_content='before temperature rises). overall this helps us build better forecasts and failure detection \\nmodels. \\nFor example, if a multivariate model recognizes that a spike in vibration tends to precede an increase \\nin temperature by 10 minutes, it can issue early warnings for preventive maintenance. \\n \\nTechniques for Multivariate Time Series Analysis \\nTransitioning from univariate to multivariate analysis requires models that can handle multiple \\nvariables simultaneously. Here are some key techniques: \\n1. Vector Autoregressive (VAR) Models: The VAR model is an extension of autoregression for \\nmultivariate time series. It captures linear relationships between multiple variables over time. \\n2. Vector Error Correction Models (VECM): VECM is a variant of VAR used when variables \\nexhibit long-term equilibrium relationships. It’s particularly useful when features are \\ncointegrated — meaning they move together over time.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 2}, page_content='exhibit long-term equilibrium relationships. It’s particularly useful when features are \\ncointegrated — meaning they move together over time. \\n3. Machine Learning Approaches: Recurrent Neural Networks (RNNs) and Long Short-Term \\nMemory (LSTM) networks: These models excel at learning complex, non-linear patterns in \\nmultivariate time series. They are widely used for predictive maintenance, financial \\nforecasting, and weather prediction. \\n4. Transformer Models: Recent advances like transformers can efficiently handle multivariate \\ntime series with long-term dependencies. \\n5. Multivariate State-Space Models: These models explicitly consider the underlying system \\ndynamics and constraints, making them well-suited for physical systems governed by laws \\nlike thermodynamics or mechanics. \\nNext Steps \\nUnivariate time series models are simple and effective for single-variable analysis but fail to account \\nfor relationships between features.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 2}, page_content='Univariate time series models are simple and effective for single-variable analysis but fail to account \\nfor relationships between features. \\nMultivariate time series models leverage correlations between variables to improve forecast accuracy \\nand account for system constraints. \\nPhysical systems often exhibit interdependencies that can only be captured through multivariate \\nanalysis, making it essential for fields like predictive maintenance, energy forecasting, and climate \\nmodeling. \\nTechniques like VAR, LSTMs, and transformers allow us to analyze and predict multivariate time \\nseries data at scale. \\nBy embracing multivariate approaches, we unlock deeper insights, better forecasts, and more reliable \\ndecisions — especially in complex, interconnected systems.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 3}, page_content='Bee Example \\nYou notice a correlation between bee traffic and temperature. If temperature increases, bee traffic \\nincreases. If bee traffic decreases suddenly, the hive may be under stress. \\nHere, analyzing only bee traffic (univariate) would miss the relationship with temperature and weight. \\nMultivariate analysis can combine all three to improve predictions. \\n \\nApplications of Multivariate Time Series \\n \\n• \\nFinance: To track indicators like stock prices, interest rates, and trading volumes, \\nhelping forecast market trends. \\n• \\nHealthcare: To monitor health metrics such as blood pressure and heart rate, detecting \\npatterns or predicting health events. \\n• \\nClimate Science: To analyze variables like temperature and precipitation, aiding in \\nweather prediction and climate study. \\n• \\nEconomics: To assess indicators like GDP and inflation rates, providing insights into \\neconomic conditions. \\n• \\nManufacturing: To monitor production metrics like machine performance and product'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 3}, page_content='economic conditions. \\n• \\nManufacturing: To monitor production metrics like machine performance and product \\nquality, optimizing processes and preventing failures. \\nConclusion \\nMultivariate time series modeling involves preparing the data by handling missing values, selecting \\nan appropriate model like VAR, fitting the model to the data, and then evaluating its performance \\nthrough diagnostics and metrics. This process helps to understand the relationships between variables \\nand supports decision-making and forecasting. To enhance the analysis, you can add relevant \\nvariables, explore advanced modeling techniques, regularly update the model with new data, and \\nconduct sensitivity analyses. \\n \\nVector Autoregression (VAR) for Multivariate Time Series \\n \\nVector Autoregression (VAR) is a statistical tool used to investigate the dynamic relationships between \\nmultiple time series variables. Unlike univariate autoregressive models, which only forecast a single'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 3}, page_content=\"multiple time series variables. Unlike univariate autoregressive models, which only forecast a single \\nvariable based on its previous values, VAR models investigate the interconnectivity of many variables. \\nThey accomplish this by modeling each variable as a function of not only its previous values but also \\nof the past values of other variables in the system. In this article, we are going to explore the \\nfundamentals of Vector Autoregression. \\nTable of Content \\n• \\nWhat is Vector Autoregression? \\n• \\nMathematical Intuition of VAR Equations \\n• \\nAssumptions underlying the VAR model \\n• \\nApplications of VAR Models \\n \\nWhat is Vector Autoregression? \\nVector Autoregression was first presented in the 1960s by economist Clive Granger. Granger's \\nsignificant discoveries laid the framework for understanding and modeling the dynamic interactions \\nthat exist among economic factors. VAR models acquired significant momentum in econometrics and \\nmacroeconomics during the 1970s and 1980s.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 3}, page_content='that exist among economic factors. VAR models acquired significant momentum in econometrics and \\nmacroeconomics during the 1970s and 1980s. \\n \\nVector Autoregression (VAR) is a multivariate extension of autoregression (AR) models. While \\ntraditional AR models analyze the relationship between a single variable and its lagged values, VAR \\nmodels consider multiple variables simultaneously. In a VAR model, each variable is regressed on its \\nown lagged values as well as lagged values of other variables in the system.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 4}, page_content='Mathematical Intuition of VAR Equations \\nVAR models are mathematically represented as a system of simultaneous equations, where each \\nequation describes the behavior of one variable as a function of its own lagged values and the lagged \\nvalues of all other variables in the system. \\n \\n \\nvarious assumptions and requirements must be met. \\n \\nAssumptions underlying the VAR model \\n \\nVAR analysis is subject to several assumptions and requirements to ensure the validity and reliability \\nof the results: \\n \\n1. Linearity: Relationships between variables are linear. \\n2. Stationarity: Time series data are stationary. \\n3. No Perfect Multicollinearity: No perfect linear relationships exist between variables. \\n4. No Autocorrelation in Residuals: Residuals are not serially correlated. \\n5. Homoscedasticity: Residual variance is constant. \\n6. No Endogeneity: Variables are not affected by omitted factors. \\n7. Exogeneity: Explanatory variables are not influenced by other variables.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 4}, page_content='6. No Endogeneity: Variables are not affected by omitted factors. \\n7. Exogeneity: Explanatory variables are not influenced by other variables. \\n8. Sufficient Observations: Adequate data for parameter estimation. \\n9. Weak Exogeneity: Some variables may be endogenous but not contemporaneously \\ncorrelated with errors. \\n \\nApplications of VAR Models \\n \\n1. Economic Forecasting: VAR models are widely used in economics to forecast the \\nbehavior of economic variables such as GDP, inflation, and interest rates. \\n2. Causal Inference: By studying the impulse responses generated by VAR models, \\nresearchers can infer the causal impact of one variable on another. This is particularly \\nvaluable in policy evaluation. \\n3. Financial Markets: VAR models can be used to predict financial indices, stocks and \\nasset prices.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 5}, page_content='What is Multivariate Least Squares Estimation? \\n• \\nIn a multivariate time series model like VAR (Vector Auto Regression), we have multiple \\nequations, each explaining a variable based on its own lags and the lags of other variables. \\n• \\nMultivariate Least Squares Estimation simply means: \\no \\nApply Ordinary Least Squares (OLS) to each equation separately. \\no \\nEach equation is treated like an independent multiple regression. \\n \\nAsymptotic Properties of Least Squares Estimation (OLS) \\nWhat Are Asymptotic Properties? \\n• \\nAsymptotic refers to the behavior of an estimator as the sample size (T) approaches infinity. \\n• \\nIn the case of OLS, these properties describe how the estimates of the model parameters behave \\nwhen you have a large number of observations. \\nThese properties are essential for understanding whether OLS estimators are reliable when working \\nwith large datasets (like in time series or panel data). \\nKey Asymptotic Properties of OLS Estimators'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 6}, page_content='3. Efficiency (BLUE: Best Linear Unbiased Estimator) \\n• \\nDefinition: OLS is the Best Linear Unbiased Estimator (BLUE) under certain conditions. \\n• \\nWhy Important: \\no \\nEfficiency means that, among all linear unbiased estimators, OLS has the smallest \\nvariance. \\no \\nIn simple terms, OLS gives the most precise estimates when assumptions hold. \\n \\n• \\nMathematical Basis (Gauss-Markov Theorem): \\no \\nUnder the assumption of no heteroskedasticity (constant variance of errors) and no \\nautocorrelation (errors are uncorrelated), OLS is the best estimator in terms of \\nhaving the lowest variance. \\n \\nAn Introduction to Vector Error Correction Models (VECMs) \\nOne of the prerequisits for the estimation of a vector autoregressive (VAR) model is that the analysed \\ntime series are stationary. However, economic theory suggests that there exist equilibrium relations \\nbetween economic variables in their levels, which can render these variables stationary without taking'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 6}, page_content='between economic variables in their levels, which can render these variables stationary without taking \\ndifferences. This is called cointegration. Since knowing the size of such relationships can improve the \\nresults of an analysis, it would be desireable to have an econometric model, which is able to capture \\nthem. So-called vector error correction models (VECMs) belong to this class of models. The following \\ntext presents the basic concept of VECMs and guides through the estimation of such a model in R. \\n \\nModel and data'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 7}, page_content='Vector error correction models are very similar to VAR models and can have the following form: \\n \\nwhere Δx is the first difference of the variables in vector x, Pi is a coefficient matrix of cointegrating \\nrelationships, T is a coefficient matrix of the lags of differenced variables of x, d is a vector of \\ndeterministic terms and C its corresponding coefficient matrix. p is the lag order of the model in its \\nVAR form and ϵ is an error term with zero mean and variance-covariance matrix Σ. \\nThe above equation shows that the only difference to a VAR model is the error correction term Πxt−1, \\nwhich captures the effect of how the growth rate of a variable in x changes, if one of the variables \\ndeparts from its equilibrium value. The coefficient matrix Π can be written as the matrix \\nproduct Π=αβ′ so that the error correction term becomes αβ′xt−1. The cointegration matrix β contains \\ninformation on the equilibrium relationships between the variables in levels. The vector described'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 7}, page_content='information on the equilibrium relationships between the variables in levels. The vector described \\nby β′xt−1 can be interpreted as the distance of the variables form their equilibrium values. α is a so-\\ncalled loading matrix describing the speed at which a dependent variable converges back to its \\nequilibrium value. \\nNote that Π is assumed to be of reduced rank, which means that α is a K×r matrix and β is a Kco×r \\nmatrix, where K is the number of endogenous variables, Kco is the number of variables in the \\ncointegration term and r is the rank of Π, which describes the number of cointegrating relationships that \\nexist between the variables. Note that if r=0, there is no cointegration between the variables so that Π=0. \\nA Vector Error Correction Model (VECM) is a special form of a Vector Autoregression (VAR) \\nmodel that is designed for non-stationary but cointegrated time series. If two or more variables are'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 7}, page_content='model that is designed for non-stationary but cointegrated time series. If two or more variables are \\nintegrated (i.e., I(1)) and share a long-run equilibrium relationship, VECM is used to model both \\ntheir short-run dynamics and long-run relationships. \\n Key Features: \\n• \\nIncorporates cointegration constraints into a VAR model. \\n• \\nCaptures both short-term adjustments and long-run equilibrium. \\n• \\nSuitable when at least two variables move together over time due to an economic relationship \\n(like inflation and interest rates). \\n \\nCointegrated Processes (Johensen Co-integration technique), Common Stochastic Trends \\nDeterministic Terms in Cointegrated Processes, Forecasting Integrated and Cointegrated \\nVariables'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 8}, page_content=\"2. Cointegrated Processes \\nWhat is Cointegration? \\nTwo or more non-stationary time series are said to be cointegrated if a linear combination of them is \\nstationary (I(0)). This implies a long-run equilibrium relationship between them despite being \\nindividually non-stationary. \\n   Example: \\nLet’s say GDP and consumption are both I(1). If the residual from the equation Consumption = β0 + \\nβ1*GDP + ε is I(0), then these variables are cointegrated. \\n3. Johansen Cointegration Technique \\nWhat is Johansen's Method? \\nJohansen's test is a multivariate technique for testing the number of cointegration relationships in a \\nsystem of I(1) time series. It is based on estimating a VECM and uses eigenvalues and trace \\nstatistics to determine the number of cointegration vectors. \\n Steps: \\n1. Check each variable is I(1) using ADF or PP test. \\n2. Estimate a VECM. \\n3. Use Johansen Trace Test or Max-Eigenvalue Test to find the number of cointegrating \\nequations. \\nWhat is the Johansen cointegration test?\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 8}, page_content='3. Use Johansen Trace Test or Max-Eigenvalue Test to find the number of cointegrating \\nequations. \\nWhat is the Johansen cointegration test? \\nThe Johansen Cointegration Test is a statistical procedure used to analyse the long-term \\nrelationships between multiple time series variables. Time Series is a sequence of observations \\nover time, which are usually spaced at regular intervals. For example, daily observed prices of \\nthe stocks, bonds etc. over a period of 10 years, 1 minute stock price data for the last 100 days \\netc. \\nKey properties of Johansen cointegration test \\nThe Johansen Cointegration Test is a valuable tool for economists, financial analysts, and \\nresearchers to assess the relationships between multiple time series variables and make informed \\ndecisions based on their long-term behaviour. \\nKey properties of the Johansen Cointegration Test include:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 9}, page_content='Key properties of the Johansen Cointegration Test \\n• \\nMultivariate Approach: Unlike some other cointegration tests, the Johansen Test \\ncan handle multiple time series variables simultaneously. This makes it especially \\nuseful when you want to analyse the relationships between more than two variables. \\n• \\nEigenvalues and Eigenvectors: The test relies on the eigenvalues and eigenvectors \\nof a matrix derived from the time series data. These mathematical properties help \\ndetermine the number of cointegrating relationships between the variables. \\n• \\nTrace and Maximum Eigenvalue Tests: The Johansen Test consists of two different \\ntests: the Trace test and the Maximum Eigenvalue test. These tests help determine \\nthe rank of the cointegration matrix, which, in turn, indicates the number of \\ncointegrating relationships present. \\n• \\nOrder of Integration: The test takes into account the order of integration of the'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 9}, page_content='cointegrating relationships present. \\n• \\nOrder of Integration: The test takes into account the order of integration of the \\ntime series variables, allowing it to differentiate between I(0) (stationary) and I(1) \\n(integrated of order 1) series. This is crucial for understanding whether the variables \\nhave a common stochastic trend. \\n• \\nCritical Values: The interpretation of the test results involves comparing test \\nstatistics to critical values from statistical tables, which depend on the significance \\nlevel chosen for the test. These critical values help determine whether cointegration \\nexists. \\n• \\nInterpretation: The test results can reveal whether there are long-term relationships \\nbetween the variables. If cointegration is detected, it implies that the variables move \\ntogether in the long run, and deviations from this equilibrium relationship are mean-\\nreverting.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 10}, page_content='Importance of Johansen Cointegration Test \\nThe Johansen Cointegration Test holds significant importance in the fields of econometrics, \\nfinance, and time series analysis for several key reasons: \\n \\nImportance of the Johansen Cointegration Test \\n• \\nLong-Term Relationships: It identifies and quantifies the existence of long-term or \\nequilibrium relationships between multiple time series variables. This is crucial for \\nunderstanding how different economic or financial factors interact over extended \\nperiods.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 11}, page_content=\"• \\nDiverse Applications: The test can be applied in various contexts, such as finance, \\neconomics, and social sciences. It's used to analyse the relationships between \\nmacroeconomic variables, financial instruments, asset pricing models, and more. \\n• \\nMultivariate Analysis: Unlike some other cointegration tests, the Johansen Test can \\nhandle multiple variables simultaneously, making it a versatile tool for analysing \\ncomplex relationships within a dataset. \\n• \\nPortfolio Management: In finance, the test is essential for portfolio management. It \\nhelps investors and fund managers assess the cointegration of assets in a portfolio, \\nwhich can inform diversification and risk management strategies. \\n• \\nMean-Reverting Portfolios: The test can identify mean-reverting (stationary) \\nportfolios. In such cases, deviations from the long-term equilibrium are expected to \\nreturn to that equilibrium, making it valuable for traders and investors. \\n•\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 11}, page_content='return to that equilibrium, making it valuable for traders and investors. \\n• \\nHedging Strategies: For hedging purposes, it is important to determine if there are \\ncointegrated relationships between assets or financial instruments. A cointegrated \\nrelationship can be exploited for hedging purposes. \\n• \\nReducing Spurious Regression: Cointegration analysis helps reduce the risk of \\nspurious regression, a common issue when dealing with non-stationary time series \\ndata. By identifying cointegration, researchers avoid drawing erroneous conclusions \\nfrom non-causal relationships. Exploring Stationary Time Series plays a key role in \\navoiding spurious regression. When time series are stationary, cointegration analysis \\nbecomes more effective, ensuring that you draw accurate conclusions and base your \\ndecisions on true relationships. Learn more to see how stationarity can enhance your \\nanalysis and minimize errors. \\n•'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 11}, page_content='decisions on true relationships. Learn more to see how stationarity can enhance your \\nanalysis and minimize errors. \\n• \\nPolicy Analysis: In economics, the Johansen Cointegration Test is useful for policy \\nanalysis. It can help assess the long-term impact of various economic policies on \\ndifferent variables, providing insights for policymakers. \\n• \\nForecasting: Cointegrated variables can be used to improve the accuracy of \\neconomic and financial forecasts. By understanding how variables move together in \\nthe long term, forecasts can be refined. \\n• \\nFinancial Modelling: The test plays a crucial role in the development of financial \\nmodels, particularly those involving multiple interacting variables. It enhances the \\naccuracy of models by capturing the underlying cointegrated relationships. \\nIn summary, the Johansen Cointegration Test is a valuable tool for analysing the long-term \\nrelationships between time series variables, providing insights into economic and financial'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 11}, page_content=\"relationships between time series variables, providing insights into economic and financial \\ndynamics, portfolio management, and policy analysis, among other applications. Its ability to \\nhandle multivariate data makes it a versatile and indispensable technique for researchers and \\npractitioners in these fields. \\nApplying cointegration in trading or forecasting \\nCointegration, a concept in time series analysis, is especially useful in the world of trading and \\nforecasting. It helps traders and analysts make better predictions and strategic decisions. \\nHere's how it works: \\n• \\nIdentifying Trading Pairs: Traders often look for pairs of assets or securities that \\nmove together in the long run. Cointegration can help identify these pairs. For \\ninstance, if you're trading stocks, you might notice that the prices of two companies \\ntend to follow a similar pattern over time. These pairs could be useful for a trading \\nstrategy. \\n•\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 11}, page_content='tend to follow a similar pattern over time. These pairs could be useful for a trading \\nstrategy. \\n• \\nStatistical Arbitrage: Cointegration enables traders to engage in statistical \\narbitrage. This means taking advantage of temporary price divergences within'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 12}, page_content=\"cointegrated pairs. If one stock temporarily deviates from the other in a predictable \\nway, traders can buy or sell to capture the difference when the prices realign. \\n• \\nRisk Management: Cointegration can be a tool for risk management. By \\ndiversifying your investments in cointegrated assets, you can reduce your portfolio's \\nexposure to risk. When one asset in a pair fluctuates, the other tends to balance it \\nout. \\n• \\nForecasts: Cointegration can improve forecasting accuracy. When two or more \\nvariables are cointegrated, their long-term relationship can be used to make better \\npredictions. For instance, in economics, cointegrated variables can help in predicting \\nfuture inflation or interest rates. \\n• \\nHedging: Cointegrated assets are often used for hedging purposes. If you have an \\nasset exposed to a certain risk, you can use another cointegrated asset to hedge that \\nrisk. This helps protect your investments.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 12}, page_content='asset exposed to a certain risk, you can use another cointegrated asset to hedge that \\nrisk. This helps protect your investments. \\nCommon Stochastic Trends and Deterministic Terms in Cointegrated Processes \\nCommon Stochastic Trends: \\nThese are shared underlying trends that drive the long-term behavior of multiple variables. \\nCointegrated variables are driven by fewer stochastic trends than the number of series. \\n• \\nIf you have 3 I(1) series with 2 cointegrating vectors, then only one common stochastic trend \\ndrives them. \\n Deterministic Terms: \\nThese are constants, trends, or seasonal dummies included in cointegration analysis. \\n• \\nIntercept (constant): Captures mean shift. \\n• \\nTrend term: Models time-dependent growth or decline. \\n• \\nSeasonal dummies: Account for periodic patterns. \\nThe inclusion of these terms affects the interpretation and estimation of cointegrating relationships. \\n \\n Forecasting Integrated and Cointegrated Variables'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 12}, page_content='Forecasting Integrated and Cointegrated Variables \\nWhat Are Integrated and Cointegrated Variables? \\n1. Integrated Variables (I(1)) \\n• \\nThese are non-stationary time series that become stationary after differencing once. \\n• \\nExample: GDP, inflation, or interest rate levels often show trends over time and are I(1). \\n2. Cointegrated Variables \\n• \\nA group of I(1) variables are cointegrated if a linear combination of them is stationary. \\n• \\nThis implies a long-run equilibrium relationship among the variables despite short-term \\nfluctuations. \\nKey Concepts:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 13}, page_content='• \\nFor non-cointegrated I(1) variables, standard differenced VAR or ARIMA models can be \\nused. \\n• \\nFor cointegrated variables, a VECM provides better forecasts since it: \\no \\nIncorporates short-term dynamics. \\no \\nMaintains long-term equilibrium relationships. \\no \\nAvoids spurious regression results. \\nForecasting Steps with VECM: \\n1. Identify and test for unit roots. \\n2. Test for cointegration using Johansen’s method. \\n3. Estimate the VECM. \\n4. Generate forecasts and interpret both short-run and long-run implications. \\n \\nIntroduction to Univariate GARCH models...elaborate in detail \\ndetailed explanation of Univariate GARCH (Generalized Autoregressive Conditional \\nHeteroskedasticity) models, which are widely used in financial econometrics to model and forecast \\ntime-varying volatility in time series data such as stock returns or exchange rates. \\nWhat Is a Univariate GARCH Model? \\nUnivariate GARCH models focus on a single time series (like the daily return of a stock) and aim to'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 13}, page_content='What Is a Univariate GARCH Model? \\nUnivariate GARCH models focus on a single time series (like the daily return of a stock) and aim to \\ncapture the phenomenon where volatility changes over time — specifically where periods of high \\nand low volatility cluster together. \\nThese models address the non-constant variance (heteroskedasticity) in the error terms of time \\nseries data. \\nWhy Use GARCH Models? \\n• \\nFinancial return data often exhibit volatility clustering. \\n• \\nClassical time series models assume homoskedasticity (constant variance), which is \\nunrealistic in financial markets. \\n• \\nGARCH models capture and forecast this changing variance. \\nARCH Model: The Starting Point \\nBefore GARCH, the ARCH (Autoregressive Conditional Heteroskedasticity) model, introduced by \\nRobert Engle in 1982, was the first to model conditional variance. \\nARCH(q) Model:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 14}, page_content='GARCH Model: A Generalization (Bollerslev, 1986) \\nGARCH(p, q) Model: \\n \\nInterpretation of Parameters in GARCH(1,1) \\n• \\nα0: Long-run average variance. \\n• \\nα1: Impact of recent shocks (news). \\n• \\nβ1: Persistence of past variance. \\nThe sum α1+β1 indicates the persistence of volatility: \\n• \\nIf close to 1 → high persistence \\n• \\nIf < 1 → volatility eventually dies out (stationary)'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 15}, page_content='Properties of GARCH Models \\nProperty \\nExplanation \\nVolatility clustering \\nCaptures the fact that volatility tends to persist. \\nLeptokurtosis \\nCan account for fat tails in returns. \\nForecasting power \\nExcellent for short-term volatility forecasts. \\nConditional heteroskedasticity Variance depends on past information. \\n \\nApplications of Univariate GARCH Models \\n• \\nRisk management (Value at Risk) \\n• \\nOption pricing (volatility modeling) \\n• \\nPortfolio optimization \\n• \\nMarket analysis (detecting crisis periods) \\n• \\nMacroeconomic volatility studies \\nExample in Real Life: S&P 500 Returns \\nIf daily returns of the S&P 500 show high volatility after major economic news and calm periods \\notherwise, a GARCH(1,1) model can help: \\n• \\nModel how the news affects short-term volatility. \\n• \\nPredict future volatility for risk control or derivative pricing. \\n \\nIntroduction: Why Multivariate GARCH? \\nWhile Univariate GARCH models capture the time-varying volatility of a single time series (e.g.,'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 15}, page_content='Introduction: Why Multivariate GARCH? \\nWhile Univariate GARCH models capture the time-varying volatility of a single time series (e.g., \\nreturns of one stock), Multivariate GARCH (MGARCH) models extend this framework to handle \\nmultiple time series simultaneously — for example: \\nModeling volatility and correlation across different assets, sectors, or markets. \\nThis is crucial for: \\n• \\nPortfolio optimization \\n• \\nRisk management \\n• \\nAsset allocation \\n• \\nSpillover and contagion analysis in financial markets \\n Key Objectives of Multivariate GARCH Models \\n1. Model time-varying variances of multiple assets. \\n2. Capture time-varying covariances or correlations. \\n3. Ensure the covariance matrix is positive semi-definite. \\n4. Allow for parsimonious parameter estimation, especially when the number of series is large.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-05-05T12:08:51+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf', 'total_pages': 17, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-05-05T12:08:51+05:30', 'trapped': '', 'modDate': \"D:20250505120851+05'30'\", 'creationDate': \"D:20250505120851+05'30'\", 'page': 16}, page_content='Estimation of GARCH Models \\n• \\nMethod: Maximum Likelihood Estimation (MLE) or Quasi-MLE (QMLE) \\n• \\nSteps (for DCC-GARCH): \\n1. Estimate univariate GARCH models. \\n2. Use standardized residuals to estimate correlation dynamics. \\n• \\nSoftware: \\no \\nR: rmgarch, ccgarch \\no \\nPython: arch, statsmodels \\no \\nEViews, MATLAB, Stata \\nApplication Areas of Multivariate GARCH \\n1. Portfolio Risk Modeling: Estimating time-varying covariance matrix for optimal weights. \\n2. VaR (Value at Risk): Computing portfolio risk under changing volatility and correlation. \\n3. Market Spillovers: Identifying how volatility in one market (e.g., US) affects others (e.g., \\nIndia, EU). \\n4. Financial Contagion: Studying co-movement during crisis periods. \\nExample \\nSuppose you’re analyzing daily returns of Apple, Google, and Tesla: \\n• \\nStep 1: Fit individual GARCH(1,1) to each stock. \\n• \\nStep 2: Use residuals to estimate dynamic correlation matrix using DCC. \\n• \\nStep 3: Forecast covariance matrix for tomorrow’s portfolio risk.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 0}, page_content='Unit 3 \\nUnit 3: Univariate time series analysis — II: \\n• ARMA (p,q) process,  \\n• ACF (Auto Correlation Function) and PACF (Partial Auto Correlation Function) of an \\nARMA (p,q) process, forecasting ARMA process,  \\n• integration of non-stationary data, first-order integration and second order integration,  \\n• ARIMA (p,i,q), estimation of parameters of ARIMA model,  \\n• Wald Test Statistic for significance of coefficients. \\n \\n1. Chap 5: ARIMA Model \\nhttp://ocw.utm.my/pluginfile.php/3782/mod_resource/content/0/Chap5-\\nARIMAModel.pdf  \\n \\n2. Auto correlation Function (ACF) and Partial Auto correlation Function (PACF) \\nhttps://medium.com/@ritusantra/auto-correlation-function-acf-and-partial-auto-\\ncorrelation-function-pacf-e29ec2db2b1b \\n \\n \\n3. Order of Integration: Time Series and Integration \\nhttps://www.statisticshowto.com/order-of-integration/ \\n \\n4. What are ARIMA models? \\nhttps://www.ibm.com/think/topics/arima-model \\n \\n5. Time Series Analysis using ARIMA model in R Programming'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 0}, page_content='4. What are ARIMA models? \\nhttps://www.ibm.com/think/topics/arima-model \\n \\n5. Time Series Analysis using ARIMA model in R Programming \\nhttps://www.geeksforgeeks.org/time-series-analysis-using-arima-model-in-r-\\nprogramming/ \\n \\n6. ARIMA Models in R \\nhttps://medium.com/biased-algorithms/arima-models-in-r-8ccd2328bb32 \\n \\n7. Model Selection for ARIMA \\nhttps://www.geeksforgeeks.org/model-selection-for-arima/ \\n \\n8. Quick way to find p, d and q values for ARIMA (With time series data sample) \\nhttps://analyticsindiamag.com/ai-trends/quick-way-to-find-p-d-and-q-values-for-\\narima/ \\n \\n9. How to Perform a Wald Test in R \\nhttps://www.geeksforgeeks.org/how-to-perform-a-wald-test-in-r/ \\n \\n10. Wald test hypothesis testing regression analysis \\nhttps://diogoribeiro7.github.io/statistics/wald_test_hypothesis_testing_regression_anal\\nysis/ \\n \\n11. Understanding — ‘Wald Test’'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 1}, page_content='https://medium.com/@analyttica/understanding-wald-test-2e3fa7723516 \\n \\n12. ARMA TIME SERIES MODEL  \\nhttps://www.geeksforgeeks.org/arma-time-series-model/ \\n \\n13. Time Series Forecasting \\nhttps://medium.com/@immadisettysukeshkumar999/time-series-forecasting-part-3-\\na4bcdec1b44e \\n \\nARMA TIME SERIES MODEL \\nTime series analysis is a crucial aspect of data science, particularly when dealing with data \\nthat is collected over time. One of the fundamental models used in time series analysis is the \\nARMA (Autoregressive Moving Average) model. This article will delve into the ARMA \\nmodel, its components, how it works, and its applications. \\nTable of Content \\n• \\nUnderstanding ARMA Model \\no 1. ARMA Components: Autoregressive (AR) \\no 2. ARMA Components: Moving Average (MA) \\no Mathematical Representation of ARMA Model \\n• \\nHow to Determine the Orders p and q in ARMA Model? \\n• \\nApplication and Use Cases of ARMA Model \\n• \\nAdvantages and Disadvantages of ARMA Model \\nUnderstanding ARMA Model'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 1}, page_content='• \\nApplication and Use Cases of ARMA Model \\n• \\nAdvantages and Disadvantages of ARMA Model \\nUnderstanding ARMA Model \\nThe ARMA model is a combination of two simpler models: the Autoregressive (AR) \\nmodel and the Moving Average (MA) model. The ARMA model is used to describe time series \\ndata that is stationary, meaning its statistical properties do not change over time. \\n• \\nAutoregressive (AR) Model: This model uses the dependency between an \\nobservation and a number of lagged observations (previous time points). It is denoted \\nas AR(p), where p is the number of lagged observations included. \\n• \\nMoving Average (MA) Model: This model uses the dependency between an \\nobservation and a residual error from a moving average model applied to lagged \\nobservations. It is denoted as MA(q), where ?q is the number of lagged forecast \\nerrors included. \\nThe ARMA model combines these two approaches and is denoted as ARMA(p, q), where p is'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 1}, page_content='errors included. \\nThe ARMA model combines these two approaches and is denoted as ARMA(p, q), where p is \\nthe order of the autoregressive part and q is the order of the moving average part. \\n1. ARMA Components: Autoregressive (AR)'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 2}, page_content=\"The Autoregressive (AR) part of the ARMA model uses the relationship between an \\nobservation and a number of lagged (previous) observations to predict future values. Imagine, \\nthat you are attempting to forecast the temperature for tomorrow by using the data from the last \\nseveral days. The AR portion makes the assumption that the current temperature and the \\ntemperatures from earlier days are connected. For instance suppose we write the temperature \\nof today as Tt and the temperatures of the last two days as Tt−1 \\n \\n2. ARMA Components: Moving Average (MA) \\nThe Moving Average (MA) part of the ARMA model uses the dependency between an \\nobservation and a residual error from a moving average model applied to lagged observations. \\nContinuing with our temperature example, the MA part assumes that today's temperature is \\nalso influenced by the errors made in predicting previous days' temperatures. If we denote\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 2}, page_content=\"also influenced by the errors made in predicting previous days' temperatures. If we denote \\ntoday's error as et and the errors of the last two days as et−1 and et−2 an MA(2) model can be \\nwritten as: \\n \\nMathematical Representation of ARMA Model \\nThe ARMA model is a combination of both AR and MA components. An ARMA(p, q) model, \\nwhere p is the number of lagged observations (AR part) and q is the number of lagged forecast \\nerrors (MA part), is represented as: \\n \\nHow to Determine the Orders p and q in ARMA Model?\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 3}, page_content='Determining the appropriate values for p and q is crucial for building an effective ARMA \\nmodel. This can be done using the following methods: \\n1. Partial Autocorrelation Function (PACF): \\n• \\nPACF is used to determine the order p of the AR model. It measures the \\ncorrelation between observations at different lags, excluding the influence of \\nintermediate lags. \\n• \\nThe order p is determined by the lag at which the PACF plot cuts off. \\n2. Autocorrelation Function (ACF): \\n• \\nACF is used to determine the order q of the MA model. It measures the \\ncorrelation between observations at different lags. \\n• \\nThe order q is determined by the lag at which the ACF plot cuts off. \\nApplication and Use Cases of ARMA Model \\nFor predicting and evaluating time series data the ARMA model is extensively utilized in many \\ndifferent domains. A few typical uses are as follows: \\n• \\nEconomics: Predicting stock prices, exchange rates, and economic indicators. \\n•'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 3}, page_content='different domains. A few typical uses are as follows: \\n• \\nEconomics: Predicting stock prices, exchange rates, and economic indicators. \\n• \\nWeather Forecasting: Analyzing temperature, rainfall, and other meteorological data. \\n• \\nSales Forecasting: Predicting future sales based on past sales data. \\n• \\nEngineering: Monitoring and controlling industrial processes. \\n• \\nInventory management: Forecasting future demand for products. \\n• \\nEpidemiology: Predicting the spread of diseases. \\n \\nAdvantages and Disadvantages of ARMA Model \\nAdvantages \\nLimitations \\nSimplicity: The ARMA model is \\nrelatively simple to understand and \\nimplement. \\nStationarity Requirement: The ARMA model \\nassumes that the time series data is stationary, \\nmeaning its statistical properties do not change \\nover time. Non-stationary data needs to be \\ntransformed before applying the ARMA model. \\nEffectiveness: It works well for \\nmany types of time series data, \\nespecially when there are clear \\npatterns or trends.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 3}, page_content='Effectiveness: It works well for \\nmany types of time series data, \\nespecially when there are clear \\npatterns or trends. \\nComplexity with High Parameters: For large \\nvalues of ? and ?, the model can become complex \\nand difficult to interpret.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 4}, page_content='Advantages \\nLimitations \\nCombination of AR and MA: By \\ncombining both autoregressive and \\nmoving average components, the \\nARMA model can capture more \\ncomplex patterns in the data. \\nChoosing the right order for the AR and MA \\ncomponents can be challenging. \\n \\nAuto correlation Function (ACF) and Partial Auto correlation Function (PACF) \\n \\nAuto correlation Function (ACF) \\nAuto-correlation is the correlation between a time series and a delayed version of itself (lag). \\nIt represents a correlation coefficient between the time series and its lag values. \\nAuto correlation Function (ACF) plots the correlation coefficient against the lag, and it’s a \\nvisual representation of autocorrelation. \\nFor example, ACF at lag 3 is calculated as the correlation between the time series (Yt) and the \\nsame time series lagged by 3 time periods (Yt-3). In this way, the correlation is estimated at \\nevery lag and plotted on a graph showing the correlation coefficient at each lag.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 5}, page_content='The correlation coefficient is measured either by Pearson’s correlation coefficient or \\nby Spearman’s rank correlation coefficient. \\nThe correlation coefficient can range from -1 (a perfect negative relationship) to +1 (a perfect \\npositive relationship). A coefficient of 0 means that there is no relationship between the \\nvariables. \\nThe autocorrelation function starts a lag 0, which is the correlation of the time series with itself \\nand therefore results in a correlation of 1. \\nNote: ACF includes both direct and indirect effects through the intermediary time periods. \\n \\n \\nPartial Auto correlation Function (PACF) \\nA partial autocorrelation function captures a direct correlation between time series and a \\nlagged version of itself. \\nFor example, if we’re regressing a signal S at lag t (St) with the same signal at lags t-1, t-2 and \\nt-3 (St-1, St-2, St-3), the partial correlation between St and St-2 is the amount of correlation'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 5}, page_content='t-3 (St-1, St-2, St-3), the partial correlation between St and St-2 is the amount of correlation \\nbetween St and St-3 that isn’t explained by their mutual correlations with St-1 and St-2. \\nTo find PACF between St and St-3 we use regression model, \\n \\nHere, ϕ3 is the PACF at lag 3; \\nϕ1, ϕ2 and ϕ3 are coefficients and Є is error. \\nFrom the regression formula above, the PACF value between St and St-3 is the coefficient ϕ3. \\nThis coefficient will give us direct effect of time-series St-3 to the time-series St because the \\neffects of St-2 and St-1 are already captured by ϕ1 and ϕ2. \\nThe PACF graph is constructed by plotting all the values of PACF obtained from regressions \\nat different lags. \\nNote: PACF includes only direct effect and it does not consider the indirect effects.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 6}, page_content='Importance of ACF and PACF \\nACF and PACF graphs are used to find out the order of AR and MA component of an ARIMA \\nmodel. \\nIf the ACF graph is declining and there are a few significant lags in the PACF, then this \\nindicates the process is AR (Auto-regressive). We can select the order p for AR(p) model \\nbased on significant spikes from the PACF plot. Spikes those are outside the blue boundary of \\nthe PACF plot tell us the order of the AR model. \\nIf the PACF graph is declining and there are a few significant lags in the ACF, then this \\nindicates the process is MA (Moving average). We can select the order q for MA(q) model \\nbased on significant spikes from the ACF plot. Spikes those are outside the blue boundary of \\nthe ACF plot tell us the order of the MA model. \\nThe blue area in the ACF and PACF graphs indicated 95% confidence interval and it is an \\nindictor of significance threshold. Anything within the are is statistically close to zero and'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 6}, page_content='indictor of significance threshold. Anything within the are is statistically close to zero and \\nanything outside is statistically non-zero. \\nTo determine the order of the model, we have to consider the spikes which are outside the \\nsignificance threshold (blue area). \\n \\nForecasting with ARMA Process \\n Steps for Forecasting: \\n1. Check Stationarity: \\no Use ADF/KPSS tests. \\no If non-stationary, difference the series. \\n2. Plot ACF and PACF: \\no Identify appropriate p and q values. \\n3. Estimate Parameters:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 7}, page_content='o Use Maximum Likelihood Estimation or Least Squares to estimate ϕ\\\\phiϕ and \\nθ\\\\thetaθ. \\n4. Model Validation: \\no Check residuals (should resemble white noise). \\no Use AIC/BIC for model selection. \\n5. Make Forecasts: \\no Once model fits well, use it to predict future values. \\n \\nIntegration of Non-Stationary Data \\nNon-Stationary Data \\nIn time series analysis, a stationary series has a constant mean, variance, and autocovariance \\nover time. A non-stationary series, on the other hand, exhibits trends, seasonality, or changing \\nvariance. \\n• \\nNon-stationary data often lead to spurious regression results, which means misleading \\nstatistical inferences. \\n \\nIntegration \\n\"Integration\" is the process of transforming a non-stationary time series into a stationary one \\nby differencing. \\n• \\nA time series is said to be integrated of order d (denoted I(d)) if it becomes stationary \\nafter differencing d times. \\nDifferencing \\n \\nFirst-Order Integration (I(1)) and Second-Order Integration (I(2))'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 7}, page_content='after differencing d times. \\nDifferencing \\n \\nFirst-Order Integration (I(1)) and Second-Order Integration (I(2)) \\n I(1) Process (First-order Integrated) \\n• \\nA time series Yt is I(1) if it becomes stationary after taking the first difference. \\n• \\nMany economic and financial time series are I(1), such as GDP, exchange rates, or stock \\nprices.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 8}, page_content='I(2) Process (Second-order Integrated) \\n• \\nA time series is I(2) if it becomes stationary only after taking the second difference. \\n• \\nRare in practice but may occur in some long-term macroeconomic variables. \\nARIMA (p, d, q) Model \\nThe ARIMA model combines three components: \\n• \\nAR (Auto Regressive) – p: Regression on its own lagged (past) values. \\n• \\nI (Integrated) – d: Number of times the data are differenced to become stationary. \\n• \\nMA (Moving Average) – q: Regression on past forecast errors. \\nMathematical Representation: \\n \\nEstimation of Parameters of ARIMA Model \\nParameters are typically estimated using Maximum Likelihood Estimation (MLE) or Least \\nSquares. \\nSteps: \\n1. Identify the model order (p, d, q) using: \\no ACF (AutoCorrelation Function) \\no PACF (Partial AutoCorrelation Function) \\no Information criteria like AIC, BIC \\n2. Estimate parameters: \\no Estimate AR (ϕ) and MA (θ) coefficients. \\no Software like R, Python (statsmodels), and EViews can automate this.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 8}, page_content='2. Estimate parameters: \\no Estimate AR (ϕ) and MA (θ) coefficients. \\no Software like R, Python (statsmodels), and EViews can automate this. \\n3. Diagnostic checking: \\no Check residuals for autocorrelation (Ljung-Box test). \\no Ensure residuals are white noise. \\nWald Test Statistic for Significance of Coefficients \\nPurpose:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-04-22T12:07:11+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit3.pdf', 'total_pages': 11, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-04-22T12:07:11+05:30', 'trapped': '', 'modDate': \"D:20250422120711+05'30'\", 'creationDate': \"D:20250422120711+05'30'\", 'page': 9}, page_content='The Wald test checks the statistical significance of individual or a group of \\nparameters in the model. \\nFormula: \\n \\nHypotheses: \\n• \\nNull Hypothesis (H₀): Parameter = 0 (not significant) \\n• \\nAlternative Hypothesis (H₁): Parameter ≠ 0 (significant) \\nIf the Wald statistic exceeds the critical value from a Chi-square distribution, or the p-value < \\n0.05, we reject H₀. \\nUse in ARIMA: \\nUsed to test whether AR or MA coefficients significantly improve the model. \\nSummary Table \\nConcept \\nMeaning \\nNon-stationary Data \\nMean/variance changes over time \\nIntegration \\nMaking data stationary via differencing \\nFirst-order \\nIntegration \\n(I(1)) \\nOne difference needed for stationarity \\nSecond-order \\nIntegration \\n(I(2)) \\nTwo differences needed \\nARIMA(p, d, q) \\nCombines autoregression, integration (differencing), and \\nmoving average \\nParameter Estimation \\nTypically via MLE or least squares \\nWald Test \\nTests if AR/MA parameters are statistically significant'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 0}, page_content='Unit-2: Univariate time series analysis — I: \\n \\nModels related to stationary data, Auto Regressive model, Moving Average model, Stationarity \\nof data, concepts on unit root, impacts of a unit root in estimating the model parameters, tests \\nrelated to unit root Dickey Fuller test, Augmented Dickey Fuller test, KPSS Test, The Phillips \\nPeron Test, seasonal unit roots periodic integration and unit root testing. \\n \\nhttps://www.wallstreetmojo.com/unit-root-tests/ \\nhttps://ebrary.net/577/economics/stationarity_tests \\nhttps://www.analyticsvidhya.com/blog/2015/12/complete-tutorial-time-series-modeling/ \\n \\nAutoregressive (AR) Model for Time Series Forecasting \\nAutoregressive models, often abbreviated as AR models, are a fundamental concept in time \\nseries analysis and forecasting. They have widespread applications in various fields, including \\nfinance, economics, climate science, and more. In this comprehensive guide, we will explore'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 0}, page_content='finance, economics, climate science, and more. In this comprehensive guide, we will explore \\nautoregressive models, how they work, their types, and practical examples. \\nAutoregressive Models \\nAutoregressive models belong to the family of time series models. These models capture the \\nrelationship between an observation and several lagged observations (previous time steps). The \\ncore idea is that the current value of a time series can be expressed as a linear combination of \\nits past values, with some random noise.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 1}, page_content='Autocorrelation (ACF) in Autoregressive Models \\nAutocorrelation, often denoted as \"ACF\" (Autocorrelation Function), is a fundamental concept \\nin time series analysis and autoregressive models. It refers to the correlation between a time \\nseries and a lagged version of itself. In the context of autoregressive models, autocorrelation \\nmeasures how closely the current value of a time series is related to its past values, specifically \\nthose at different time lags. \\nHere\\'s a breakdown of the concept of autocorrelation in autoregressive models: \\n• \\nAutocorrelation involves calculating the correlation between a time series and a lagged \\nversion of itself. The \"lag\" represents the number of time units by which the series is \\nshifted. For example, a lag of 1 corresponds to comparing the series with its previous \\ntime step, while a lag of 2 compares it with the time step before that, and so on. Lag \\nvalues help you calculate autocorrelation, which measures how each observation in a'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 1}, page_content='values help you calculate autocorrelation, which measures how each observation in a \\ntime series is related to previous observations. \\n• \\nThe autocorrelation at a particular lag provides insights into the temporal dependence \\nof the data. If the autocorrelation is high at a certain lag, it indicates a strong relationship \\nbetween the current value and the value at that lag. Conversely, if the autocorrelation is \\nlow or close to zero, it suggests a weak or no relationship. \\n• \\nTo visualize autocorrelation, a common approach is to create an ACF plot. This plot \\ndisplays the autocorrelation coefficients at different lags. The horizontal axis represents \\nthe lag, and the vertical axis represents the autocorrelation values. Significant peaks or \\npatterns in the ACF plot can reveal the underlying temporal structure of the data. \\nAutocorrelation plays a pivotal role in autoregressive models. \\n• \\nIn an Autoregressive model of order p, the current value of the time series is expressed'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 1}, page_content='• \\nIn an Autoregressive model of order p, the current value of the time series is expressed \\nas a linear combination of its past p values, with coefficients determined through'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 2}, page_content='methods like least squares or maximum likelihood estimation. The selection of the lag \\norder (p) in the AR model often relies on the analysis of the ACF plot. \\n• \\nAutocorrelation can also be used to assess whether a time series is stationary. In a \\nstationary time series, autocorrelation should gradually decrease as the lag increases. \\nDeviations from this behavior might indicate non-stationarity. \\nTypes of Autoregressive Models \\n \\nAR(p) Model: \\n• \\nThe general autoregressive model of order p includes p lagged values. \\n• \\nIt is expressed as shown in the introduction. \\n \\nBenefits and Drawbacks of Autoregressive Models \\nAutoregressive models (AR models) are a class of time series models that have their own set \\nof benefits and drawbacks. Understanding these can help in choosing when to use them and \\nwhen to consider alternative modeling approaches. \\nBenefits of Autoregressive Models: \\n• \\nSimplicity: AR models are relatively simple to understand and implement. They rely'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 2}, page_content='Benefits of Autoregressive Models: \\n• \\nSimplicity: AR models are relatively simple to understand and implement. They rely \\non past values of the time series to predict future values, making them conceptually \\nstraightforward. \\n• \\nInterpretability: The coefficients in an AR model have clear interpretations. They \\nrepresent the strength and direction of the relationship between past and future values, \\nmaking it easier to derive insights from the model. \\n• \\nUseful for Stationary Data: AR models work well with stationary time series data. \\nStationary data have stable statistical properties over time, which is an assumption that \\nAR models are built upon. \\n• \\nEfficiency: AR models can be computationally efficient, especially for short time \\nseries or when you have a reasonable amount of data. \\n• \\nModeling Temporal Patterns: AR models are good at capturing short-term temporal \\ndependencies and patterns in the data, which makes them valuable for short-term \\nforecasting.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 2}, page_content='dependencies and patterns in the data, which makes them valuable for short-term \\nforecasting. \\nDrawbacks of Autoregressive Models:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 3}, page_content='• \\nStationarity Assumption: AR models assume that the time series is stationary, \\nmeaning that its statistical properties do not change over time. In practice, many real-\\nworld time series are non-stationary, requiring preprocessing steps like differencing. \\n• \\nLimited to Short-Term Dependencies: AR models are not well-suited for capturing \\nlong-term dependencies in data. They are primarily designed for modeling short-term \\ntemporal patterns. \\n• \\nLag Selection: Choosing the appropriate lag order (p) in an AR model can be \\nchallenging. Selecting too few lags may lead to underfitting, while selecting too many \\nmay lead to overfitting. Techniques like ACF and PACF plots are used to determine the \\nlag order. \\n• \\nSensitivity to Noise: AR models can be sensitive to random noise in the data. This \\nsensitivity can lead to overfitting, especially when dealing with noisy or irregular time \\nseries. \\n• \\nLimited Forecast Horizon: AR models are generally not suitable for long-term'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 3}, page_content=\"series. \\n• \\nLimited Forecast Horizon: AR models are generally not suitable for long-term \\nforecasting as they are designed for capturing short-term dependencies. For long-term \\nforecasting, other models like ARIMA, SARIMA, or machine learning models may be \\nmore appropriate. \\n• \\nData Quality Dependence: The effectiveness of AR models is highly dependent on \\ndata quality. Outliers, missing values, or data irregularities can significantly affect the \\nmodel's performance. \\nConclusion \\nAutoregressive (AR) models provide a powerful framework for analyzing and forecasting time \\nseries data. We explored the fundamental concepts of AR models, from understanding \\nautocorrelation to fitting models and making future predictions. By generating a simulated \\ntemperature dataset, we were able to apply AR modeling. AR models are particularly useful \\nwhen dealing with stationary time series data, where past values influence future observations.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 3}, page_content='when dealing with stationary time series data, where past values influence future observations. \\nThe choice of lag order is a crucial step, and it can be determined by examining the \\nAutocorrelation Function (ACF) plot. \\nAs we demonstrated, AR models offer a practical approach to forecasting. However, they have \\ntheir limitations and are most effective when the underlying data exhibits some degree of \\nautocorrelation. \\nFor \\nmore \\ncomplex \\ntime \\nseries \\ndata, \\nother \\nmodels \\nlike ARIMA or SARIMA may be more appropriate. \\nThe ability to make accurate forecasts is a valuable asset in various domains, from finance to \\neconomics and beyond. By mastering Autoregressive models and understanding their \\napplications, analysts and data scientists can make informed decisions based on historical data, \\nhelping to anticipate future trends and make better choices. \\n \\nUnderstanding the Moving average (MA) in Time Series Data'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 3}, page_content='helping to anticipate future trends and make better choices. \\n \\nUnderstanding the Moving average (MA) in Time Series Data \\nData is often collected with respect to time, whether for scientific or financial purposes. When \\ndata is collected in a chronological order, it is referred to as time series data. Analyzing time'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 4}, page_content='series data provides insights into how the data behaves over time, including underlying patterns \\nthat can help solve problems in various domains. Time series analysis can also aid in \\nforecasting future values based on historical data, leading to better production, profits, policy \\nplanning, risk management, and other fields. Therefore, analysis of time series data becomes \\nan important aspect of data science. \\nWhat is the Moving Average Model? \\nMoving Average Models are a type of time series analysis model usually used in econometrics \\nto forecast trends and understand patterns in time series data. In moving average models the \\npresent value of the time series depends on the linear combination of the past white noise error \\nterms of the time series. In time series analysis moving average is denoted by the letter \"q\" \\nwhich represents the order of the moving average model, or in simple words we can say the'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 4}, page_content='which represents the order of the moving average model, or in simple words we can say the \\ncurrent value of the time series will depend on the past q error terms. Therefore, the moving \\naverage model of order q could be represented as: \\nXt=c+ϵt+θ1.ϵt−1+θ2.ϵt−2+...+θq.ϵt−q \\nHere, \\n• \\nXt is the value of time series at time t \\n• \\nc is a constant or the mean of the time series \\n• \\nϵt,ϵt−1,ϵt−2,...,ϵt−q are the white noise terms associated with the time series at time t, \\nt-1, t-2, ... , t-q. \\n• \\nθ1,θ2,...,θq are the moving average constants. \\nFor example, if we consider MA(1) model, in this model the present value of the time series \\nwill only depend on a single past error term and the time series becomes: \\nXt=c+ϵt+θ1.ϵt−1 \\nFrom this observation we can also conclude one of the most important aspects of moving \\naverage models that the higher the value of the order of moving average model (q), the model \\nwill have longer memory and dependence on the past values.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 4}, page_content='will have longer memory and dependence on the past values. \\nInterpretation of MA model: \\nThere is a difference in the shock wave that is seen in the MA model and AR model that we \\ncan mention which might help us get a better understanding how MA and AR model differ. For \\na better understanding let\\'s look at the AR model\\'s general form as well: \\nXt=c+ϕ1.Xt−1+ϕ2.Xt−2+...+ϕp.Xt−p+ϵt \\n• \\nFirst that the past noise term ϵt−1 affects the MA model\\'s present value Xt directly as \\nwe can see in the above equation of the MA model but in AR model the past noise \\nterm(ϵt−1) have an indirect influence on the present AR model value(Xt) since the AR \\nmodel equation depends on the previous value of the model(Xt−1) and the previous \\nmodel value depends on it\\'s noise term(ϵt−1). \\n• \\nThe MA model works a a finite impulse model, which means that the current noise \\nvalue affects the present value of the model as well as \"q\" further values, as the moving'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 5}, page_content=\"average models only depend on q terms in the past. Whereas AR models acts as infinite \\nimpulse model since the current noise affects infinite values of the model in the future. \\nIn AutoRegressive model ϵt value affects the Xt term which affects the Xt+1 term and \\nso on. \\nConcept Related to Moving Average: \\nNow let's discuss about some of the concepts that can help us in understanding the moving \\naverage model in a better way: \\n• \\nStationarity: Stationarity is the principle of time series data that conveys that the \\nstatistical properties of the data doesn't change with time, the mean of the data remains \\nthe same or we can also say that the data fluctuates around a certain value, the standard \\ndeviation of the time series data nearly remains constant, and there must not be any \\nseasonality in the time series data or there is no periodic behavior in the data. We can \\ncheck for the stationarity of the dataset visually as well as through Augmented Dickey-\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 5}, page_content='check for the stationarity of the dataset visually as well as through Augmented Dickey-\\nFuller(ADF) Test. We consider stationarity to be one of the most important aspect that \\nthe time series data must possess in order to be accepted by the models that are applied \\nto time series data for accurate modelling. \\n• \\nDifferencing: Differencing is one of the most important steps to consider during time \\nseries analysis, after taking a peek at the original time series data, if the data is not \\nstationary and contains a lot of trends then differencing must be considered since for \\naccurate time series data analysis the data must be stationary. In regular differencing \\nthe current time series data is subtracted by the previous data point. Δyt=yt−yt−1Δyt=yt\\n−yt−1, this method removes trends from the data, making it suitable for modelling. \\n• \\nWhite Noise: White noise is the error term which has the mean of zero and a constant'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 5}, page_content='• \\nWhite Noise: White noise is the error term which has the mean of zero and a constant \\nstandard deviation with no correlation of the data points with each other. White noise \\nacts as a benchmark in the forecasting process through time series modelling, if the \\nforecast error is nor white noise further modifications could be performed on the model, \\nbut if it reaches a state such that the forecast errors are white noise then the model would \\nneed no further improvements. The value of white noise series are random and \\nunpredictable therefore if any time series data is a white noise then there is no method \\nto model or forecast it.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 6}, page_content=\"White noise time series with mean = 0 and standard deviation = 1 \\n• \\nACF Plot: Autocorrelation Function plot or the ACF plot is the plot of correlation \\nbetween the time series and its lagged version. It shows how similar the time series is \\nwith it's different lagged values. Here the lag term is a fixed time displacement, in the \\nACF plot the x-axis is the lagged time series and the y-axis is the correlation which \\nranges from -1 to 1. \\nAdvantages and Disadvantages of Using MA Model \\nThere are certain advantages and disadvantages of using a moving average model that \\nwe must pay attention to in order to achieve better results in modelling and forecasting \\nthe time series data. \\n \\n \\nAdvantages \\n• \\nNoise Reduction: Moving average models are effective in smoothing out the noise \\nwhich is present in the time series data, thus, it helps in reducing the short term \\nfluctuations in the time series data. \\n•\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 6}, page_content='which is present in the time series data, thus, it helps in reducing the short term \\nfluctuations in the time series data. \\n• \\nStationarity: Moving average models within itself assumes that the time series data is \\nstationary which is a primary requirement in the time series analysis. \\n• \\nEase of Understanding: It is not that tough to understand how the moving average \\nmodels work in comparison to some of the other time series forecasting models. The \\norder of the moving average model is the number of previous error terms on which the \\ncurrent value of the time series depends. \\n• \\nCombination of models: The moving average models could be easily combined with \\nautoregressive and integrated models and the whole of ARIMA modelling could be \\napplied on the time series data.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 7}, page_content=\"Disadvantages \\n• \\nAssumption of Stationarity: In moving average models it is already assumed that the \\ntime series data is stationary, but in reality, most of the real world data are not stationary. \\nTherefore, in order to convert the time series data into stationary data information loss \\nmight happen. \\n• \\nLimited Forecasting Range: Moving average models are suitable for short term \\nforecasting, as the time increases model's forecasting capabilities decreases. \\n• \\nSensitivity to Outliers \\n• \\nIdentification of Model Order: If the model order is not chosen correctly the model \\nmight not be able to predict the time series data effectively. \\nConclusion \\nHence, we can conclude that analysis of the time series data with moving average model \\nis possible but is only suitable for short period of time and the predictions are not good \\nas the time span increases. \\n \\nWhat Are Unit Root Tests? \\nA Unit Root Test is a statistical method employed in econometrics to determine whether a time\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 7}, page_content='What Are Unit Root Tests? \\nA Unit Root Test is a statistical method employed in econometrics to determine whether a time \\nseries dataset is non-stationary and contains a unit root. A unit root indicates that a variable is \\naffected by random shocks and tends to return to its mean over time, suggesting a lack of long-\\nterm trend or stability. These tests are used in econometrics to analyze economic data. \\n \\nYou are free to use this image on your website, templates, etc..   \\nStationary time series data is crucial for accurate modeling and forecasting in statistical \\nanalysis. Hence, researchers, economists, and analysts employ the unit root test to confirm if \\nstatistical properties like mean and variance have remained constant over time. If a series is'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 8}, page_content='non-stationary (contains a unit root), it can lead to misleading regression results and unreliable \\nforecasts. It happens because the statistical properties of non-stationary data change over time. \\nKey Takeaways \\n• \\nA unit root test refers to an econometric measure that aids researchers in identifying \\nwhether a time series is stationary or non-stationary. \\n• \\nSome of the standard methods are the Augmented Dickey-Fuller (ADF), Dickey-Fuller \\n(DF), and Phillips-Perron (PP) tests. \\n• \\nRejecting the null hypothesis of a unit root test indicates stationarity, making the data \\nsuitable for various time series models and analyses. \\n• \\nSuch tests are critical as they ensure the validity of statistical analysis, improve \\nforecasting accuracy, and provide a solid foundation for economic research and \\npolicymaking. \\nUnit Root Tests Explained \\nUnit root tests are essential tools in time series analysis. They are used to determine whether a'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 8}, page_content='policymaking. \\nUnit Root Tests Explained \\nUnit root tests are essential tools in time series analysis. They are used to determine whether a \\nvariable is non-stationary (has a unit root) or stationary. A non-stationary variable (as the name \\nsuggests) is one where the mean, variance, or autocorrelation changes over time. A stationary \\nvariable is one where statistical property remains unchanged over time. \\nThere are many unit root tests in econometrics and time series analysis, as discussed below: \\n1. Augmented Dickey-Fuller (ADF) Test: In the context of the ADF test, a unit root \\nsuggests that the series follows a random walk pattern, where changes from one period \\nto the next are unorganized and unpredictable. \\n2. Dickey-Fuller Test (DF) Test: This is the simpler version of the ADF test, which does \\nnot include additional lagged differences in the regression equation. \\n3. Phillips-Perron (PP) Test: Similar to ADF, the PP test examines a unit root and'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 8}, page_content='3. Phillips-Perron (PP) Test: Similar to ADF, the PP test examines a unit root and \\nrectifies errors like autocorrelation and heteroskedasticity in the given series. It is \\nespecially useful for analyzing non-normal data or data that contains outliers since it is \\nbased on nonparametric regression. Nonparametric regression does not make any \\nassumptions about the underlying distribution of the data in question. \\n4. Elliott-Rothenberg-Stock (ERS) Test: This test is specifically designed to handle \\nstructural breaks in time series data, allowing for a more robust analysis in the presence \\nof such noise. Structural breaks refer to changes in underlying trends or patterns of a \\ntime series.  \\n5. Zivot-Andrews Test: It is used when there might be a single structural break in the \\ndata. It is an extension of the ADF test that allows for a structural break at an unknown \\npoint in the series. A structural break is a sudden and permanent change in the level or \\ntrend of a time series.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 9}, page_content='Examples \\nA unit root test makes the analytical process seamless and efficient. Let us understand its \\napplication in certain scenarios. \\nExample #1 \\nSuppose Laura, the sales head of ABC Co., uses the unit root test to analyze time series datasets \\nfor one of her retail stores. In this case, she wishes to analyze the monthly sales data. She \\napplies the Augmented Dickey-Fuller (ADF) test to the sales data. The purpose of this test is \\nto determine whether the data exhibits a unit root, indicating a random walk and non-stationary \\nbehavior, or if it is stationary over time. \\nThe unit root test null hypothesis of the ADF test asserts that unit roots exist in the time series \\nsample. If the calculated test statistic is significantly lower than the critical values, the null \\nhypothesis can be rejected. This rejection implies that the data is stationary, without a unit root, \\nmaking it valuable for accurate forecasting and understanding the underlying patterns in the \\nsales data.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 9}, page_content='making it valuable for accurate forecasting and understanding the underlying patterns in the \\nsales data. \\nNow, let us see what Laura achieves by doing this. She ensures that the sales data is stationary \\nbefore making important decisions. This is because stationary data will likely be more accurate, \\nimproving the quality and relevance of business decisions. \\nExample #2 \\nSuppose the stock price movements of a specific stock in the last ten years without a constant \\ntrend are: \\nTime \\nStock Price \\n∆ Stock Price ($) \\n1 \\n$78 \\n \\n2 \\n$77 \\n-1 \\n3 \\n$81 \\n4 \\n4 \\n$87 \\n6 \\n5 \\n$85 \\n-2'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 10}, page_content='Time \\nStock Price \\n∆ Stock Price ($) \\n6 \\n$89 \\n4 \\n7 \\n$92 \\n3 \\n8 \\n$95 \\n3 \\n9 \\n$92 \\n-3 \\n10 \\n$94 \\n2 \\nSince the series has no constant trend, one can use the formula δYt-1＋ut to find the time series. \\nUsing this test, analysts identify patterns in price movements, determining whether such data \\nis stationary or non-stationary. It enables them to make decisions and market predictions. \\nApplications \\nListed below are some ways in which the unit root tests can be used: \\n• \\nIt is used for forecasting economic variables by establishing the order of integration. \\n• \\nIt helps analyze the long-term behavior of economic variables. \\n• \\nUnit root tests enable the examination of stock prices, exchange rates, and other \\nfinancial variables to assess future trends in these areas. \\n• \\nThese tests are applied to macroeconomic variables such as GDP, inflation, \\nand unemployment rates to understand their long-term patterns and relationships. \\n•'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 10}, page_content='and unemployment rates to understand their long-term patterns and relationships. \\n• \\nThey are used with asset pricing models to determine the stationarity of the variables \\nused in these models. \\n• \\nEnvironmental studies use these tests to analyze time series data related to pollution, \\nclimate, and other environmental factors. \\n• \\nMonitoring, controlling, and improving the quality of products in manufacturing over \\ntime is possible by studying the results obtained from unit root tests. \\n• \\nA major application that helps on a macroeconomic level is the analysis of patterns in \\ndisease prevalence, patient outcomes, or healthcare costs. \\nHowever, like other statistical techniques, this measure is also prone to certain limitations. \\nPrimarily, its outcomes can be sensitive to the sample size, leading to different results even \\nwith minor variations in input variables. Also, it assumes that the underlying process is linear,'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 10}, page_content='with minor variations in input variables. Also, it assumes that the underlying process is linear, \\nwhich may not always be the case. It even fails to provide information about the order of \\nintegration or the presence of structural breaks in the data. \\nFurther, its interpretation is quite challenging and requires strong econometrics knowledge. \\nMoreover, the outcomes may not always be definitive, requiring extensive analysis and testing \\nwith other methods. \\nStill, unit root tests are used extensively in situations where time series analysis is needed. \\nHence, using it in conjunction with other testing methodologies may prove wise. \\nImportance'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 11}, page_content='Unit root tests are essential tools in time series analysis and econometrics. They play a crucial \\nrole in determining whether a given time series dataset is stationary or non-stationary. Its \\nimportance can be outlined as follows: \\n1. Critical for Time Series Modeling: It facilitates employing time series models such \\nas Vector Auto-Regression (VAR) and Auto-Regressive Integrated Moving Average \\n(ARIMA), which requires the data to be stationary, showing constant mean and \\nvariance over time. \\n2. Avoids Spurious Regression: Since non-stationary time series can lead to false \\nregression outcomes, where unrelated series appear correlated simply because they both \\nhave trends, stationary testing helps identify and address this issue. \\n3. Enhances Forecasting Accuracy: The stationary series tend to exhibit more \\npredictable patterns, making them easier to forecast accurately. Hence, the unit root \\ntests assist analysts in selecting appropriate models for such analysis.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 11}, page_content='tests assist analysts in selecting appropriate models for such analysis. \\n4. Facilitates Policy Formulation and Economic Research: In the field of economics, \\nsuch tests are indispensable for making policy decisions and economic research that \\nrely on interpreting the underlying patterns in economic variables identified through \\nthis test. \\n5. Prevents Misinterpretation: These tests provide a systematic approach to assess the \\nstationarity of a time series, saving analysts from misinterpreting results or drawing \\nfalse conclusions about data patterns. Marketing analysts, financial analysts, and \\nresearchers are some examples of professionals who use this testing method to their \\nadvantage. \\n6. Cointegration Analysis: Such tests are fundamental in cointegration analysis that \\nhelps understand the various equilibrium relationships among economic variables. \\nCointegration analysis is useful for identifying long-run relationships between the given'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 11}, page_content='Cointegration analysis is useful for identifying long-run relationships between the given \\ntime series, which helps reduce or eliminate spurious regression. \\nImpact of Unit Root on Estimating Model Parameters \\nThe presence of a unit root in a time series can significantly impact the estimation of model \\nparameters, particularly in econometric and statistical analyses. Here’s why it matters: \\n1. Non-Stationarity and Mis-Specification: A unit root indicates that the series is non-\\nstationary, meaning its statistical properties like mean and variance change over time. \\nModels that assume stationarity, such as ordinary least squares (OLS), may become \\nmis-specified, leading to unreliable estimates. \\n2. Biased and Inefficient Estimates: When a unit root is present but ignored, parameter \\nestimates can become biased and inefficient. For example, regression coefficients may \\nnot converge to their true values as the sample size increases.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 11}, page_content='not converge to their true values as the sample size increases. \\n3. Spurious Relationships: A non-stationary series with a unit root can exhibit spurious \\nrelationships. In such cases, high correlations may appear between unrelated variables, \\nleading to misleading conclusions.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 12}, page_content=\"4. Impact on Hypothesis Testing: Standard statistical tests, like t-tests and F-tests, may \\nlose their validity in the presence of unit roots. Critical values used to assess \\nsignificance may no longer apply, increasing the likelihood of Type I or Type II errors. \\n5. Long-Term Impact on Models: Models like ARIMA (AutoRegressive Integrated \\nMoving Average) specifically account for unit roots by differencing the series. Ignoring \\nthe unit root can hinder the model's ability to accurately capture the underlying process. \\nTo address these challenges, it’s essential to: \\n• \\nTest for unit roots using methods like the Augmented Dickey-Fuller (ADF) or Phillips-\\nPerron tests. \\n• \\nApply transformations, such as differencing or detrending, to achieve stationarity. \\n• \\nUse models explicitly designed for non-stationary data, like cointegration models or \\nerror-correction models. \\n \\nTests for Stationarity in Time Series — Dickey Fuller Test & Augmented Dickey \\nFuller(ADF) Test \\n \\nDickey Fuller Test\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 12}, page_content='error-correction models. \\n \\nTests for Stationarity in Time Series — Dickey Fuller Test & Augmented Dickey \\nFuller(ADF) Test \\n \\nDickey Fuller Test \\nDickey Fuller test is a statistical test that is used to check for stationarity in time series. This is \\na type of unit root test, through which we find if the time series is having any unit root. \\n \\nUnit root is a feature of time series that indicates if there is any stochastic trend in the time \\nseries that drives it away from its mean value. Presence of unit root makes a time series non-\\nstationary and as a result it leads to difficulties in deriving statistical inferences from the time \\nseries and future predictions. \\n \\nDickey Fuller test assumes a AR(1) type time series model and it is represented mathematically \\nas, \\n \\n \\nAfter we substract yt-1 from both the side, we get:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 13}, page_content='where, \\n \\nµ: Constant \\n \\nϕ: Co-efficient \\n \\nyt-1: Value in the time series at lag of 1 \\n \\nEt: Error component \\n \\nThe test statistic formula is: \\n \\n \\nAugmented Dickey Fuller(ADF) Test \\nAugmented Dickey Fuller(ADF) test is an extension of Dickey Fuller test for more complex \\nmodels than AR(1). The primary difference between the two tests is that the ADF is utilized for \\na larger sized set of time series models which can be more complicated. \\n \\nAugmented Dickey Fuller test assumes a AR(p) type time series model and it is represented \\nmathematically as, \\n \\n \\nAfter we substract yt-1 from both the side, we get:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 14}, page_content='ADF is the same equation as the DF with the only difference being the addition of differencing \\nterms representing a larger time series. \\n \\nThe test statistic formula is: \\n \\n \\nAssumptions \\nThe test is conducted under following assumptions: \\n \\nNull Hypothesis (H0): There exists a unit root in the time series and it is non-stationary. Unit \\nroot = 1 or δ = 0 \\nAlternate Hypothesis (H1): There exists no unit root in the time series and it is stationary. Unit \\nroot < 1 or δ < 0 \\nCondition to reject H0 and accept H1 \\nIf the test statistic is less than the critical value or if the p-value is less than a pre-specified \\nsignificance level (e.g., 0.05), then the null hypothesis is rejected and the time series is \\nconsidered stationary. \\n \\nIf the test statistic is greater than the critical value, the null hypothesis cannot be rejected, and \\nthe time series is considered non-stationary. \\n \\nThe critical value is found from the Dickey Fuller table (similar to t-table that we use for t-test,'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 14}, page_content='The critical value is found from the Dickey Fuller table (similar to t-table that we use for t-test, \\nwe have a table with critical values for Dickey Fuller test). \\n \\n \\nUnit Root Tests in Time Series Analysis: Detailed Explanation \\nIn time series analysis, determining whether a series is stationary or has a unit root is critical for \\nbuilding accurate models. The presence of a unit root indicates non-stationarity, which can lead to \\nspurious regression results. To detect unit roots, several statistical tests are commonly used, including: \\n1. Dickey-Fuller (DF) Test \\n2. Augmented Dickey-Fuller (ADF) Test'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 15}, page_content='3. Phillips-Perron (PP) Test \\n4. KPSS (Kwiatkowski-Phillips-Schmidt-Shin) Test \\nLet’s elaborate on each of these tests. \\n \\n1. Dickey-Fuller (DF) Test \\nObjective: \\n• \\nThe Dickey-Fuller Test checks for the presence of a unit root in a time series. \\nHypotheses: \\n• \\nH0: The series has a unit root (Non-stationary) \\n• \\nH1: The series does not have a unit root (Stationary) \\nDecision Rule: \\n• \\nIf the test statistic is less than the critical value, reject H0 and conclude the series is stationary. \\n• \\nIf the test statistic is greater than the critical value, fail to reject H0 (series has a unit root). \\nLimitations: \\n• \\nDF test assumes no autocorrelation in the error term. \\n• \\nIt may not perform well with autocorrelated errors. \\n \\n2. Augmented Dickey-Fuller (ADF) Test \\nObjective: \\n• \\nThe ADF Test is an improved version of the Dickey-Fuller test that accounts for higher-order \\nautocorrelation.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 16}, page_content='Hypotheses: \\n• \\nH0: The series has a unit root (Non-stationary) \\n• \\nH1: The series does not have a unit root (Stationary) \\nDecision Rule: \\n• \\nSimilar to the DF test, check the test statistic against critical values. \\nAdvantages: \\n• \\nControls for serial correlation by including lag terms. \\n• \\nMore reliable for larger datasets. \\nLimitations: \\n• \\nChoosing the right number of lags is essential. \\n• \\nOverdifferencing may remove useful information. \\n \\n3. Phillips-Perron (PP) Test \\nObjective: \\n• \\nThe Phillips-Perron Test also tests for a unit root, but it makes non-parametric adjustments to \\nthe test statistics to correct for heteroskedasticity and autocorrelation without adding lagged \\nterms. \\nHypotheses: \\n• \\nH0: The series has a unit root (Non-stationary) \\n• \\nH1: The series does not have a unit root (Stationary)'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 17}, page_content='Key Difference from ADF: \\n• \\nInstead of adding lagged differences, the PP test directly adjusts the t-statistic using non-\\nparametric techniques to correct for autocorrelation and heteroskedasticity. \\nDecision Rule: \\n• \\nReject H0 if the test statistic is lower than the critical value. \\nAdvantages: \\n• \\nSuitable for large datasets with heteroskedasticity. \\n• \\nNo need to specify the lag length. \\nLimitations: \\n• \\nCan be less effective in small samples. \\n \\n4. KPSS (Kwiatkowski-Phillips-Schmidt-Shin) Test \\nObjective: \\n• \\nUnlike the previous tests, the KPSS Test assumes the null hypothesis of stationarity and tests \\nfor the presence of a unit root as the alternative hypothesis. \\nHypotheses: \\n• \\nH0: The series is stationary \\n• \\nH1: The series has a unit root (Non-stationary) \\nDecision Rule:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-29T15:55:20+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes unit 2.pdf', 'total_pages': 19, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-29T15:55:20+05:30', 'trapped': '', 'modDate': \"D:20250329155520+05'30'\", 'creationDate': \"D:20250329155520+05'30'\", 'page': 18}, page_content='• \\nIf the test statistic exceeds the critical value, reject H0 and conclude the series is non-stationary. \\n• \\nIf the test statistic is less than the critical value, accept H0 and conclude the series is stationary. \\nAdvantages: \\n• \\nComplements other tests like ADF and PP by providing a different perspective. \\n• \\nEffective for identifying mean-reverting behavior. \\nLimitations: \\n• \\nSensitive to lag selection. \\n \\nComparison of Unit Root Tests \\nCriteria \\nDF Test \\nADF Test \\nPP Test \\nKPSS Test \\nNull Hypothesis \\nUnit Root \\nUnit Root \\nUnit Root \\nStationarity \\nAlternative Hypothesis \\nStationarity \\nStationarity \\nStationarity \\nUnit Root \\nAccounts for \\nAutocorrelation \\nNo \\nYes \\nYes \\nNo \\nAdjusts for \\nHeteroskedasticity \\nNo \\nNo \\nYes \\nNo \\nLag Selection Required \\nNo \\nYes \\nNo \\nYes \\nSuitable for Small \\nSamples \\nModerate \\nGood \\nModerate \\nModerate \\nBest for \\nSimple \\nData \\nAutocorrelated \\nData \\nHeteroskedastic \\nData \\nConfirming \\nStationarity'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 0}, page_content='Unit 1 \\nIntroduction to Time Series Analysis \\n• \\nLearning Objectives \\n• \\nIntroduction \\n• \\nFunctional relationship \\n• \\nClassification of time series \\n• \\nComponents of time series \\n• \\nMathematical model of time series \\n• \\nUtility of time series \\n• \\nRequirement of time series \\n• \\nApplications of time series \\n• \\ntime series data and cross-sectional data, difference between time series and cross-\\nsectional data, time series and stochastic process, \\n• \\nMeans, variances, covariance, stationarity, importance of stationarity in time series \\nanalysis \\n• \\nwhite noise process, random walk  \\n• \\nelementary time series models with zero mean \\n• \\nmodel evaluation techniques: Bias, MAD, MSE, MAPE \\n• \\nSummary \\n• \\nSuggested Readings \\n \\nLearning Objectives \\n  \\nThe objective of this module is to give basic introduction of Time series analysis and explain its meaning \\nand concepts to understand its vast application areas. Classification of time series and components of'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 0}, page_content='and concepts to understand its vast application areas. Classification of time series and components of \\ntime series will be discussed in detail. Mathematical model of time series. Utility, requirement of time \\nseries and its application will also be discussed for in depth knowledge of this topic. \\n  \\n Introduction \\n  \\nIn general, Series is a sequence of observations in a specific order. Similarly, Time series is a sequence \\nof observations in specific order but these observations are time dependent. Actual time series is \\nrealization of stochastic process. In different sectors like Economics, Commerce and Environment \\nevents happen over a period of time. For example- temperature of a day at different time interval and \\nprice of commodity in one month to other month or it may be day or year, production of crop varies \\nover year, production of an item in an industry increase or decrease depending on the demand of the'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 1}, page_content='product, sale of goods depend upon the price as well as need of the product over the time like in change \\nof technology, consumption of items increase with increase in earning over time or decrease due to lack \\nof money like visit to hotels depends upon person’s earning that varies over time. These examples show \\na series of data which are dependent on time, this measurement of variable at different time point is \\nknown as “Time interval” in literature terms. Time interval may be hours, days, quarters, months and \\nyears. In modern literature time series is also referred as both data and process. Hence time series has a \\ngreat importance in Business, Economics and other areas. This is the main reason for the development \\nof many statistics tools specially for these areas exist in literature. Even a particular subject named as \\nEconometrics originate to cater the need of this topic. Econometrics is now among the most widely'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 1}, page_content='Econometrics originate to cater the need of this topic. Econometrics is now among the most widely \\ntaught subject in the colleges and other institutions due to importance of happening of events over a \\nperiod of time. \\n  \\nDefinition: \\n  \\n“A Time Series is a set of statistical observations arranged in chronological order” by Morris Hamburg. \\n“A time series may be defined as a collection of reading belonging to different time periods, of some \\neconomic variables or composite of variables” by Ya-lun Chou. \\n“Time series is a chronological sequence of observations of quantitative variables that are recorded \\nsuccessively at regular and specified time interval”. \\n  \\n Classification of the Time series: \\n  \\nTime series can be classified in two types, first is according to dependency on time and second is \\naccording to variable numeracy. \\n Dependency on time can be further categorized into: \\n1. Discrete time series \\n2. Continuous time series  \\nVariable numeracy has further two categories'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 1}, page_content='1. Discrete time series \\n2. Continuous time series  \\nVariable numeracy has further two categories \\n1. Univariate time series \\n2. Multivariate time series \\n We will now discuss these classification in detail: \\n❖ Discrete time series: A Time series is discrete time series when variable dependency on time \\nis of discrete form. A variable is said to be discrete if it takes only integer values like days, \\nmonths etc. For example- closing price of daily stock market. \\n❖ Continuous time series: A Time series is continuous time series when variable depends on \\ntime is of continuous nature. A variable is said to be continuous if it takes values in continuous \\nform like in second, minutes etc. For example- hourly reading of temperature.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 2}, page_content='❖ Univariate time series: A time series is univariate time series when there is only one type of \\nstudy variable or one characteristics under consideration. For example: share price of one \\ncompany. \\n❖ Multivariate time series: A Time series is multivariate time series when there is more than \\none type of study variable that is of interest in time series. For example- share price of one \\ncompany, share price of other company. \\n \\n \\n \\nComponents of time series: \\nStudy variable take different values in a particular time series. This difference in value is not due to \\nonly one component like time but affected by more than one component or multiple components. These \\nmultiple components pull up and down the values of the characteristics under study. For example: the \\ncrop yield depends on weather condition, seed quality, land quality, fertilizer etc. Here crop yield is \\nstudy variable and weather condition, seed quality, land quality are other multiple components that are'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 2}, page_content='study variable and weather condition, seed quality, land quality are other multiple components that are \\nalso responsible for the yield of the crop. \\n \\n \\n \\nThese multiple components are classified into four categories. Such as: \\n1) Secular Trend (long term movement) \\n2) Seasonal variation (short term movement) \\n3) Cyclic variation \\n4) Random or Irregular Movements \\n  \\nThese four categories are known as components of time series. Now let’s discuss components of time \\nseries one by one with examples.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 3}, page_content='• \\n1) Secular trend: \\n  \\nSecular trend or generally trend is a long term movement. In general, Trend shows tendency of the time \\nseries data in long term period. This tendency may be downward and upward. It should be kept in mind \\nthat this tendency of upward and downward movement should not remain same throughout the time \\nspan. It is also possible that it can be observed in different time section or time span. However one can \\nsay that the overall tendency of the series seem like moving upward or downward but in actual there \\nare many factor that persist for a long period. Tendency depends on the effects of the factor. If effect of \\nfactors on time series data is of increasing then it shows upward tendency, if is on decreasing then it \\nshows downward tendency. \\n Trend consists of Long term effects. Long term cannot be defined exactly because in some cases 2 year \\ntime may be enough and for some cases it is not enough.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 3}, page_content='time may be enough and for some cases it is not enough. \\n For some cases 5 minutes is a very long period, for other case it may not be appropriate. The term of \\nlong or short period of time depends on the nature or objective of the data. In some cases, a period of \\nhours can be considered as very large while in other cases even the period of years is not sufficient to \\nbe named as long time. For example if data of agriculture production \\n  \\nof 24 month shows increment in the growth of the crop then it is not considered as secular trend for 2 \\nyears, the count of bacterial population of a culture in every five minutes, if this tendency of increment \\npersist for a week then it is a secular trend. One important thing is that the values for short period (may \\nbe 2-3 years in some cases) are mainly affected by cyclic variations. Hence the values are not able to \\nreveal true trend. In order to solve this problem, one should consider the multiple cycle periods to see'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 3}, page_content='reveal true trend. In order to solve this problem, one should consider the multiple cycle periods to see \\nthe impact of cyclic variations on the values. For some cases, due to nature of  the data like increment \\nof bacterial population persists due to strong germicide in an hour then reading in every five minutes or \\nin seconds would lead to a general pattern that can be termed as a secular trend. \\n This tendency of the data may be linear and nonlinear trend. It depends on the nature of the data. If the \\ntime series values are plotted on the graph with more concentration around a straight line then trend \\npattern of time series values are said to be linear on the other hand if the time series values are not close \\nto straight line then it is called non-linear trend like increase in the price of gold, crude oil in the \\ninternational market is not constant and varies with different phases of time. Hence the trend of time'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 3}, page_content='international market is not constant and varies with different phases of time. Hence the trend of time \\nseries will help you to get a general idea about the pattern of the behavior of the data under \\nconsideration. This will help in forecasting and future planning of different sectors like business,'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 4}, page_content='weather and economy based on previous values. With the use of trend analysis one can compare two or \\nmore time series over different time periods and draw important conclusions based on them. \\n  \\n• \\n2) Seasonal variation: \\n  \\nSeasonal variation is a short term movement in a time series. Short term movement means observational \\ndata collects in less than one year of time period i.e. data collected monthly, quarterly, weekly, daily, \\nhourly etc. If collected data are annual then there is no seasonal variation. As the name suggests, \\nseasonal variation means variation that occur due to change in season and natural forces in any study \\nvariable. For example prices, production and consumption of any commodities, sales and profit in any \\ndepartmental store etc. \\n  \\nSome variations in data are due to natural forces like seasons. For example: sale of umbrella increases \\nin rainy season, consumption of ice-cream increases in summer, price of woolen increases in winter.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 4}, page_content='in rainy season, consumption of ice-cream increases in summer, price of woolen increases in winter. \\nSome variation are due to man-made convention such as sale of jewellery and price of clothes go up \\ndue to marriage season and in festival like Diwali, Christmas, and Durga Pooja. \\n  \\nThe following image shows sales of clothes changing in different seasons \\n \\n \\n• \\n3) Cyclic variation: \\nCyclic variation is a repeated pattern in a time period of a time series, this time period will be more than \\none year. The data of sale of ice cream for few years shows that the sale of ice-cream is high in summer \\nand low in winter. Therefore this data shows some repeated pattern in time series data, this pattern is \\nknown as cyclic variation . \\n  \\nGenerally cyclic variation shows in business cycle. Business cycle have four phases. Hence this is \\nreferred as four phase cycle such as prosperity, recession, depression and recovery. Each phase in'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 4}, page_content='referred as four phase cycle such as prosperity, recession, depression and recovery. Each phase in \\nbusiness cycle persists for a very long term variation approximately 5 to 7 years. On the other side,'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 5}, page_content='cyclic variation may be short term and long term movement that depend on time period but time period \\nmust be greater than one year. \\n \\n• \\n4) Irregular component: \\n  \\nIrregular component is also known as random or residual component. Every time series must contain \\nthis fluctuation and this fluctuation cannot be removed from the data. Irregular component can be found \\nby removing all three components, so that irregular component is not affected by other three \\ncomponents of time series.  \\nIrregular component is beyond the control of human being and considered as unpredictable. This type \\nof fluctuation may be seen due to effect of factors like earthquake, wars, floods, famines, political unrest \\nrevolution, epidemics etc. \\nIrregular variation are unpredictable due to its accidental variation. For example- rise in prices of LPG \\ngas cylinder due to strike of workers etc. \\n \\n \\nMathematical model of time series:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 5}, page_content='gas cylinder due to strike of workers etc. \\n \\n \\nMathematical model of time series: \\n  \\nIn analysis of time series, there are types of problems like to identify the components and their effect \\non the data sets, to isolate, analyze and measure them independently. In literature, there are some \\nmathematical model to decompose the time series into its components.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 6}, page_content='Additive model: Additive model of a time series can be expressed as: \\nYt=Tt+St+Ct+Rt \\nwhere: \\n• \\nYt = observed value at time t, \\n• \\nTt= trend component (captures long-term growth or decline)/ is trend value at time t. \\n• \\nSt = seasonal component (captures periodic fluctuations)/ is seasonality value at time t. \\n• \\nRt = residual or random component (captures irregular fluctuations)/ is random or irregular \\nvalue at time t. \\n• \\nCt= is cyclic value at time t. \\nAll four component of time series in additive model operate independently to each other. Thus, in \\nadditive model , there is no effect of one component to other component. Additive model can be used \\nto measure one or more component by elimination i.e. by subtraction. \\nFor example- time series decomposition of additive model with visualization as in the following image: \\n \\nMultiplicative model: \\n  \\nIf all component of time series operate proportionally to the general level of the series, multiplicative'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 6}, page_content='Multiplicative model: \\n  \\nIf all component of time series operate proportionally to the general level of the series, multiplicative \\nmodel is appropriate. Multiplicative model can be expressed as: \\nYt=Tt×St×Rt×Ct \\nwhere: \\n• \\nYt = observed value at time t, \\n• \\nTt = trend component (captures long-term growth or decline), \\n• \\nSt= seasonal component (captures periodic fluctuations),'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 7}, page_content='• \\nRt= residual or random component (captures irregular fluctuations). \\n• \\nCt= cyclic value at time t. \\nOr  \\nYt is the value of time series at time t. \\nTt,St,Ct,Rt, and is the value of trend, seasonal ,cyclic and irregular component respectively. \\nMultiplicative decomposition of time series is same as the additive decomposition of logarithmic values \\nof the original time series that is: \\n \\nFor example: time series transform Multiplicative to Additive decomposition by using logarithmic with \\nvisualization is given in Figure 7. \\n It means that when the observations are related with each other in proportionate manner then by taking \\nlog of the observation we can convert the multiplicative model into additive model as it is easier to \\ndetect the components in additive models than multiplicative model. By taking log of observations one \\ncan smooth the curve. In practical cases, it is most widely used concept to take log of observations to'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 7}, page_content='can smooth the curve. In practical cases, it is most widely used concept to take log of observations to \\ndetermine the model that fits in an appropriate manner on the observations. \\n Most of time series related to business and economic confirms to multiplicative model. Multiplicative \\nmodel are used in measure of one or more components i.e. by division. For example if trend value is \\nknown then isolate them: \\n= If data is annual then seasonal components is not there i.e. \\nFor example-assume birth time series decomposition of Multiplicative model with visualization as in \\nthe following image:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 8}, page_content='Hence from Figures 6-8, one can understand the mathematical model of time series components. One \\ncan choose an appropriate model based on the relationship among components in the data values. \\n  \\nUtility of time series: \\n  \\nUtility of time series is given as: \\n  \\n1) It helps in understanding past behavior of the time series: to understand the past behavior \\nof any time series, to analyze variation between data sets over a period of time. \\n2) It helps in future prediction: by observing past behavior of time series data we may see \\nhow observation are varying. According to behavior of data one can use this information for \\nforecasting. We know that time series depend on past data. For better prediction of values one \\nrequire long period data. \\n3) It helps in understand current situation of the problem: the actual performance can be \\nanalyzed by taking difference between expected performance and cause of variation of the data. \\n4) It facilitates comparisons between different time series'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 8}, page_content='4) It facilitates comparisons between different time series \\n  \\nRequirements of time series: \\n  \\nTime series have following requirements: \\n  \\n1) Data must consist of a homogenous set of values. \\n2) The data should be available for sufficiently long period. \\n3) Time gap between various values must, as far as possible be equal. \\n4) The gaps, if any, in data should be made up by interpolation.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 9}, page_content='Application of Time series: \\n  \\nTime series analysis has wide application area. Most important area of time series analysis is economic \\nand business. Some other application areas are: weather forecasting, pattern recognition, earthquake \\nprediction, mathematical science and mathematical finance. Time series analysis is mostly used in \\nforecasting or predication. \\n \\nTime Series Data vs. Cross-Sectional Data  \\nTime series data is data collected at regular intervals over time. On the other hand, cross-sectional \\ndata is a snapshot of a group of things or people at the same point in time. \\nFor example, a time series dataset of the number of cars sold each month over the course of 5 years \\nconsists of 60 data points (one for each month). Meanwhile, cross-sectional data is a dataset composed \\nof not only the number of cars sold in one month, but also information on the car model, price, color, \\nand other variables. \\nWhat is Time Series Data'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 9}, page_content='and other variables. \\nWhat is Time Series Data \\nTime series data allows you to track changes over time. It consists of observations on one or several \\nvariables over time—the most common frequencies being hourly, daily, weekly, monthly, quarterly \\n(every 3 months), and annual. \\nHere are two examples of time series data: \\n• \\nThe daily closing price of Apple’s stock over the course of a year. This data set consists of the \\nstock price recorded at the end of each trading day for 365 days. \\n• \\nThe monthly revenue of a Walmart over the course of one year. The data includes the total sales \\nfor the company recorded at the end of each month for 12 months. \\nIn both of these examples, we collect the data at regular intervals (daily or monthly) and cover a certain \\nperiod of time (a year). This allows us to see how the stock price or sales of the company change over \\ntime.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 10}, page_content='Time Series Data \\nYou can use time series data to identify patterns in financial data, and make predictions about future \\nvalues based on past behavior. \\nWhat is Cross-Sectional Data \\nCross-sectional data allows you to compare data at one point in time. It consists of observations of \\nmultiple variables at one specific point in time. \\nThe data reflects the characteristics of individuals at a single moment, rather than over a period of time. \\nHere are two examples of cross-sectional data: \\n• \\nA survey of households to learn about their saving and investment habits. The survey collects \\ndata on the types of investment products that households have, how much they save and invest, \\nand their attitudes toward risk. \\n• \\nA study of the financial performance of companies in the tech industry. The study collects data \\non the revenue, profits, debt levels, and market share of the companies. \\nBoth examples are ways to understand the financial characteristics of a group of people or companies'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 10}, page_content='Both examples are ways to understand the financial characteristics of a group of people or companies \\nat a specific point in time.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 11}, page_content='Cross-Sectional Data \\nThis type of data does not provide information on how these characteristics change over time though. \\nDifference Between Cross-Sectional and Time Series Data \\nAttribute \\nCross-Sectional Data \\nTime Series Data \\nDefinition \\nData collected at a specific point in time, \\ncapturing information from multiple individuals, \\nentities, or observations. \\nData collected over a period of time, \\ncapturing information from a single \\nindividual, entity, or observation. \\nObservations Multiple observations at a single point in time. \\nSingle observation over multiple points in \\ntime. \\nFocus \\nComparing different individuals, entities, or \\nobservations at a specific time. \\nExamining changes in a single individual, \\nentity, or observation over time. \\nVariables \\nMultiple variables measured simultaneously for \\neach observation. \\nSingle or multiple variables measured over \\ntime for each observation. \\nAnalysis \\nTypically used for cross-sectional analysis, such'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 11}, page_content='Single or multiple variables measured over \\ntime for each observation. \\nAnalysis \\nTypically used for cross-sectional analysis, such \\nas comparing groups or identifying correlations. \\nCommonly used for time series analysis, \\nsuch as forecasting, trend analysis, or \\nidentifying patterns. \\nExamples \\nSurvey data collected from different households \\nat a specific point in time. \\nStock prices recorded daily over a period of \\nseveral years. \\n \\n \\nIntroduction to Time Series Analysis and key concepts'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 12}, page_content='Stationarity, Random walk, White noise, Time Series models and Evaluation of models. \\nIn this article, we are going to examine what is time series analysis?, its scope in the future? and key \\nconcepts of time series analysis. \\nTable of Contents: \\n1. Introduction: What is time series analysis and its importance? \\n2. What is stationarity in time series and its types? \\n3. White Noise & Random Walk \\n4. AutoCorrelation Function(ACF) & Partial auto correlation function(PACF) \\n5. Models: \\nAutoRegression(AR), \\nMoving \\nAverage(MA), \\nAutoRegression-Moving \\nAverage(ARMA) , Autoregressive–moving-average model with exogenous inputs (ARMAX) \\nand Auto Regressive Integrated Moving Average(ARIMA) \\n6. Model diagnostics \\n1] Introduction: \\nTime series analysis is a statistical technique that deals with time series data, or trend analysis. In Time \\nseries,data is in a series of particular time periods or intervals.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 12}, page_content='series,data is in a series of particular time periods or intervals. \\nTime series analysis is used for various applications such as stock market analysis, pattern recognition, \\nearthquake prediction, economic forecasting, census analysis and so on. \\nA time series consists of the following components: \\n \\nImage showing Trend, Seasonality and Cyclicality (Photo by Panwar Abhash Anil )'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 13}, page_content='• \\nTrend: The trend shows the general tendency of the data to increase or decrease during a long \\nperiod of time. A trend is a smooth, general, long-term, average tendency. It is not always \\nnecessary that the increase or decrease is in the same direction throughout the given period of \\ntime. \\n• \\nSeasonality: Patterns that repeats frequently at regular intervals. For example: high sales every \\nweekend. \\n• \\nCyclicality: Cyclicality is where there is a repeating pattern but no fixed period. \\nScope of the Time Series Analysis: \\n• \\nStock Market Analysis \\n• \\nEconomic Forecasting \\n• \\nInventory studies \\n• \\nDemand Forecasting \\n• \\nSales Forecasting and more \\nTime Series and Stochastic Process'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 14}, page_content='2] Means, Variances, and Covariance in Time Series & Stationarity: \\n \\nMeans, Variances, and Covariance in Time Series'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 16}, page_content='Stationary means that the distribution of the data does not change with time. \\n \\nStationary v/s Non-Stationary (Photo by Panwar Abhash Anil) \\n• \\nNo Trend: It is not growing or shrinking. \\n• \\nMean & Variance constant: The average distance of the data points from the zero line is not \\nchanging. \\n• \\nAutoCorrelation Constant: How each value in time series is related to its neighbors stays the \\nsame. \\n◦ Types of stationary: \\n• \\nStrong stationary: Entire distribution of data is time-invariant. \\n• \\nWeak stationary: mean, variance and autocorrelation are time-invariant (i.e., for \\nautocorrelation, corr[(X(t), X(t−τ )] is only a function of τ ) \\n◦ Test for stationarity: Augmented Dicky Fuller test'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 17}, page_content='• \\nNull hypothesis is that the time series is non-stationary. \\n• \\nAlternate hypothesis is that the time series is non-stationary. \\n• \\nDicky-Fuller test only used to test trend. \\n◦ Making time series stationary: \\nIdentifying whether a time series is stationary or not is very important. If it is stationary then we can \\nuse models that take assumptions that time series need to be stationary to predict the next values of the \\ntime series using historical data. If it is non-stationary then make it stationary on applying below \\ntransformations then use a model. \\n• \\nStationarity through differencing time series \\n• \\nTaking log of time series \\n• \\nTaking Square root of time series \\n• \\nTaking the proportional change (df.shift(1)/df) \\n3] White noise and random walk: \\nWhite Noise: A time series is white noise when sequence of uncorrelated random variables that are \\nidentically distributed. Stock returns are often modeled as white noise. Unfortunately, for white noise,'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 17}, page_content='identically distributed. Stock returns are often modeled as white noise. Unfortunately, for white noise, \\nwe cannot forecast future observations based on the past — autocorrelations at all lags are zero. \\nWhite Noise is a series with: \\n• \\nConstant mean \\n• \\nConstant variance \\n• \\nZero autocorrelations at all lags \\nSpecial Case: if data has normal distribution, then white noise is termed as gaussian white noise. \\nRandom Walk: A random walk is another time series model where the current observation is equal \\nto the previous observation with a noise. \\n• \\nIn a random walk, today’s price is equal to yesterday’s price plus some noise. \\n• \\nCan’t forecast a random walk \\n• \\nIncidentally, if prices are in logs, the difference in log price is one way to measure return. \\n• \\nTo test whether the time series is random walk, you can regress current values on lagged values. \\nIf the slope coefficient (beta) is not significantly different from one then we cannot reject the'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 17}, page_content='If the slope coefficient (beta) is not significantly different from one then we cannot reject the \\nnull hypothesis that the series is a random walk. However if the slope is less than one we can \\nreject the null hypothesis. \\n4] AutoCorrelation Function & Partial auto correlation Function: \\nAutocorrelation: Autocorrelation is the correlation of a single time series with a lagged copy of itself. \\nIt is also called single correlation \\nACF is a complete auto-correlation function which gives us values of auto-correlation of any series \\nwith its lagged values. We plot these values along with the confidence interval. In simple terms, it \\ndescribes how well the present value of the series is related with its past values. A time series can have'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 18}, page_content='components like trend, seasonality, cyclic and residual. ACF considers all these components while \\nfinding correlations hence it’s a ‘complete auto-correlation plot’. \\nACF shows not only at one lag autocorrelation, but the entire autocorrelation function for different lags. \\nPACF is a partial auto-correlation function. PACF is a conditional correlation which gives the partial \\ncorrelation of a stationary time series with its own lagged values, regressing the values of the time series \\nat all shorter lags. It contrasts with the autocorrelation function, which does not control for other lags. \\n5] Models: \\nTime series models look at past patterns of data and attempt to predict the future based upon the \\nunderlying patterns contained within those data. \\n5.1) AR model: \\nIn an autoregressive model, we regress the values of the time series against previous values of the same \\ntime series. \\nAn autoregressive model predicts future behavior based on past behavior. It’s used for forecasting'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 18}, page_content='time series. \\nAn autoregressive model predicts future behavior based on past behavior. It’s used for forecasting \\nwhen there is some correlation between values in a time series and the values that precede and succeed \\nthem. \\n \\nImage showing AR models (Photo by Panwar Abhash Anil) \\nThe order of the model is the number of times lags (p) used. and for stationary, -1<a1,a2,..,ap<1. If AR \\nparameter (p) is 0, then the process is white noise. \\n5.2] MA Model: \\nIn the MA model, we regress the values of the time series against the previous shocks/residual values of \\ntime series.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 19}, page_content='Image showing MA models (Photo by Panwar Abhash Anil) \\nThe order of the model is the number of times lags (q) used. and for stationary, -1<m1,m2,..,mq<1. If \\nMA parameter (p) is 0, then the process is white noise. \\n5.3] ARMA Model: \\nAn ARMA model is a combination of AR and MA models. The time series is regressed on the previous \\nvalues and the previous shock term. \\n \\nImage showing ARMA models (Photo by Panwar Abhash Anil) \\n5.4) ARMAX model: \\nAn ARMAX is a model of lagged dependent variable and lagged independent variable(s). One possible \\nextension to the ARMA model is to use exogenous. This means that we model the time series using \\nother independent variables as well as the time series itself. \\nThis is like a combination between an ARMA model and a normal linear regression model. \\n• \\nExogenous ARMA \\n• \\nUse external variables as well as time series \\n• \\nARMAX =ARMA + linear regression \\nIn principle, an ARMAX model is a linear regression model that uses an ARMA-type process [i.e. w(t)]'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 19}, page_content='• \\nARMAX =ARMA + linear regression \\nIn principle, an ARMAX model is a linear regression model that uses an ARMA-type process [i.e. w(t)] \\nto model residuals: \\n \\nEquation of ARMAX (Photo by Panwar Abhash Anil) \\n5.5) ARIMA model: \\nARIMA model is actually a class of models that ‘explains’ a given time series based on its own past \\nvalues, that is, its own lags and the lagged forecast errors, so that equation can be used to forecast future \\nvalues. \\nWe cannot apply the ARMA model to non-stationary times series. We need to take the difference of the \\ntime series to make it stationary. Only then can we model it.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 20}, page_content='However, when we do this, we have a modal which is trained to predict the value of the difference of \\nthe time series. What we really want to predict is not the difference, but the actual value of the time \\nseries. \\nAn ARIMA model is characterized by 3 terms: p, d, q \\nwhere, \\n• \\np is the order of the AR term \\n• \\nq is the order of the MA term \\n• \\nd is the number of differencing required to make the time series stationary \\n6] Model diagnostics: \\nModel diagnostics to confirm our model is behaving well. To diagnose our model we focus on the \\nresiduals to the training data. \\nThe residuals are the difference between our model’s one-step-ahead predictions and the real values of \\nthe time series. \\n  \\n1. Mean Absolute Percentage Error (MAPE) \\nMAPE calculates the average of the absolute percentage differences between the model’s predictions \\nand the actual values. Therefore, this metric expresses the average error as a percentage of the actual \\nvalue.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 20}, page_content='and the actual values. Therefore, this metric expresses the average error as a percentage of the actual \\nvalue. \\n \\nMAPE penalizes negative errors more heavily (when the predicted value exceeds the actual). This is \\nbecause the percentage error cannot exceed 100% for very low predictions, while there is no upper limit \\nfor higher predictions. Consequently, MAPE tends to favor models that underestimate rather than \\noverestimate. An example of using MAPE in a business context would be in evaluating the accuracy of \\nonline sales forecasting models, as well as in cash flow forecasting (financial projections) \\n \\n2. Mean Squared Error (MSE) \\nThis metric is widely used to evaluate regression models. It represents the average of the squared \\ndifference between the original and predicted values.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 21}, page_content='The importance of using MSE in identifying outliers and imbalances in the dataset. Furthermore, this \\nmetric is most suitable when the dataset has a normal distribution. MSE will always be non-negative \\nand in simpler terms, the lower the value, the better the fit. Implicitly understood, it indicates that the \\nsmaller the difference between the actual and predicted values, the smaller the trade-off between bias \\nand variance of the model. \\nAs previously explained, the downside of using MSE is that it is sensitive to large errors, as it squares \\nthe differences. \\nThe use of this metric in a business environment includes employing MSE in evaluating stock forecasts \\nand financial asset price predictions, to fine-tune investment strategies. \\n \\nTo optimize your forecast, whether moving average, exponential smoothing or another form of a \\nforecast, you need to calculate and evaluate MAD, MSE, RMSE, and MAPE. With Excel 2016 or later, \\nthis is easy to do.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 21}, page_content='forecast, you need to calculate and evaluate MAD, MSE, RMSE, and MAPE. With Excel 2016 or later, \\nthis is easy to do. \\n3. The Mean Absolute Deviation (MAD) is the sum of absolute differences between the actual \\nvalue and the forecast divided by the number of observations. MAD is the same as MAE, Mean \\nAbsolute Error. \\n \\n4. Mean square error (MSE) is probably the most commonly used error metric. It penalizes \\nlarger errors because squaring larger numbers has a greater impact than squaring smaller \\nnumbers.  The MSE is the sum of the squared errors divided by the number of observations. \\n \\n5. The Root Mean Square Error (RMSE) is the square root of the MSE. RMSE is used to \\nconvert MSE back into the same units as the actual data. \\n \\n6. Mean Absolute Percentage Error (MAPE) is the average of absolute errors divided by actual \\nobservation values. MAPE should not be used if there are zeros or near-zeros in the actual'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 21}, page_content='observation values. MAPE should not be used if there are zeros or near-zeros in the actual \\ndata. SMAPE, Symmetric Mean Absolute Percent Error, can be used where there are zero \\nor near-zeros values in the actual data.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 22}, page_content='7. Symmetric Mean Absolute Percent Error (SMAPE) is an alternative to Mean Absolute \\nPercent Error (MAPE) when there are zero or near-zero values in your actual observations. \\nSMAPE self-limits to an error rate of 200%, reducing the influence of zero or near-zeros \\nobservations. SMAPE is the forecast minus actuals divided by the sum of forecasts and actuals \\nas expressed in this formula: \\n \\n \\n8. Mean Absolute Error: \\nHow large the residuals are and so how far our predictions are from the true values. Then calculate mae \\nof the residuals \\nIf the model fits well the residuals will be white gaussian centered on zero. \\n \\nEvaluating Time Series Models \\nWhen Evaluating Time Series Models, it’s super important to consider various metrics to determine \\ntheir accuracy and performance. \\nHere are some key factors to assess: \\n• \\nMean Absolute Error (MAE) provides an average of the absolute errors between predictions \\nand actual values.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 23}, page_content='• \\nMean Squared Error (MSE) measures the average of the squared errors, emphasizing larger \\nerrors more than MAE. \\n• \\nRoot Mean Squared Error (RMSE) is the square root of MSE, giving us an interpretable value \\nin the same units as the data. \\n• \\nMean Absolute Percentage Error (MAPE) calculates the percentage not the same between \\npredictions and actual values, giving ideas into the model’s performance relative to the data. \\nTo improve the evaluation process, consider using techniques like cross-validation to test the model on \\ndifferent subsets of data. \\nThis helps validate the model’s strongness and generalizability. \\nChoosing the Right Time Series Model \\nWhen it comes to time series analysis, selecting the appropriate model is critical for accurate \\nforecasting. \\nHere are some key considerations to help us choose the right time series model: \\n• \\nUnderstand the Data: Before choosing a model, it’s super important to thoroughly understand'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 23}, page_content='• \\nUnderstand the Data: Before choosing a model, it’s super important to thoroughly understand \\nthe patterns present in the data. Looking at the trends, seasonality, and cyclicality can guide us \\ntowards selecting the most suitable model. \\n• \\nIdentify Stationarity: Ensuring that the data is stationary is important for many time series \\nmodels. Stationarity implies that the statistical properties of the data remain constant over time, \\nmaking it easier to predict future values. \\n• \\nChoose the Right Technique: Based on the characteristics of the data, we can opt for techniques \\nsuch as moving averages, exponential smoothing, or more advanced models like ARIMA \\n(AutoRegressive Integrated Moving Average). \\n• \\nInvestigate Advanced Models: To investigate more into time series analysis, it’s beneficial to \\ninvestigate resources from reputable sources such as Towards Data Science and \\nthe StatsModels library for Python.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 23}, page_content='investigate resources from reputable sources such as Towards Data Science and \\nthe StatsModels library for Python. \\nBy following these steps and using the appropriate time series models, we can make smart decisions for \\nforecasting future trends. \\n \\nSummary \\n  \\nThis module is an introduction to time series. Here we give a basic introduction of Time series analysis \\nand attempt to explain its meaning, concepts that help in understanding its vast application areas. \\nClassification of time series like univariate, multivariate, discrete and continuous are discussed and their \\ndifferences analyzed from one another. After that components of time series like secular trend, seasonal, \\ncyclic and irregular are discussed in detail with graphical understanding so that they are easy to learn \\nand differentiate from one another. Mathematical model of time series like additive model, \\nmultiplicative model and mixed models are shown with their mathematical formulation, to know about'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 23}, page_content='multiplicative model and mixed models are shown with their mathematical formulation, to know about \\nthe importance of time series and its applications. Utility, requirement of time series and its application \\nare discussed for in depth knowledge of this topic.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 24}, page_content='Suggested Readings \\n  \\n• \\nGupta, S. P., Statistical Methods, Sultan Chand & Sons, New Delhi, 2012. \\n• \\nGupta, S. C. and Kapoor, V. K., Fundamentals of Applied Statistics, Sultan Chand & Sons, New \\nDelhi, 2009. \\n• \\nSharma, J. K., Business Statistics, Vikas Publishing House, 2014. \\n• \\nTsay, R. S., Time Series and Forecasting: Brief History and Future Research, Journal of the \\nAmerican \\n• \\nStatistical Association, Vol.95, pp. 638-643, 2000. \\n• \\n https://medium.com/analytics-vidhya/introduction-to-time-series-analysis-and-key-concepts-\\ndbf6c394984f \\n• \\nhttps://financestu.com/time-series-data-vs-cross-sectional-data/ \\n \\n \\nWhat is Stationarity? \\nA time series is said to be stationary if its statistical properties, such as the mean, variance, and \\nautocorrelation, are constant over time. In other words, the distribution of the data does not change over \\ntime. This is in contrast to a non-stationary time series, where the statistical properties of the data change \\nover time.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 24}, page_content='time. This is in contrast to a non-stationary time series, where the statistical properties of the data change \\nover time. \\nFor example, consider a time series of monthly sales data for a company. If the mean sales are constant \\nover time, and the variance of the sales is also constant over time, then the time series is stationary. \\nHowever, if the mean sales are increasing over time, or if the variance of the sales is increasing over \\ntime, then the time series is non-stationary. \\nThe reason why stationarity is important is because many statistical models and techniques used in \\neconomics and other fields require the data to be stationary. This is because these models and techniques \\nare based on the assumption that the statistical properties of the data are constant over time. If the data \\nis non-stationary, then these models and techniques may not provide accurate results. \\n \\nWhy Stationarity Matters in Time Series Analysis and How to Achieve It'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 24}, page_content='Why Stationarity Matters in Time Series Analysis and How to Achieve It \\n \\nTime series data is universal in fields like finance, healthcare, climate science, and more, where the \\nanalysis of patterns over time plays a crucial role in decision-making. However, not all time series data \\nis immediately ready for modeling. One of the fundamental properties that analysts and data scientists \\nlook for in time series is stationarity. A stationary time series has statistical properties — such as its \\nmean, variance, and autocorrelation — that remain consistent over time. This stability is a critical \\nassumption for many forecasting models, such as ARIMA, that rely on predictable and consistent \\npatterns in the data. Understanding stationarity and knowing how to test and enforce it are essential \\nskills for anyone working with time series data. \\nWhat is Stationarity?'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 25}, page_content='A time series is stationary if its statistical properties (mean, variance, and autocorrelation) remain \\nconstant over time. This means that the process generating the time series does not change over time, \\nmaking it easier to model and predict. \\nOr \\nStationarity in time series refers to a condition where the statistical properties of the series remain \\nconstant over time. This means that the mean, variance, and autocorrelation structure of the data do not \\nchange as time progresses. Stationarity is often categorized into two main types: \\n1. Strong (Strict) Stationarity: A time series is strictly stationary if the joint probability \\ndistribution of any subset of the series remains the same, regardless of the time at which the \\nsubset is observed. \\nOr  \\nStrict Stationarity → The joint distribution of values remains unchanged regardless of the \\ntime shift. \\n \\n2. Weak (Second-Order) Stationarity: A time series is weakly stationary if its mean and variance'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 25}, page_content='time shift. \\n \\n2. Weak (Second-Order) Stationarity: A time series is weakly stationary if its mean and variance \\nare constant over time, and the covariance between two time points depends only on the time \\nlag between them. \\nOr  \\nWeak (or Second-Order) Stationarity → The mean and variance are constant over time, and \\nthe autocovariance depends only on the time lag, not the actual time. \\n \\nFor practical purposes, weak stationarity is usually sufficient and is the focus of most statistical tests \\nand transformations in time series analysis. \\nMany real-world time series, like stock prices or seasonal sales data, are non-stationary due to trends, \\nseasonality, or other factors. Recognizing this non-stationarity is the first step toward making the data \\nusable for predictive models.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 26}, page_content='Why Stationarity Matters \\nStationarity is a cornerstone of time series analysis and forecasting. Many statistical and machine \\nlearning models, such as ARIMA and SARIMA, assume that the input data is stationary. When this \\nassumption is violated, these models can produce inaccurate or misleading results. Here’s why \\nstationarity is important: \\n1. Model Assumptions: Time series models often rely on the assumption that relationships in the \\ndata remain consistent over time. Non-stationary data, with changing means or variances, can \\ndisrupt this consistency and compromise model performance. \\n2. Predictability: Stationary data is easier to predict because its underlying patterns are stable. \\nThis stability allows models to identify consistent trends and relationships, which leads to more \\nreliable forecasts. \\n3. Statistical Inference: Many statistical tests and methods, like hypothesis testing or confidence'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 26}, page_content='reliable forecasts. \\n3. Statistical Inference: Many statistical tests and methods, like hypothesis testing or confidence \\nintervals, assume stationarity. Violations of this assumption can lead to incorrect conclusions. \\n4. Simpler Transformations: Working with stationary data simplifies the analysis by removing \\ncomplex trends and seasonality, enabling a clearer focus on relationships in the residual data. \\nUnderstanding the importance of stationarity helps analysts and data scientists make informed decisions \\nabout preprocessing and choosing appropriate models for their time series data.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 27}, page_content='Or  \\n Importance of Stationarity in Time Series Analysis \\n1. Model Simplicity and Reliability \\n• \\nMany time series models (such as ARIMA, SARIMA, and Exponential Smoothing) assume \\nstationarity. \\n• \\nIf a time series is non-stationary, the model may give misleading results or fail to capture \\npatterns effectively. \\n2. Consistency in Statistical Inference \\n• \\nIn stationary series, parameters like mean and variance remain stable over time, making \\nstatistical tests (like hypothesis testing) valid. \\n• \\nIn non-stationary series, statistical relationships may change over time, leading to incorrect \\nconclusions. \\n3. Improved Forecasting Accuracy \\n• \\nStationary time series allow models to generalize better for forecasting future values. \\n• \\nNon-stationary data often require differencing or transformation to remove trends and \\nseasonality before forecasting. \\n4. Meaningful Autocorrelation and Seasonality Detection \\n•'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 27}, page_content='seasonality before forecasting. \\n4. Meaningful Autocorrelation and Seasonality Detection \\n• \\nIn a stationary series, the autocorrelation function (ACF) and partial autocorrelation \\nfunction (PACF) provide meaningful insights into the relationship between past and present \\nvalues. \\n• \\nIn non-stationary series, high correlations can be due to trends, not actual dependencies, leading \\nto spurious results. \\n5. Preventing Spurious Regression \\n• \\nRegressing non-stationary time series on each other can lead to spurious (false) relationships, \\nwhere variables appear to be correlated even when they are not. \\n• \\nStationarity ensures that the regression results are valid and interpretable. \\n \\nHow to Test for Stationarity \\nIdentifying whether a time series is stationary is a critical step before building predictive models. There \\nare several methods to assess stationarity, ranging from simple visual inspections to formal statistical \\ntests. \\n1. Visual Inspection \\n•'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 27}, page_content='are several methods to assess stationarity, ranging from simple visual inspections to formal statistical \\ntests. \\n1. Visual Inspection \\n• \\nPlot the Time Series: Observe the time series plot for trends or seasonality. Non-stationary \\ndata often shows upward or downward trends or repeating seasonal patterns. \\n• \\nRolling Statistics: Calculate and plot rolling mean and variance. If these values change over \\ntime, the data is likely non-stationary.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 28}, page_content='The plot above illustrates the original non-stationary time series data, along with its rolling mean and \\nrolling standard deviation. Notice how both the rolling mean and standard deviation change over time, \\nindicating that the data is non-stationary. \\n2. Statistical Tests \\nAugmented Dickey-Fuller (ADF) Test: \\n• \\nA widely used test for stationarity. \\n• \\nNull hypothesis (H₀): The series is non-stationary. \\n• \\nIf the p-value is below a chosen significance level (e.g., 0.05), you can reject the null \\nhypothesis, indicating the series is stationary. \\nFor example:  \\nThe Augmented Dickey-Fuller (ADF) test results are as follows: \\n• \\nADF Statistic: 0.096 \\n• \\np-value: 0.966 \\nSince the p-value (0.966) is much greater than 0.05, we fail to reject the null hypothesis. This indicates \\nthat the data is non-stationary.  \\n Kwiatkowski-Phillips-Schmidt-Shin (KPSS) Test: \\n• \\nTests for trend stationarity. \\n• \\nNull hypothesis (H₀): The series is stationary. \\n•'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 28}, page_content='Kwiatkowski-Phillips-Schmidt-Shin (KPSS) Test: \\n• \\nTests for trend stationarity. \\n• \\nNull hypothesis (H₀): The series is stationary. \\n• \\nA p-value higher than the significance level suggests stationarity. \\nFor example: \\nThe Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test results are as follows: \\n• \\nKPSS Statistic: 1.770 \\n• \\np-value: 0.01 \\n• \\nSince the KPSS statistic exceeds the critical values at all levels and the p-value (0.01) is less \\nthan 0.05, we reject the null hypothesis. This indicates that the data is not stationary.  \\n3. Autocorrelation Analysis'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 29}, page_content='• \\nUse an autocorrelation function (ACF) plot to detect patterns or dependencies in the data. Non-\\nstationary series often exhibit slowly decaying autocorrelations. \\n \\nThe autocorrelation plot (ACF) above shows that the autocorrelations decay slowly over increasing \\nlags. This gradual decline is a strong indicator of non-stationarity in the time series data.  \\nOr \\nHow to Check for Stationarity? \\n1. Visual Inspection \\n• \\nPlot the time series and observe if there is a clear trend or seasonality. \\n• \\nIf the mean and variance seem to change over time, the series is likely non-stationary. \\n2. Summary Statistics \\n• \\nDivide the series into different time intervals and check if mean and variance remain constant. \\n3. Statistical Tests for Stationarity \\n• \\nAugmented Dickey-Fuller (ADF) Test → Null hypothesis: The series is non-stationary. \\n• \\nKwiatkowski-Phillips-Schmidt-Shin (KPSS) Test → Null hypothesis: The series is \\nstationary. \\n•'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 29}, page_content='• \\nKwiatkowski-Phillips-Schmidt-Shin (KPSS) Test → Null hypothesis: The series is \\nstationary. \\n• \\nPhillips-Perron (PP) Test → Alternative to ADF for testing unit roots. \\n \\nStationarity is a fundamental requirement for many time series models. Ensuring that a time \\nseries is stationary improves: \\n• \\n \\nModel accuracy \\n• \\n \\nForecast reliability \\n• \\n \\nStatistical validity'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 30}, page_content='Unit 3: \\nUnivariate time series analysis — II \\n \\nARMA (p,q) process, ACF (Auto Correlation Function) and PACF (Partial Auto Correlation \\nFunction) of an ARMA (p,q) process, forecasting ARMA process, integration of non-stationary data, \\nfirst-order integration and second order integration, ARIMA (p,i,q), estimation of parameters of ARIMA \\nmodel, Wald Test Statistic for significance of coefficients. \\n \\nARMA TIME SERIES MODEL \\nTime series analysis is a crucial aspect of data science, particularly when dealing with data that is \\ncollected over time. One of the fundamental models used in time series analysis is the ARMA \\n(Autoregressive Moving Average) \\nmodel. \\nThis article \\nwill delve \\ninto \\nthe ARMA \\nmodel, \\nits components, how it works, and its applications. \\nTable of Content \\n• \\nUnderstanding ARMA Model \\no \\n1. ARMA Components: Autoregressive (AR) \\no \\n2. ARMA Components: Moving Average (MA) \\no \\nMathematical Representation of ARMA Model \\n•'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 30}, page_content='o \\n1. ARMA Components: Autoregressive (AR) \\no \\n2. ARMA Components: Moving Average (MA) \\no \\nMathematical Representation of ARMA Model \\n• \\nHow to Determine the Orders p and q in ARMA Model? \\n• \\nApplication and Use Cases of ARMA Model \\n• \\nAdvantages and Disadvantages of ARMA Model \\nUnderstanding ARMA Model \\nThe ARMA model is a combination of two simpler models: the Autoregressive (AR) model and the \\nMoving Average (MA) model. The ARMA model is used to describe time series data that is stationary, \\nmeaning its statistical properties do not change over time. \\n• \\nAutoregressive (AR) Model: This model uses the dependency between an observation and a \\nnumber of lagged observations (previous time points). It is denoted as AR(p), where p is the \\nnumber of lagged observations included. \\n• \\nMoving Average (MA) Model: This model uses the dependency between an observation and \\na residual error from a moving average model applied to lagged observations. It is denoted'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 30}, page_content='a residual error from a moving average model applied to lagged observations. It is denoted \\nas MA(q), where q is the number of lagged forecast errors included. \\nThe ARMA model combines these two approaches and is denoted as ARMA(p, q), where p is the order \\nof the autoregressive part and q is the order of the moving average part. \\n1. ARMA Components: Autoregressive (AR) \\nThe Autoregressive (AR) part of the ARMA model uses the relationship between an observation and a \\nnumber of lagged (previous) observations to predict future values. Imagine, that you are attempting to \\nforecast the temperature for tomorrow by using the data from the last several days. The AR portion'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 31}, page_content=\"makes the assumption that the current temperature and the temperatures from earlier days are connected. \\nFor instance suppose we write the temperature of today as Tt and the temperatures of the last two days \\nas Tt−1 and Tt−2, an AR(2) model (since it uses two lagged values) can be written as: \\nTt=c+ϕ1Tt−1+ϕ2Tt−2+et \\nWhere: \\n• \\nc is a constant. \\n• \\nϕ1 and ϕ2 are coefficients that determine the influence of the past temperatures. \\n• \\net is the error term (random noise). \\n2. ARMA Components: Moving Average (MA) \\nThe Moving Average (MA) part of the ARMA model uses the dependency between an observation and \\na residual error from a moving average model applied to lagged observations. Continuing with our \\ntemperature example, the MA part assumes that today's temperature is also influenced by the errors \\nmade in predicting previous days' temperatures. If we denote today's error as etet and the errors of the \\nlast two days as et−1et−1 and et−2et−2 an MA(2) model can be written as:\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 31}, page_content='last two days as et−1et−1 and et−2et−2 an MA(2) model can be written as: \\nTt=c+et+θ1et−1+θ2et−2Tt=c+et+θ1et−1+θ2et−2 \\nWhere: \\n• \\nc is a constant. \\n• \\nϕ1ϕ1and ϕ2ϕ2 are coefficients that determine the influence of the past temperatures. \\nMathematical Representation of ARMA Model \\nThe ARMA model is a combination of both AR and MA components. An ARMA(p, q) model, \\nwhere pp is the number of lagged observations (AR part) and qq is the number of lagged forecast errors \\n(MA part), is represented as: \\nTt=c+Σi=1pϕiTt−i+Σj=1qθjet−j+etTt=c+Σi=1pϕiTt−i+Σj=1qθjet−j+et \\nHow to Determine the Orders p and q in ARMA Model? \\nDetermining the appropriate values for p and q is crucial for building an effective ARMA model. This \\ncan be done using the following methods: \\n1. Partial Autocorrelation Function (PACF): \\n• \\nPACF is used to determine the order p of the AR model. It measures the correlation \\nbetween observations at different lags, excluding the influence of intermediate lags. \\n•'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 31}, page_content='between observations at different lags, excluding the influence of intermediate lags. \\n• \\nThe order p is determined by the lag at which the PACF plot cuts off. \\n2. Autocorrelation Function (ACF): \\n• \\nACF is used to determine the order q of the MA model. It measures the correlation \\nbetween observations at different lags. \\n• \\nThe order q is determined by the lag at which the ACF plot cuts off. \\nApplication and Use Cases of ARMA Model \\nFor predicting and evaluating time series data the ARMA model is extensively utilized in many different \\ndomains. A few typical uses are as follows:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 32}, page_content='• \\nEconomics: Predicting stock prices, exchange rates, and economic indicators. \\n• \\nWeather Forecasting: Analyzing temperature, rainfall, and other meteorological data. \\n• \\nSales Forecasting: Predicting future sales based on past sales data. \\n• \\nEngineering: Monitoring and controlling industrial processes. \\n• \\nInventory management: Forecasting future demand for products. \\n• \\nEpidemiology: Predicting the spread of diseases. \\nAdvantages and Disadvantages of ARMA Model \\nAdvantages \\nLimitations \\nSimplicity: The ARMA model is \\nrelatively simple to understand and \\nimplement. \\nStationarity Requirement: The ARMA model assumes \\nthat the time series data is stationary, meaning its \\nstatistical properties do not change over time. Non-\\nstationary data needs to be transformed before applying \\nthe ARMA model. \\nEffectiveness: It works well for many \\ntypes of time series data, especially \\nwhen there are clear patterns or trends. \\nComplexity with High Parameters: For large values of ?'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 32}, page_content='types of time series data, especially \\nwhen there are clear patterns or trends. \\nComplexity with High Parameters: For large values of ? \\nand ?, the model can become complex and difficult to \\ninterpret. \\nCombination of AR and MA: By \\ncombining both autoregressive and \\nmoving average components, the ARMA \\nmodel can capture more complex \\npatterns in the data. \\nChoosing the right order for the AR and MA \\ncomponents can be challenging. \\nConclusion \\nThe ARMA model is a powerful tool for time series analysis, helping us predict future values based on \\npast trends. It offers a thorough method for deciphering patterns and generating forecasts by merging \\nthe moving average and autoregressive components. Even though it has drawbacks, its ease of use and \\npotency make it a useful technique in a variety of sectors. \\nWe have deconstructed the ARMA model in this easy-to-read introduction for beginners. Always keep'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 32}, page_content=\"We have deconstructed the ARMA model in this easy-to-read introduction for beginners. Always keep \\nin mind that improving forecasts requires balancing historical values and mistakes. Next time you \\nencounter time series data, think ARMA ! \\nARMA TIME SERIES MODEL- FAQs \\nWhat is the difference between AR and MA in ARMA? \\nWhile the MA (Moving Average) component leverages historical errors to enhance the prediction, the \\nAR (Autoregressive) component uses historical observations to forecast future values. \\nWhat if my data isn't stationary?\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 33}, page_content='There are techniques to make non-stationary data stationary, like differencing. \\nCan ARMA be used for non-stationary data? \\nNo, the ARMA model requires the data to be stationary. Non-stationary data needs to be transformed \\n(e.g., through differencing) to become stationary before applying ARMA. \\nHow do you choose the values of ? and ? in ARMA? \\nSelecting the values of ? , and ? frequently entails applying information criteria, such as AIC (Akaike \\nInformation Criterion), and evaluating the time series data autocorrelation function (ACF), and partial \\nautocorrelation function (PACF). \\n \\nAutocorrelation and Partial Autocorrelation \\n \\nAutocorrelation and partial autocorrelation are statistical measures that help analyze the relationship \\nbetween a time series and its lagged values. In R Programming Language, the acf() and pacf() functions \\ncan be used to compute and visualize autocorrelation and partial autocorrelation, respectively. \\nAutocorrelation'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 33}, page_content='can be used to compute and visualize autocorrelation and partial autocorrelation, respectively. \\nAutocorrelation \\nAutocorrelation measures the linear relationship between a time series and its lagged values. In simpler \\nterms, it assesses how much the current value of a series depends on its past values. Autocorrelation is \\nfundamental in time series analysis, helping identify patterns and dependencies within the data. \\nInterpretation \\n• \\nPositive ACF: A positive ACF at lag k indicates a positive correlation between the current \\nobservation and the observation at lag k. \\n• \\nNegative ACF: A negative ACF at lag k indicates a negative correlation between the current \\nobservation and the observation at lag k.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 34}, page_content='• \\nDecay in ACF: The decay in autocorrelation as lag increases often signifies the presence of a \\ntrend or seasonality in the time series. \\n• \\nSignificance: Significant ACF values at certain lags may suggest potential patterns or \\nrelationships in the time series. \\nExample:  \\nLet\\'s take an example with a real-world dataset to illustrate the differences between the Autocorrelation \\nFunction (ACF) and Partial Autocorrelation Function (PACF). In this example, we\\'ll use the \\n\"AirPassengers\" dataset in R, which represents monthly totals of international airline passengers. \\n# Load necessary libraries \\nlibrary(forecast) \\n \\n# Load AirPassengers dataset \\ndata(\"AirPassengers\") \\n \\n# Plot the time series \\nplot(AirPassengers, main = \"Monthly International Airline Passengers\") \\nOutput: \\nAutocorrelation \\nNow Plot ACF \\n# Plot ACF \\nacf(AirPassengers, main = \"Autocorrelation Function (ACF) for AirPassengers\") \\nOutput:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 35}, page_content='Autocorrelation \\nwe use the same \"AirPassengers\" dataset and plot the PACF. The PACF plot shows the direct correlation \\nat each lag, helping identify the order of autoregressive terms. \\n• \\nThe ACF plot reveals a decaying pattern, indicating a potential seasonality in the data. Peaks at \\nmultiples of 12 (12, 24, ...) suggest a yearly cycle, reflecting the seasonal nature of airline \\npassenger data. \\n• \\nThe ACF plot gives a comprehensive view of the correlation at all lags, showing how each \\nobservation relates to its past values. \\nPartial Autocorrelation \\nPartial autocorrelation removes the influence of intermediate lags, providing a clearer picture of the \\ndirect relationship between a variable and its past values. Unlike autocorrelation, partial autocorrelation \\nfocuses on the direct correlation at each lag. \\n \\nInterpretation \\n• \\nDirect Relationship: PACF isolates the direct correlation between the current observation and'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 35}, page_content='Interpretation \\n• \\nDirect Relationship: PACF isolates the direct correlation between the current observation and \\nthe observation at lag k, controlling for the influence of lags in between. \\n• \\nAR Process Identification: Peaks or significant values in PACF at specific lags can indicate \\npotential orders for autoregressive (AR) terms in time series models. \\n• \\nModeling Considerations: Analysts often examine PACF to guide the selection of lag orders \\nin autoregressive integrated moving average (ARIMA) models. \\n# Load necessary libraries \\nlibrary(forecast)'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 36}, page_content='# Load AirPassengers dataset \\ndata(\"AirPassengers\") \\n \\n# Plot PACF \\npacf_result <- pacf(AirPassengers,  \\n                    main = \"Partial Autocorrelation Function (PACF) for AirPassengers\") \\nOutput: \\nPartial Autocorrelation \\nwe use the same \"AirPassengers\" dataset and plot the PACF. The PACF plot shows the direct correlation \\nat each lag, helping identify the order of autoregressive terms. \\n• \\nThe PACF plot helps identify the direct correlation at each lag. Peaks at lags 1 and 12 suggest \\npotential autoregressive terms related to the monthly and yearly patterns in the data. \\n• \\nThe PACF plot, on the other hand, focuses on the direct correlation at each lag, providing \\ninsights into the order of autoregressive terms. \\n• \\nBy comparing the two plots, you can observe how they complement each other in revealing the \\ntemporal dependencies within the time series. The ACF helps identify overall patterns, while \\nthe PACF refines the analysis by highlighting direct correlations.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 36}, page_content='the PACF refines the analysis by highlighting direct correlations. \\nPerform both on a Time series dataset to compare \\n# Load necessary libraries \\nlibrary(fpp2) \\n \\n# Load the \"ausbeer\" dataset from fpp2 package \\ndata(\"ausbeer\") \\n \\n# Plot the time series \\nautoplot(ausbeer, main = \"Monthly Australian Beer Production\")'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 37}, page_content='Output: \\nTime Series Plot \\nPlot ACF \\n# Plot ACF \\nacf(ausbeer, main = \"Autocorrelation Function (ACF) for Australian Beer Production\") \\nOutput: \\nAutocorrelation Plot \\nPlot PACF for differenced time series \\n# Load PACF from the forecast package \\nlibrary(forecast) \\n \\n# Plot PACF for differenced time series'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 38}, page_content='diff_ausbeer <- diff(ausbeer) \\npacf_result <- pacf(diff_ausbeer,main = \"Partial Autocorrelation Function (PACF) for  \\n                                  Differenced Australian Beer Production\") \\nOutput: \\nPartial Autocorrelation Plot \\nIn this example, we use the \"ausbeer\" dataset from the fpp2 package, which represents monthly \\nAustralian beer production. The ACF plot can provide insights into the potential seasonality and trends \\nin beer production. \\n• \\nAutocorrelation (ACF): The ACF plot for Australian beer production may reveal patterns \\nrelated to seasonality, trends, or cyclic behavior. Peaks at certain lags could indicate recurring \\npatterns in beer production. \\n• \\nPartial Autocorrelation (PACF): Differencing the time series and examining the PACF helps \\nidentify potential autoregressive terms that capture the direct correlation at each lag, after \\nremoving the influence of trends. \\nAdditional Considerations \\n• \\n \\no'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 38}, page_content='removing the influence of trends. \\nAdditional Considerations \\n• \\n \\no \\nSeasonal Differencing: In some cases, it might be beneficial to apply seasonal \\ndifferencing (e.g., differencing by 12 for monthly data) to handle seasonality properly. \\no \\nSeasonal Differencing: In some cases, it might be beneficial to apply seasonal \\ndifferencing (e.g., differencing by 12 for monthly data) to handle seasonality properly. \\no \\nModel Selection: The combination of ACF and PACF analysis can guide the selection \\nof parameters in time series models, such as autoregressive integrated moving average \\n(ARIMA) models. \\no \\nInterpretation: Understanding the patterns revealed by ACF and PACF is crucial for \\ninterpreting the underlying dynamics of a time series and building accurate forecasting \\nmodels. \\nDifference between Autocorrelation and Partial Autocorrelation \\nAutocorrelation (ACF) and Partial Autocorrelation (PACF) are both measures used in time series'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 38}, page_content='Autocorrelation (ACF) and Partial Autocorrelation (PACF) are both measures used in time series \\nanalysis to understand the relationships between observations at different time points.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 39}, page_content='Autocorrelation \\nPartial Autocorrelation \\nUsed for identifying the order of a moving average \\n(MA) process. \\nUsed for identifying the order of an autoregressive \\n(AR) process. \\nRepresents the overall correlation structure of the \\ntime series. \\nHighlights \\nthe \\ndirect \\nrelationships \\nbetween \\nobservations at specific lags. \\nAutocorrelation measures the linear relationship \\nbetween \\nan \\nobservation \\nand \\nits \\nprevious \\nobservations at different lags. \\nPartial Autocorrelation measures the direct linear \\nrelationship between an observation and its \\nprevious observations at a specific lag, excluding \\nthe contributions from intermediate lags. \\nConclusion \\nACF and PACF are critical tools in time series analysis, providing insights into temporal dependencies \\nwithin a dataset. These functions aid in understanding the structure of the data, identifying potential \\npatterns, and guiding the construction of time series models for accurate forecasting. By examining'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 39}, page_content='patterns, and guiding the construction of time series models for accurate forecasting. By examining \\nACF and PACF, analysts gain valuable information about the underlying dynamics of the time series \\nthey are studying. \\nhttps://www.geeksforgeeks.org/autocorrelation-and-partial-autocorrelation/ \\nOR \\n \\nARMA (p, q) Process: Detailed Explanation \\nARMA (p, q) stands for AutoRegressive Moving Average process, which is one of the most commonly \\nused models in time series analysis for understanding and forecasting data. It combines two \\ncomponents: \\n• \\nAR (AutoRegressive) Component: Uses past values (lags) to predict future values. \\n• \\nMA (Moving Average) Component: Uses past forecast errors (shocks) to predict future values.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 40}, page_content='Properties of ARMA Model \\n• \\nStationarity: ARMA requires the data to be stationary, meaning constant mean and variance \\nover time. \\n• \\nInvertibility: For the MA component, it ensures that the model can be represented using an \\ninfinite AR process. \\n• \\nWhite Noise Residuals: The error terms (ϵt) should be independent and identically distributed \\nwith zero mean and constant variance. \\nSteps to Build an ARMA Model \\n1. Visualize the Data: Plot the time series to check for trends or seasonality. \\n2. Check for Stationarity: Use plots like ACF (Autocorrelation Function) and PACF (Partial \\nAutocorrelation Function) or perform statistical tests (e.g., ADF Test). \\n3. Determine p and q Values: \\no \\nUse PACF to determine the AR order p \\no \\nUse ACF to determine the MA order q \\n4. Estimate Parameters: Fit the model using Maximum Likelihood Estimation (MLE). \\n5. Model Diagnostics: Check residuals to ensure they follow a white noise process.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 40}, page_content='5. Model Diagnostics: Check residuals to ensure they follow a white noise process. \\n6. Forecasting: Use the fitted model for short-term predictions.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-03-28T11:59:47+05:30', 'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'total_pages': 42, 'format': 'PDF 1.7', 'title': '', 'author': 'suman mann', 'subject': '', 'keywords': '', 'moddate': '2025-03-28T11:59:47+05:30', 'trapped': '', 'modDate': \"D:20250328115947+05'30'\", 'creationDate': \"D:20250328115947+05'30'\", 'page': 41}, page_content='Example of ARMA Model Application \\nScenario: \\nA financial analyst wants to predict the daily stock prices of a company using past data. After examining \\nthe data, they determine the following: \\n• \\np=2p = 2p=2 (using PACF) \\n• \\nq=1q = 1q=1 (using ACF) \\nARMA(2,1) Model: \\nYt=c+ϕ1Yt−1+ϕ2Yt−2+θ1ϵt−1+ϵt \\nUsing this model, the analyst predicts stock prices for the next 5 days, adjusts the portfolio accordingly, \\nand monitors the results. \\nhttp://www-stat.wharton.upenn.edu/~stine/insr260_2009/lectures/arma_forc.pdf \\nhttp://www.statslab.cam.ac.uk/%7Errw1/timeseries/t.pdf')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd510be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 193 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 7/7 [00:27<00:00,  3.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Embeddings with shape: (193, 384)\n",
      "Adding 193 documents to vector store...\n",
      "Successfully added 193 documents to vector store\n",
      "Total documents in collection: 772\n"
     ]
    }
   ],
   "source": [
    "#converting text into embeddings\n",
    "texts = [doc.page_content for doc in chunks]\n",
    "\n",
    "#generating the embeddings\n",
    "embeddings  = embedding_manager.generate_embeddings(texts)\n",
    "\n",
    "#storing into the vector database\n",
    "vector_store.add_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e6f99",
   "metadata": {},
   "source": [
    "Retriever Pipeline from vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bde982fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.RAGRetriever at 0x25838499d30>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RAGRetriever:\n",
    "    \"\"\"Handles query-based retrieval from the vector store\"\"\"\n",
    "\n",
    "    def __init__(self, vector_store: VectorStore, embedding_manager = EmbeddingManager):\n",
    "        \"\"\"\n",
    "        Initialize the retireiver\n",
    "        Args:\n",
    "            Vector_store: vector store containing document embeddings\n",
    "            embedding_manager: Manager for generating query embeddings\n",
    "        \"\"\"\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "    def retrieve(self, query: str, top_k: int = 5, score_threshold:  float =0.0)-> List[Dict[str,Any]]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant document for a  query\n",
    "        Args:\n",
    "            query: The search  query\n",
    "            top_k: Number of top results to return\n",
    "            score_threshold:Minimum similarity score threshold\n",
    "        Returns:\n",
    "            List of dictionaries containing retrieved documents and metadata    \n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"Retreiving documents for query: {query}\")\n",
    "        print(f\"Top K: {top_k}, score_threshold: {score_threshold}\")\n",
    "\n",
    "        #generate query embedding\n",
    "        query_embedding = self.embedding_manager.generate_embeddings([query])[0]\n",
    "        \n",
    "        #search in a vector store\n",
    "        try:\n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings = [query_embedding.tolist()],\n",
    "                n_results = top_k\n",
    "            )\n",
    "\n",
    "            #process results\n",
    "            retrieved_docs = []\n",
    "\n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents = results['documents'][0]\n",
    "                metadatas = results['metadatas'][0]\n",
    "                distances = results['distances'][0]\n",
    "                ids = results['ids'][0]\n",
    "\n",
    "                for i, (doc_id, document, metadata, distance) in enumerate(zip(ids, documents, metadatas, distances)):\n",
    "                    #converting distance to similarity score(chromadb uses cosine distance)\n",
    "                    similarity_score = 1 - distance\n",
    "\n",
    "                    if similarity_score >= score_threshold:\n",
    "                        retrieved_docs.append({\n",
    "                            'id': doc_id,\n",
    "                            'content': document,\n",
    "                            'metadata': metadata,\n",
    "                            'similarity_score': similarity_score,\n",
    "                            'distance': distance,\n",
    "                            'rank': i+1\n",
    "                        })\n",
    "\n",
    "                print(f\"Retrieved {len(retrieved_docs)} documents after filtering\")\n",
    "            else:\n",
    "                print(\"No documents found\")\n",
    "\n",
    "            return retrieved_docs\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(\"Error during retrieval: {e}\")\n",
    "            return[]\n",
    "\n",
    "rag_retreiver = RAGRetriever(vector_store, embedding_manager)\n",
    "rag_retreiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7f185e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retreiving documents for query: What is multivaritate Time series analysis\n",
      "Top K: 5, score_threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Embeddings with shape: (1, 384)\n",
      "Retrieved 5 documents after filtering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_c455694f_2',\n",
       "  'content': 'Univariate and Multivariate Time Series Analysis  \\n \\nTraditional statistical approaches for time series are univariate, meaning they focus on a single \\nsequence of values. \\nHowever, in the real world, time series data often consists of multiple variables that interact with one \\nanother. This interaction introduces an opportunity to move beyond univariate analysis and leverage \\nmultivariate time series, where relationships between features play a central role. \\n \\nWhat is Univariate Time Series? \\nUnivariate time series analysis deals with a single variable measured over time. For example: \\n• \\nStock prices: The daily closing price of a single stock. \\n• \\nTemperature: The hourly temperature recorded in a city. \\n• \\nMachine sensor data: A single sensor recording vibration levels over time. \\nIn a univariate time series, we focus exclusively on the historical behavior of one sequence to predict',\n",
       "  'metadata': {'keywords': '',\n",
       "   'format': 'PDF 1.7',\n",
       "   'author': 'suman mann',\n",
       "   'moddate': '2025-05-05T12:08:51+05:30',\n",
       "   'creator': 'Microsoft® Word 2019',\n",
       "   'creationdate': '2025-05-05T12:08:51+05:30',\n",
       "   'trapped': '',\n",
       "   'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf',\n",
       "   'producer': 'Microsoft® Word 2019',\n",
       "   'doc_index': 2,\n",
       "   'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf',\n",
       "   'title': '',\n",
       "   'page': 1,\n",
       "   'total_pages': 17,\n",
       "   'modDate': \"D:20250505120851+05'30'\",\n",
       "   'creationDate': \"D:20250505120851+05'30'\",\n",
       "   'content_length': 898,\n",
       "   'subject': ''},\n",
       "  'similarity_score': 0.28607261180877686,\n",
       "  'distance': 0.7139273881912231,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_ca47fdc2_2',\n",
       "  'content': 'Univariate and Multivariate Time Series Analysis  \\n \\nTraditional statistical approaches for time series are univariate, meaning they focus on a single \\nsequence of values. \\nHowever, in the real world, time series data often consists of multiple variables that interact with one \\nanother. This interaction introduces an opportunity to move beyond univariate analysis and leverage \\nmultivariate time series, where relationships between features play a central role. \\n \\nWhat is Univariate Time Series? \\nUnivariate time series analysis deals with a single variable measured over time. For example: \\n• \\nStock prices: The daily closing price of a single stock. \\n• \\nTemperature: The hourly temperature recorded in a city. \\n• \\nMachine sensor data: A single sensor recording vibration levels over time. \\nIn a univariate time series, we focus exclusively on the historical behavior of one sequence to predict',\n",
       "  'metadata': {'producer': 'Microsoft® Word 2019',\n",
       "   'content_length': 898,\n",
       "   'author': 'suman mann',\n",
       "   'creationdate': '2025-05-05T12:08:51+05:30',\n",
       "   'subject': '',\n",
       "   'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf',\n",
       "   'creationDate': \"D:20250505120851+05'30'\",\n",
       "   'title': '',\n",
       "   'format': 'PDF 1.7',\n",
       "   'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf',\n",
       "   'trapped': '',\n",
       "   'modDate': \"D:20250505120851+05'30'\",\n",
       "   'doc_index': 2,\n",
       "   'keywords': '',\n",
       "   'creator': 'Microsoft® Word 2019',\n",
       "   'total_pages': 17,\n",
       "   'moddate': '2025-05-05T12:08:51+05:30',\n",
       "   'page': 1},\n",
       "  'similarity_score': 0.28607261180877686,\n",
       "  'distance': 0.7139273881912231,\n",
       "  'rank': 2},\n",
       " {'id': 'doc_884ad311_2',\n",
       "  'content': 'Univariate and Multivariate Time Series Analysis  \\n \\nTraditional statistical approaches for time series are univariate, meaning they focus on a single \\nsequence of values. \\nHowever, in the real world, time series data often consists of multiple variables that interact with one \\nanother. This interaction introduces an opportunity to move beyond univariate analysis and leverage \\nmultivariate time series, where relationships between features play a central role. \\n \\nWhat is Univariate Time Series? \\nUnivariate time series analysis deals with a single variable measured over time. For example: \\n• \\nStock prices: The daily closing price of a single stock. \\n• \\nTemperature: The hourly temperature recorded in a city. \\n• \\nMachine sensor data: A single sensor recording vibration levels over time. \\nIn a univariate time series, we focus exclusively on the historical behavior of one sequence to predict',\n",
       "  'metadata': {'subject': '',\n",
       "   'total_pages': 17,\n",
       "   'author': 'suman mann',\n",
       "   'doc_index': 2,\n",
       "   'keywords': '',\n",
       "   'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf',\n",
       "   'creationdate': '2025-05-05T12:08:51+05:30',\n",
       "   'modDate': \"D:20250505120851+05'30'\",\n",
       "   'title': '',\n",
       "   'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf',\n",
       "   'creator': 'Microsoft® Word 2019',\n",
       "   'page': 1,\n",
       "   'creationDate': \"D:20250505120851+05'30'\",\n",
       "   'producer': 'Microsoft® Word 2019',\n",
       "   'format': 'PDF 1.7',\n",
       "   'content_length': 898,\n",
       "   'trapped': '',\n",
       "   'moddate': '2025-05-05T12:08:51+05:30'},\n",
       "  'similarity_score': 0.28607261180877686,\n",
       "  'distance': 0.7139273881912231,\n",
       "  'rank': 3},\n",
       " {'id': 'doc_a0ee16b4_2',\n",
       "  'content': 'Univariate and Multivariate Time Series Analysis  \\n \\nTraditional statistical approaches for time series are univariate, meaning they focus on a single \\nsequence of values. \\nHowever, in the real world, time series data often consists of multiple variables that interact with one \\nanother. This interaction introduces an opportunity to move beyond univariate analysis and leverage \\nmultivariate time series, where relationships between features play a central role. \\n \\nWhat is Univariate Time Series? \\nUnivariate time series analysis deals with a single variable measured over time. For example: \\n• \\nStock prices: The daily closing price of a single stock. \\n• \\nTemperature: The hourly temperature recorded in a city. \\n• \\nMachine sensor data: A single sensor recording vibration levels over time. \\nIn a univariate time series, we focus exclusively on the historical behavior of one sequence to predict',\n",
       "  'metadata': {'creator': 'Microsoft® Word 2019',\n",
       "   'creationdate': '2025-05-05T12:08:51+05:30',\n",
       "   'total_pages': 17,\n",
       "   'author': 'suman mann',\n",
       "   'moddate': '2025-05-05T12:08:51+05:30',\n",
       "   'doc_index': 2,\n",
       "   'format': 'PDF 1.7',\n",
       "   'file_path': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf',\n",
       "   'keywords': '',\n",
       "   'page': 1,\n",
       "   'title': '',\n",
       "   'producer': 'Microsoft® Word 2019',\n",
       "   'modDate': \"D:20250505120851+05'30'\",\n",
       "   'source': 'data\\\\pdf\\\\Time Series Analysis -Unit 5.pdf',\n",
       "   'creationDate': \"D:20250505120851+05'30'\",\n",
       "   'subject': '',\n",
       "   'trapped': '',\n",
       "   'content_length': 898},\n",
       "  'similarity_score': 0.28607261180877686,\n",
       "  'distance': 0.7139273881912231,\n",
       "  'rank': 4},\n",
       " {'id': 'doc_4586a968_109',\n",
       "  'content': '❖ Univariate time series: A time series is univariate time series when there is only one type of \\nstudy variable or one characteristics under consideration. For example: share price of one \\ncompany. \\n❖ Multivariate time series: A Time series is multivariate time series when there is more than \\none type of study variable that is of interest in time series. For example- share price of one \\ncompany, share price of other company. \\n \\n \\n \\nComponents of time series: \\nStudy variable take different values in a particular time series. This difference in value is not due to \\nonly one component like time but affected by more than one component or multiple components. These \\nmultiple components pull up and down the values of the characteristics under study. For example: the \\ncrop yield depends on weather condition, seed quality, land quality, fertilizer etc. Here crop yield is \\nstudy variable and weather condition, seed quality, land quality are other multiple components that are',\n",
       "  'metadata': {'modDate': \"D:20250328115947+05'30'\",\n",
       "   'producer': 'Microsoft® Word 2019',\n",
       "   'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf',\n",
       "   'page': 2,\n",
       "   'subject': '',\n",
       "   'moddate': '2025-03-28T11:59:47+05:30',\n",
       "   'creationDate': \"D:20250328115947+05'30'\",\n",
       "   'creator': 'Microsoft® Word 2019',\n",
       "   'title': '',\n",
       "   'trapped': '',\n",
       "   'format': 'PDF 1.7',\n",
       "   'doc_index': 109,\n",
       "   'creationdate': '2025-03-28T11:59:47+05:30',\n",
       "   'keywords': '',\n",
       "   'author': 'suman mann',\n",
       "   'file_path': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf',\n",
       "   'content_length': 981,\n",
       "   'total_pages': 42},\n",
       "  'similarity_score': 0.28262484073638916,\n",
       "  'distance': 0.7173751592636108,\n",
       "  'rank': 5}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retreiver.retrieve(\"What is multivaritate Time series analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be833253",
   "metadata": {},
   "source": [
    "Integration Vectordb context pipeline with LLM output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae69349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple RAG pipeline with GROQ LLM\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#initiaize the groq llm\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "llm = ChatGroq(groq_api_key = groq_api_key, model_name = \"moonshotai/kimi-k2-instruct\", temperature=0.1, max_tokens = 1024)\n",
    "\n",
    "#simple rag function: retrieve context + generate response\n",
    "def rag_simple(query, retriever, llm, top_k = 3):\n",
    "    #retrieve the context\n",
    "    results = retriever.retrieve(query, top_k = top_k)\n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in  results]) if results else \"\"\n",
    "    if not context:\n",
    "        return \"No relevant context found to answer the question.\"\n",
    "    \n",
    "\n",
    "    #generate the answer using groq llm\n",
    "    prompt = f\"\"\"Use the following context to answer the question concisely.\n",
    "            context:{context}\n",
    "            Question: {query}\n",
    "            Answer:\"\"\"\n",
    "    \n",
    "    response = llm.invoke([prompt.format(context = context, query = query)])\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53b2d9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retreiving documents for query: what is univariate analysis?\n",
      "Top K: 3, score_threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Embeddings with shape: (1, 384)\n",
      "Retrieved 3 documents after filtering\n",
      "Univariate analysis is the analysis of a single time-series variable (e.g., one company’s share price).\n"
     ]
    }
   ],
   "source": [
    "answer = rag_simple(\"what is univariate analysis?\", rag_retreiver, llm)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12f3e965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from groq import Client\n",
    "# client = Client()\n",
    "# models = client.models.list()\n",
    "# print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5e1a1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retreiving documents for query: What is univariate analysis?\n",
      "Top K: 3, score_threshold: 0.1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 27.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Embeddings with shape: (1, 384)\n",
      "Retrieved 3 documents after filtering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  Univariate analysis is the analysis of a single time-series variable (only one characteristic under consideration).\n",
      "Sources:  [{'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'page': 2, 'score': 0.19676804542541504, 'preview': '❖ Univariate time series: A time series is univariate time series when there is only one type of \\nstudy variable or one characteristics under consideration. For example: share price of one \\ncompany. \\n❖ Multivariate time series: A Time series is multivariate time series when there is more than \\none t...'}, {'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'page': 2, 'score': 0.19676804542541504, 'preview': '❖ Univariate time series: A time series is univariate time series when there is only one type of \\nstudy variable or one characteristics under consideration. For example: share price of one \\ncompany. \\n❖ Multivariate time series: A Time series is multivariate time series when there is more than \\none t...'}, {'source': 'data\\\\pdf\\\\Time Series Analysis Notes.pdf', 'page': 2, 'score': 0.19676804542541504, 'preview': '❖ Univariate time series: A time series is univariate time series when there is only one type of \\nstudy variable or one characteristics under consideration. For example: share price of one \\ncompany. \\n❖ Multivariate time series: A Time series is multivariate time series when there is more than \\none t...'}]\n",
      "Confidence:  0.19676804542541504\n",
      "context preview: ❖ Univariate time series: A time series is univariate time series when there is only one type of \n",
      "study variable or one characteristics under consideration. For example: share price of one \n",
      "company. \n",
      "❖ Multivariate time series: A Time series is multivariate time series when there is more than \n",
      "one t\n"
     ]
    }
   ],
   "source": [
    "def rag_advanced(query, retriever, llm, top_k = 5, min_score = 0.2, return_context = False):\n",
    "    \"\"\"\n",
    "    RAG Pipeline with extra features: \n",
    "    -Returns answer, sources, confidence score and optionally full context.\n",
    "    \"\"\"\n",
    "\n",
    "    results = retriever.retrieve(query, top_k = top_k, score_threshold = min_score)\n",
    "    if not results:\n",
    "        return {'answer': 'No relevant context found.', 'sources': [],'confidence': 0.0, 'context': ''}\n",
    "    #prepare context and sources\n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in  results])\n",
    "    sources = [{\n",
    "        'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
    "        'page': doc['metadata'].get('page', 'unknown'),\n",
    "        'score': doc['similarity_score'],\n",
    "        'preview': doc['content'][:300] + '...'\n",
    "    }for doc in results]\n",
    "    confidence = max([doc['similarity_score'] for doc in results])\n",
    "\n",
    "    #generate answer\n",
    "    prompt = f\"\"\"Use the following context to answer the question precisely. \\ncontext: \\n{context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\"\"\n",
    "    response = llm.invoke([prompt.format(context = context, query= query)])\n",
    "\n",
    "    output = {\n",
    "        'answer': response.content,\n",
    "        'sources': sources,\n",
    "        'confidence': confidence\n",
    "    }\n",
    "\n",
    "    if return_context:\n",
    "        output['context'] = context\n",
    "    return output\n",
    "\n",
    "\n",
    "#example usage\n",
    "result = rag_advanced(\"What is univariate analysis?\", rag_retreiver, llm, top_k = 3, min_score=0.1, return_context= True)\n",
    "\n",
    "print(\"Answer: \", result['answer'])\n",
    "print(\"Sources: \",result['sources'])\n",
    "print(\"Confidence: \", result['confidence'])\n",
    "print(\"context preview:\", result['context'][:300])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce926eca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
